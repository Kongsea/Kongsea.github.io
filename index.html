<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Hexo</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/27/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/27/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-27T10:57:18+08:00">
                2018-07-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/27/resize-an-image-in-tensorflow-while-keeping-the-aspect-ratio/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/27/resize-an-image-in-tensorflow-while-keeping-the-aspect-ratio/" itemprop="url">在TensorFlow里把Image Resize到固定尺寸同时保持宽高比</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-27T18:29:49+08:00">
                2018-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用TensorFlow读入一幅图片后，有时候我们需要将图片的尺寸进行一些修正，比如AlexNet所做的crop操作，或者某些网络需要固定的输入而将图片resize到固定的大小，等等。如果是针对类似numpy array这样的内容进行这些操作，可能大家都能手到擒来，但在TensorFlow里进行这样的操作需要一些tensor操作，这些操作有些反人类，而且调试不易。所以，本文我们就对这些东西进行一些总结，以便备忘，并方便后来者查阅。</p>
<h3 id="1-Resize到固定尺寸大小"><a href="#1-Resize到固定尺寸大小" class="headerlink" title="1. Resize到固定尺寸大小"></a>1. Resize到固定尺寸大小</h3><p>这个操作相对比较简单，直接使用<code>tf.image.resize_images()</code>即可，如下：</p>
<p>image = tf.image.resize_images(image, [new_height, new_width])</p>
<p>但是这样的操作会破坏图片的原始比例，可能会影响后续的处理结果。所以，通常情况下，我们一般不再直接使用这种操作。</p>
<h3 id="2-通过padding操作把原始图片resize到一个固定大小，同时保持图片的原始比例"><a href="#2-通过padding操作把原始图片resize到一个固定大小，同时保持图片的原始比例" class="headerlink" title="2. 通过padding操作把原始图片resize到一个固定大小，同时保持图片的原始比例"></a>2. 通过padding操作把原始图片resize到一个固定大小，同时保持图片的原始比例</h3><p>在保持图片的原始比例的同时，把原始图片resize到一个固定的大小，考虑到神经网络的输入要求，这个固定的大小通常是一个正方形。我们自然会想到将较长的边resize到这个固定大小，而将较小边的空余地方padding上值为0的像素，TensorFlow提供了这样的函数<a href="https://www.tensorflow.org/api_docs/python/tf/image/pad_to_bounding_box" target="_blank" rel="noopener">tf.image.pad_to_bounding_box</a>可以直接进行操作。 该函数的介绍是这样的：</p>
<p>tf.image.pad_to_bounding_box(<br>    image,<br>    offset_height,<br>    offset_width,<br>    target_height,<br>    target_width<br>)</p>
<p>可以看到，它需要5个参数，即原始图片tensor，在高和宽方向上各需要padding多少像素，以及padding之后的图片的目标高和宽。很显然，需要目标高宽大于原始图片的高和宽。 至于我们需要的操作，将原始图片resize到一个固定大小，则可以首先将图片resize到最大边与padding之后的目标大小相等，然后在小边上padding像素。 以一副高宽为300×500的图片resize到224×224的图片为例，如下： 首先将原始的300*500的image resize到[300*(224/500)]*224，即134*224，然后宽边不作处理，在高边的两侧需要各padding (224-134)/2和224-134-(224-134)/2，即45和45像素。 因此，函数tf.image.pad_to_bounding_box的5个参数如下：</p>
<ul>
<li>image为resize过后的大边为224的image；</li>
<li>offset_height为45，offset_width为0；</li>
<li>target_height和target_width都是224.</li>
</ul>
<p>如此，即可将原来高宽为300*500的图片resize到224*224的图片，且保持了图片原来的原始比例。</p>
<h3 id="3-Resize图片时，padding不同的像素值"><a href="#3-Resize图片时，padding不同的像素值" class="headerlink" title="3. Resize图片时，padding不同的像素值"></a>3. Resize图片时，padding不同的像素值</h3><p>如2中操作，在resize时的padding操作只能padding像素值为0的内容，但有时候我们想在图片的周围padding上ImageNet的Mean值，即[123.68, 116.779, 103.939]。这时候该怎么处理呢？ 我在GitHub上TensorFlow的Repository里提了一个<a href="https://github.com/tensorflow/tensorflow/issues/19193" target="_blank" rel="noopener">Feature Request Issue</a>，但是并没有获得好的反馈，也没有人进行开发。因此，目前还是只能自己修改添加。具体我是这样处理的：</p>
<h4 id="3-1-修改函数tf-image-pad-to-bounding-box，在里面加入一个constant-values参数，指定padding的数值；"><a href="#3-1-修改函数tf-image-pad-to-bounding-box，在里面加入一个constant-values参数，指定padding的数值；" class="headerlink" title="3.1 修改函数tf.image.pad_to_bounding_box，在里面加入一个constant_values参数，指定padding的数值；"></a>3.1 修改函数tf.image.pad_to_bounding_box，在里面加入一个constant_values参数，指定padding的数值；</h4><p>具体可以参考这个函数的实现，该函数里是在这行代码进行的padding：</p>
<p>padded = array_ops.pad(image, paddings)</p>
<p>我们打开该pad函数，其定义如下：</p>
<p>def pad(tensor, paddings, mode=”CONSTANT”, name=None, constant_values=0)</p>
<p>可以看到，修改上面代码，传入一个constant_values即可：</p>
<p>padded = array_ops.pad(image, paddings, constant_values=constant_values)</p>
<h4 id="3-2-为tf-image-pad-to-bounding-box传入constant-values值"><a href="#3-2-为tf-image-pad-to-bounding-box传入constant-values值" class="headerlink" title="3.2 为tf.image.pad_to_bounding_box传入constant_values值"></a>3.2 为tf.image.pad_to_bounding_box传入constant_values值</h4><p>需要注意的是，该函数修改后还是只能针对一个tensor padding同样的值，所以，如果我们想为不同的通道传入不同的值，还是需要一些trick：</p>
<ul>
<li>将一个image Tensor的三个通道slice出来成三个Tensor</li>
<li>分别对三个Tensor使用不同的值进行padding</li>
<li>将三个padding过后的Tensor重新concat到一起</li>
</ul>
<p>代码片段如下：</p>
<p>image_slices = []<br>for i in range(3):<br>    img = image[…, i, tf.newaxis]<br>    img = tf.image.pad_to_bounding_box(img, offset_height, offset_width,<br>                                       image_size, image_size, constant_values=MEAN[i])<br>    image_slices.append(img)<br>image = tf.concat(image_slices, 2)</p>
<h3 id="代码参考"><a href="#代码参考" class="headerlink" title="代码参考"></a>代码参考</h3><p>与本文相关的代码请参考：<a href="https://github.com/Kongsea/Resize-to-fixed-size-keeping-aspect-ratio" target="_blank" rel="noopener">Resize-to-fixed-size-keeping-aspect-ratio</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/04/weighted-object-detection-using-detectron/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/04/weighted-object-detection-using-detectron/" itemprop="url">通过加权解决Detectron训练object detection模型时的类间不平衡问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-04T20:45:58+08:00">
                2018-05-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用深度学习解决分类问题时，类间不平衡是一个常见的问题，我们也有很多常用的方法去解决这一问题。比如，对类别少的样本进行augment，或者重采样；对类别多的样本进行降采样；根据不同类别的样本数目对损失函数进行加权；或者简单粗暴地对较少的样本在数据集内进行复制；等等。 不过这些方法中，考虑到数据对深度学习的重要性，一般不会使用对数据进行降采样的方法；而augment、重采样以及复制数据，都需要对数据进行直接操作，也并不如修改损失函数进行加权的方法简单优雅。这种对损失函数进行加权的方法如下：</p>
<p>Loss = class_of_less_samples_loss * weights + class_of_more_samples_loss</p>
<p>不过，这种方法虽然简单优雅，对分类问题进行处理也简单方便，但如果是目标检测问题，则可能需要考虑更多东西；如果我们使用的是像Detectron这样包装严密的框架，处理起来可能难上加难。本文，我们就以Detectron里的Faster-RCNN来详细描述一下这一问题，以期提供一些经验参考。</p>
<h3 id="1-Faster-RCNN的loss"><a href="#1-Faster-RCNN的loss" class="headerlink" title="1.Faster-RCNN的loss"></a>1.Faster-RCNN的loss</h3><p>Faster-RCNN一共有4个loss，包括前面的RPN的classification loss和regression loss，以及后面的classification loss和regression loss。但RPN部分除了前景、背景的分类之外，一般不按具体的类别进行区分，所以，我们无法对这一部分进行加权。而且由于这一部分仅仅进行region proposal，与具体的类别关系不大，所以对其进行加权也意义不大。至于后面的Fast-RCNN部分，对边框进行回归的regression loss同样意义不大，所以我们进行加权，主要加权的部分就是这里的classification loss。 当然，除了对不同类别的分类进行加权之外，我们还考虑到这样一个情况，即有时候分类错误的损失影响较大，而只要检测出来，检测到的物体的边框并不一定要求特别精确，所以，通常会针对具体问题，对这个地方进行修改，改变两者的权重占比。</p>
<h3 id="2-Detectron的caffe2"><a href="#2-Detectron的caffe2" class="headerlink" title="2.Detectron的caffe2"></a>2.Detectron的caffe2</h3><p>caffe2是Facebook推出的主要面向产品部署等场景的深度学习框架，而针对于研究等方向，Facebook则推出的是简单易用的PyTorch；因此，caffe2过于关注了性能，其易用性并不好。所以，基于caffe2的Detectron用起来虽然训练速度很好，但想对其进行修改，却并非易事。 与caffe类似，caffe2也是使用Blob来管理数据的。所以，在caffe2中，传进传出的参数，通常只有一个名字，这让很多人摸不着头脑，也使得调试十分困难。 在caffe2中，新建一个Blob可以使用如下代码：</p>
<p>import numpy as np<br>from caffe2.python import core, workspace</p>
<p>labels_array = np.array(…)<br>labels = workspace.FeedBlob(‘labels’, labels_array)</p>
<p>这样，我们就新建了一个名为labels的Blob。 然后，我们可以在其他地方使用，使用时，直接把数据fetch出来即可：</p>
<p>from caffe2.python import core, workspace</p>
<p>labels = workspace.FetchBlob(‘labels’)<br># labels = workspace.FetchBlob(core.ScopedName(‘labels’))</p>
<p>如果labels是一个全局名，可以直接进行fetch；如果它是定义在一个scope里面的Blob，则需要首先对名字进行一下处理，否则可能提示找不到相应的Blob。 在Detectron中，有很多使用Blob的例子，如<a href="https://github.com/facebookresearch/Detectron/blob/master/tests/test_loader.py#L48" target="_blank" rel="noopener">这个</a>，以及<a href="https://github.com/facebookresearch/Detectron/blob/master/tests/test_loader.py#L79" target="_blank" rel="noopener">这个</a>。</p>
<h3 id="3-修改Detectron中Faster-RCNN的loss-cls和loss-bbox的比例"><a href="#3-修改Detectron中Faster-RCNN的loss-cls和loss-bbox的比例" class="headerlink" title="3.修改Detectron中Faster-RCNN的loss_cls和loss_bbox的比例"></a>3.修改Detectron中Faster-RCNN的loss_cls和loss_bbox的比例</h3><p>Faster-RCNN中，建立这两个loss是在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/modeling/fast_rcnn_heads.py#L70" target="_blank" rel="noopener">fast_rcnn_heads.py中的add_fast_rcnn_losses函数</a>，该函数中，分别使用model.net.SoftmaxWithLoss和model.net.SmoothL1Loss得到了相应的loss值。而SoftmaxWithLoss这个函数中的参数scale=model.GetLossScale()，即是控制比例的地方。函数中，这个比例根据使用GPU的数量进行调节，我们为了最小修改原来的内容，直接在这个函数后面加上修改的比例即可，比如，将其修改为：scale=model.GetLossScale()*2，即将loss_cls的比重扩大到原来的2倍。如果与此同时，对SmoothL1Loss的scale不作调整，则相当于将classification的loss权重提高到了regression loss的2倍。</p>
<h3 id="4-根据不同类别的Object，修改其在loss中的权重"><a href="#4-根据不同类别的Object，修改其在loss中的权重" class="headerlink" title="4.根据不同类别的Object，修改其在loss中的权重"></a>4.根据不同类别的Object，修改其在loss中的权重</h3><p>我们首先来看3中的loss_cls，这个loss是使用model.net.SoftmaxWithLoss来生成的。查阅<a href="https://github.com/caffe2/caffe2/blob/master/caffe2/operators/softmax_with_loss_op.cc#L50" target="_blank" rel="noopener">这个函数的文档</a>，可以看到，其输入值，除了logits、labels，还可以输入一个Blob作为weights。这就是我们需要修改的地方。 在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/minibatch.py#L64" target="_blank" rel="noopener">minibatch.py里的get_minibatch函数</a>中，可以看到，读取RPN的Blob是通过roi_data.rpn.add_rpn_blobs来完成的，而读取Fast-RCNN的数据，则是通过roi_data.fast_rcnn.add_fast_rcnn_blobs来完成的。因此，如上分析，我们需要修改进行加权的操作，是需要在后面这个函数中进行的。 在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/fast_rcnn.py#L108" target="_blank" rel="noopener">fast_rcnn.py里的add_fast_rcnn_blobs函数</a>中，进行了数据的读取操作，具体来说，读取操作是在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/fast_rcnn.py#L112" target="_blank" rel="noopener">函数中的_sample_rois(entry, im_scales[im_i], im_i)</a>来完成的。 我们跳转到<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/fast_rcnn.py#L132" target="_blank" rel="noopener">_sample_rois这个函数</a>里，我们找到<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/fast_rcnn.py#L170" target="_blank" rel="noopener">labels生成的地方</a>，然后根据labels，来生成我们需要的weights即可。如下：</p>
<p># Add weights<br>weights = (np.where(sampled_labels==2, 5, 1)).astype(np.float32)</p>
<p>在这里，我们将label为2的类别的权重设置为了5，而其他类别保持了不变。然后，在下面要反悔的blob_dict里添加上这个weights即可，如下：</p>
<p>blob_dict = dict(<br>      labels_int32=sampled_labels.astype(np.int32, copy=False),<br>      weights=weights,<br>      rois=sampled_rois,<br>      bbox_targets=bbox_targets,<br>      bbox_inside_weights=bbox_inside_weights,<br>      bbox_outside_weights=bbox_outside_weights<br>)</p>
<p>不过，在此之前，需要添加一个名为weights的Blob。 在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/roi_data/fast_rcnn.py#L40" target="_blank" rel="noopener">fast_rcnn.py里的get_fast_rcnn_blob_names函数</a>中，直接添加即可，如下：</p>
<p># Add weights<br>if is_training:<br>  blob_names += [‘weights’]</p>
<p>如此，即可为指定类别的Object进行加权，从而突出其在object detection时的重要性，对其进行特殊对待。</p>
<h3 id="5-对某些图片进行加权"><a href="#5-对某些图片进行加权" class="headerlink" title="5.对某些图片进行加权"></a>5.对某些图片进行加权</h3><p>有时候，我们不仅想要对这些类别进行加权，我们还希望对出现了这个类别的图片进行加权，这时候应该这么处理呢？ 这个比较简单，直接在最开始读数据roidb时进行处理即可。在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/utils/train.py#L180" target="_blank" rel="noopener">train.py里的combined_roidb_for_training函数</a>，是建立数据roidb用于训练的。该函数定义在<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/datasets/roidb.py#L36" target="_blank" rel="noopener">roidb.py</a>文件中，在该函数中，我们可以看到一个<a href="https://github.com/facebookresearch/Detectron/blob/master/lib/datasets/roidb.py#L65" target="_blank" rel="noopener">过滤roidb中数据的函数</a>，该函数用来“Remove roidb entries that have no usable RoIs based on config settings”。我们可以仿照这个函数，构建一个augment_roidb_for_training函数。如下：</p>
<p>def augment_for_training(roidb):<br>  “””Augment roidb entries that have some RoIs.<br>  “””<br>  num = len(roidb)<br>  auged_roidb = []<br>  for db in roidb:<br>    if np.sum(db[‘gt_classes’]==2)&gt;=1:<br>      auged_roidb.append(db)<br>      auged_roidb.append(db)<br>    else:<br>      auged_roidb.append(db)<br>  num_after = len(auged_roidb)<br>  logger.info(‘Augment {} roidb entries: {} -&gt; {}’.<br>              format(num_after - num, num, num_after))<br>  return auged_roidb</p>
<p>这样，我们将含有label为2的图片复制成了两份，即相当于对其完成了加权。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/18/faster-rcnn-coupled-with-fpn-in-tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/18/faster-rcnn-coupled-with-fpn-in-tensorflow/" itemprop="url">使用TensorFlow训练综合FPN和Faster-RCNN的目标检测模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-18T10:10:52+08:00">
                2018-03-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Faster-RCNN已经推出几年了，尽管其后有相当多另辟蹊径的方法，比如SSD和YOLO，等等，但目前其仍是目标检测领域精度最优的模型之一。而最近推出的FPN模型，更是融合神经网络中不同层之间的特征，对目标检测的大小物体兼顾，从而达到了最好的检测结果。比如，<a href="http://cocodataset.org/#detections-leaderboard" target="_blank" rel="noopener">COCO目标检测的Leaderboard</a>前几名目前无不是基于FPN进行的各种改进。 我想着将FPN与Faster-RCNN结合使用，GitHub上目前一共有3个类似的Repositories： <a href="https://github.com/yangxue0827/FPN_Tensorflow" target="_blank" rel="noopener">FPN_Tensorflow</a>、<a href="https://github.com/wuzheng-sjtu/FastFPN" target="_blank" rel="noopener">FastFPN</a>和<a href="https://github.com/xmyqsh/FPN" target="_blank" rel="noopener">FPN</a>。 我将它们分别clone了下来，并试着调试使用，最后发现最好用的是FPN_Tensorflow，而其他两个，在调试和使用中，要么碰到各种问题，提issue未获解决；要么虽然跑通了，但无法测试模型的效果，也没有评估模型mAP的程序。 下面，我就将我在调试和使用这个FPN_Tensorflow Repository的过程中总结的经验简单记录一下，以备以后使用需要。需要特别说明的是，虽然作者说“not suitable for multi-target detection tasks”，但经我实验，对于multi-target的检测任务，其效果也是可以的。 此外，我将自己修改和订制过的Repository上传到了我的GitHub上，<a href="https://github.com/Kongsea/FPN_TensorFlow" target="_blank" rel="noopener">可以点此访问参考</a>。</p>
<h3 id="1-从GitHub上将项目clone下来"><a href="#1-从GitHub上将项目clone下来" class="headerlink" title="1. 从GitHub上将项目clone下来"></a>1. 从GitHub上将项目clone下来</h3><h3 id="2-根据数据集的名字修改配置文件"><a href="#2-根据数据集的名字修改配置文件" class="headerlink" title="2. 根据数据集的名字修改配置文件"></a>2. 根据数据集的名字修改配置文件</h3><p>修改libs/configs/cfgs.py文件中的DATASET_NAME，将其修改为自己的数据集的名字，如：</p>
<p>DATASET_NAME = ‘animals’</p>
<h3 id="3-将数据集放到项目的data文件夹下"><a href="#3-将数据集放到项目的data文件夹下" class="headerlink" title="3. 将数据集放到项目的data文件夹下"></a>3. 将数据集放到项目的data文件夹下</h3><p>比如，我们放置的数据集名为animals，然后将数据放到animals文件夹下</p>
<h4 id="3-1-原始图片放到data-animals-JPEGImages文件夹下"><a href="#3-1-原始图片放到data-animals-JPEGImages文件夹下" class="headerlink" title="3.1 原始图片放到data/animals/JPEGImages文件夹下"></a>3.1 原始图片放到data/animals/JPEGImages文件夹下</h4><h4 id="3-2-原始标注信息放到data-animals-annotations文件夹下"><a href="#3-2-原始标注信息放到data-animals-annotations文件夹下" class="headerlink" title="3.2 原始标注信息放到data/animals/annotations文件夹下"></a>3.2 原始标注信息放到data/animals/annotations文件夹下</h4><h4 id="3-3-在data-animals文件夹下生成一个classes-txt的文件，将所有的类别（除background）逐行放到该文件里"><a href="#3-3-在data-animals文件夹下生成一个classes-txt的文件，将所有的类别（除background）逐行放到该文件里" class="headerlink" title="3.3 在data/animals文件夹下生成一个classes.txt的文件，将所有的类别（除background）逐行放到该文件里"></a>3.3 在data/animals文件夹下生成一个classes.txt的文件，将所有的类别（除background）逐行放到该文件里</h4><p>在我的Repository里，运行项目根目录下的gen_classes.py即可在data/animals文件夹下生成一个classes.txt文件。</p>
<h4 id="3-4-将标注信息转化为PASCAL-VOC格式的xml标注文件"><a href="#3-4-将标注信息转化为PASCAL-VOC格式的xml标注文件" class="headerlink" title="3.4 将标注信息转化为PASCAL VOC格式的xml标注文件"></a>3.4 将标注信息转化为PASCAL VOC格式的xml标注文件</h4><p>在我的Repository里，运行根目录下的convert_txt2xml.py即可将我自己的TXT格式的标注信息转化为xml格式的文件，并放置在data/animals/Annotations文件夹里。你可以参考我的程序，根据自己的原始标注信息，将其转化为PASCAL VOC格式的xml文件。</p>
<h4 id="3-5-运行data-io-convert-data-to-tfrecord-py将准备好的数据转化为TensorFlow的tfrecords格式的文件"><a href="#3-5-运行data-io-convert-data-to-tfrecord-py将准备好的数据转化为TensorFlow的tfrecords格式的文件" class="headerlink" title="3.5 运行data/io/convert_data_to_tfrecord.py将准备好的数据转化为TensorFlow的tfrecords格式的文件"></a>3.5 运行data/io/convert_data_to_tfrecord.py将准备好的数据转化为TensorFlow的tfrecords格式的文件</h4><p>这些转化后的文件，位于data/tfrecords文件夹下，名为{dataset}_train.tfrecord和{dataset}_test.tfrecord。 转化好之后，可以在项目根目录下运行“./scripts/test.sh 0 output/res101_trained_weights/v1_animals/animals_model.ckpt 20”来测试验证生成的数据是否正确。运行后，会在tools/test_result文件夹下生成一些样例图片，查看检查即可。需要注意的是，这里需要指定一个模型，如果没有模型，可以略过此步，直接进行下面的训练，训练出模型之后，再回头通过这一步验证数据集的正确性。</p>
<h3 id="4-修改其他参数"><a href="#4-修改其他参数" class="headerlink" title="4. 修改其他参数"></a>4. 修改其他参数</h3><p>准备好数据之后，还需要修改一些其他参数，如下：</p>
<h4 id="4-1-修改libs-configs-cfgs-py中的参数"><a href="#4-1-修改libs-configs-cfgs-py中的参数" class="headerlink" title="4.1 修改libs/configs/cfgs.py中的参数"></a>4.1 修改libs/configs/cfgs.py中的参数</h4><p>我们在上面2中已经修改了这个配置文件中DATASET_NAME这个参数了，下面还可以修改这个文件中的其他参数，如：</p>
<p>NET_NAME = ‘resnet_v1_101’<br>DATASET_NAME = ‘animals’<br>VERSION = ‘v1_{}’.format(DATASET_NAME)<br>ANCHOR_SCALES = [0.5, 1., 2.]<br>ANCHOR_RATIOS = [0.5, 1, 2] # height to width<br>SCALE_FACTORS = [10., 5., 1., 0.5]</p>
<p>此外，如CLASS_NUM也需要根据数据集进行针对性地修改。这里的CLASS_NUM不包含background，可以直接将其修改为前面3.3中生成的classes.txt中的class的数量即可。</p>
<h4 id="4-2-修改configs-config-py中的参数"><a href="#4-2-修改configs-config-py中的参数" class="headerlink" title="4.2 修改configs/config_*.py中的参数"></a>4.2 修改configs/config_*.py中的参数</h4><p>这里修改的配置文件位于configs文件夹下，具体修改哪个文件，根据4.1中的NET_NAME来确定，如上，我们选择的网络为resnet_v1_101，所以我们需要修改的配置文件是configs/config_res101.py，可以修改的参数主要有：</p>
<p>pretrained_model_path # to use a pretrained model<br>batch_size</p>
<h4 id="4-3-在程序中添加数据集的名字"><a href="#4-3-在程序中添加数据集的名字" class="headerlink" title="4.3 在程序中添加数据集的名字"></a>4.3 在程序中添加数据集的名字</h4><p>具体来说，是在文件data/io/read_tfrecord.py中的next_batch函数的第一行添加数据集的名字，如下：</p>
<p>if dataset_name not in [‘cooler’, ‘animals’, ‘pascal’, ‘coco’, ‘layer’, ‘shelf’]:<br>  raise ValueError(‘dataSet name must be in cooler, animals, pascal, coco, layer or shelf’)</p>
<h4 id="4-4-在程序中添加label映射NAME-LABEL-MAP"><a href="#4-4-在程序中添加label映射NAME-LABEL-MAP" class="headerlink" title="4.4 在程序中添加label映射NAME_LABEL_MAP"></a>4.4 在程序中添加label映射NAME_LABEL_MAP</h4><p>具体来说，是在libs/label_name_dict/label_dict.py文件中添加，如下：</p>
<p>elif cfgs.DATASET_NAME == ‘animals’:<br>  NAME_LABEL_MAP = {}<br>  NAME_LABEL_MAP[‘back_ground’] = 0<br>  with open(‘data/{}/classes.txt’.format(cfgs.DATASET_NAME)) as f:<br>    lines = [line.strip() for line in f.readlines()]<br>  for i, line in enumerate(lines, 1):<br>    NAME_LABEL_MAP[line] = i<br>elif cfgs.DATASET_NAME == ‘layer’:<br>  NAME_LABEL_MAP = {<br>      ‘back_ground’: 0,<br>      “layer”: 1<br>  }</p>
<p>如果类别较少，如layer这种Dataset，可以直接手动添加；如果类别较多，推荐采用上面的animals这种通过文件的添加方式进行添加。</p>
<h3 id="5-运行scripts-train-sh训练网络"><a href="#5-运行scripts-train-sh训练网络" class="headerlink" title="5. 运行scripts/train.sh训练网络"></a>5. 运行scripts/train.sh训练网络</h3><p>在项目根目录运行如下所示的脚本进行训练：</p>
<p>cd $ FPN_Tensorflow<br># ./scripts/train.sh GPU DATASET<br>./scripts/train.sh 0 animals</p>
<p>如上，运行train.sh脚本时，后面跟两个参数，第一个指定使用第几块GPU，第二个指定使用的数据集。</p>
<h3 id="6-评测训练得到的网络的效果"><a href="#6-评测训练得到的网络的效果" class="headerlink" title="6.评测训练得到的网络的效果"></a>6.评测训练得到的网络的效果</h3><p>在项目根目录下运行以下所示脚本进行评测：</p>
<p>cd $ FPN_Tensorflow<br># ./scripts/test.sh GPU MODEL_PATH IMG_NUM<br>./scripts/test.sh 0 output/res101_trained_weights/v1_animals/animals_model.ckpt 20<br># ./scripts/eval.sh GPU MODEL_PATH IMG_NUM<br>./scripts/eval.sh 0 output/res101_trained_weights/v1_animals/animals_model.ckpt 20<br># ./scripts/demo.sh GPU MODEL_PATH<br>./scripts/demo.sh 0 output/res101_trained_weights/v1_animals/animals_model.ckpt<br># ./scripts/inference.sh GPU MODEL_PATH<br>./scripts/inference.sh 0 output/res101_trained_weights/v1_animals/animals_model.ckpt</p>
<p>如上，需要注意的是这些脚本的几个参数： GPU指定使用的哪块GPU； MODEL_PATH指定评测哪个模型，为模型的路径； IMG_NUM指定测试或验证多少张图片。</p>
<h3 id="7-可能遇到的一些错误"><a href="#7-可能遇到的一些错误" class="headerlink" title="7. 可能遇到的一些错误"></a>7. 可能遇到的一些错误</h3><h4 id="7-1-LossTensor-is-inf-or-nan-Tensor-had-NaN-values"><a href="#7-1-LossTensor-is-inf-or-nan-Tensor-had-NaN-values" class="headerlink" title="7.1 LossTensor is inf or nan : Tensor had NaN values"></a>7.1 LossTensor is inf or nan : Tensor had NaN values</h4><p>错误如下：</p>
<p>InvalidArgumentError (see above for traceback): LossTensor is inf or nan : Tensor had NaN values<br>   [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=”LossTensor is inf or nan”, _device=”/job:localhost/replica:0/task:0/device:GPU:0”](control_dependency)]]<br>   [[Node: gradients/rpn_net/concat_grad/Squeeze_3/_1493 = _Recv[client_terminated=false, recv_device=”/job:localhost/replica:0/task:0/device:CPU:0”, send_device=”/job:localhost/replica:0/task:0/device:GPU:0”, send_device_incarnation=1, tensor_name=”edge_8085_gradients/rpn_net/concat_grad/Squeeze_3”, tensor_type=DT_INT64, _device=”/job:localhost/replica:0/task:0/device:CPU:0”]()]]</p>
<p>可能是因为数据自身的原因，比如标注的坐标超出了图片的范围，如标注坐标小于0，或者大于图像的高或者宽，等等。</p>
<h4 id="7-2-signed-integer-is-less-than-minimum"><a href="#7-2-signed-integer-is-less-than-minimum" class="headerlink" title="7.2 signed integer is less than minimum"></a>7.2 signed integer is less than minimum</h4><p>错误如下：</p>
<p>UnknownError (see above for traceback): exceptions.OverflowError: signed integer is less than minimum<br>   [[Node: fast_rcnn_loss/PyFunc_1 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT, DT_INT32], Tout=[DT_UINT8], token=”pyfunc_7”, _device=”/job:localhost/replica:0/task:0/device:CPU:0”](rpn_losses/Squeeze/_1579, fast_rcnn_loss/mul_1/_1759, fast_rcnn_loss/strided_slice_1/_1761)]]<br>   [[Node: draw_proposals/Reshape_2/tensor/_1825 = _Recv[client_terminated=false, recv_device=”/job:localhost/replica:0/task:0/device:GPU:0”, send_device=”/job:localhost/replica:0/task:0/device:CPU:0”, send_device_incarnation=1, tensor_name=”edge_3802_draw_proposals/Reshape_2/tensor”, tensor_type=DT_UINT8, _device=”/job:localhost/replica:0/task:0/device:GPU:0”]()]]</p>
<p>原因可能与7.1类似。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/10/train-object-detection-model-using-detectron/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/10/train-object-detection-model-using-detectron/" itemprop="url">以Detectron用自己的数据集训练目标检测模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-10T20:58:32+08:00">
                2018-03-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>前一段时间Facebook开源了其用于目标检测、识别和分割的框架——Detectron，该框架携带了这一领域里的经典和最新算法，诸如Faster-RCNN、RetinaNet、Mask-RCNN，等等。这绝对是造福这一领域从业者和研究者的事情，当然，也成了这一领域绕不开的东西了。 Detectron自带了可以基于Pascal VOC以及COCO数据集的模型训练方法。不过Detectron十分易用，即使训练自己的数据集，操作起来也十分简单方便。本文对此进行一下简单介绍和总结。</p>
<h3 id="1-安装Detectron以及Caffe2"><a href="#1-安装Detectron以及Caffe2" class="headerlink" title="1.安装Detectron以及Caffe2"></a>1.安装Detectron以及Caffe2</h3><p>Detectron是基于Caffe2开发的，因此，首先需要安装Caffe2，然后从GitHub上clone下来Detectron进行安装，<a href="https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md" target="_blank" rel="noopener">Detectron的安装说明文档</a>十分详细且易于操作，直接参考进行安装即可。</p>
<h4 id="1-1-Caffe2"><a href="#1-1-Caffe2" class="headerlink" title="1.1 Caffe2"></a>1.1 Caffe2</h4><p>安装完成Caffe2后，在Terminal里运行下面代码，检查是否安装成功：</p>
<p># To check if Caffe2 build was successful<br>python -c ‘from caffe2.python import core’ 2&gt;/dev/null &amp;&amp; echo “Success” || echo “Failure”</p>
<p># To check if Caffe2 GPU build was successful<br># This must print a number &gt; 0 in order to use Detectron<br>python -c ‘from caffe2.python import workspace; print(workspace.NumCudaDevices())’</p>
<h4 id="1-2-安装一些依赖及可能用到的COCO-API"><a href="#1-2-安装一些依赖及可能用到的COCO-API" class="headerlink" title="1.2 安装一些依赖及可能用到的COCO API"></a>1.2 安装一些依赖及可能用到的COCO API</h4><h4 id="1-3-安装Detectron"><a href="#1-3-安装Detectron" class="headerlink" title="1.3 安装Detectron"></a>1.3 安装Detectron</h4><p>从GitHub上将其clone下来，编译：</p>
<p>cd $DETECTRON/lib &amp;&amp; make</p>
<p>然后检查是否安装成功：</p>
<p>python $DETECTRON/tests/test_spatial_narrow_as_op.py</p>
<h3 id="2-配置自己的数据集"><a href="#2-配置自己的数据集" class="headerlink" title="2.配置自己的数据集"></a>2.配置自己的数据集</h3><p>因为自定义自己的数据集比较繁琐，所以推荐使用Detectron自带的COCO数据集名称，并将自己的数据集转化为COCO数据集的格式，具体配置如下。</p>
<h4 id="2-1-放置数据"><a href="#2-1-放置数据" class="headerlink" title="2.1 放置数据"></a>2.1 放置数据</h4><p>将数据放置到<code>$DETECTRON/lib/datasets/data</code>下面，如animals数据集，并在其中以如下结构放置数据集的数据： ├── annos ├── annotations ├── classes.txt └── images 其中，annos放置你的数据集的原始的标注文件，可能是txt，或者csv格式；classes.txt放置你标注的类别名称，每行一个类别，不含背景；images放置数据集的原始图像文件。annotations预备放置与COCO数据集格式的标注文件。下面需要将我们自己的标注文件生成COCO格式的标注文件。</p>
<h4 id="2-2-转化标注格式"><a href="#2-2-转化标注格式" class="headerlink" title="2.2 转化标注格式"></a>2.2 转化标注格式</h4><p>因为我们自己的数据集的标注文件是txt格式，每行一个标注，形似如下：</p>
<p>老虎 25 36 128 159<br>猫 25 36 128 159<br>狮子 25 36 128 159</p>
<p>所以，我们需要将这种格式的标注转换为COCO格式。程序如下：</p>
<p>#!/usr/bin/python<br># -<em>- coding: utf-8 -</em>-<br>import json<br>import os<br>import sys</p>
<p>import cv2</p>
<p>if len(sys.argv) &lt; 3:<br>  print “Usage: python convert_to_detectron_json.py root_path phase split”<br>  print “For example: python convert_to_detectron_json.py data train 100200”<br>  exit(1)</p>
<p>root_path = sys.argv[1]<br>phase = sys.argv[2]<br>split = int(sys.argv[3])</p>
<p>dataset = {<br>    ‘licenses’: [],<br>    ‘info’: {},<br>    ‘categories’: [],<br>    ‘images’: [],<br>    ‘annotations’: []<br>}</p>
<p>with open(os.path.join(root_path, ‘classes.txt’)) as f:<br>  classes = f.read().strip().split()</p>
<p>for i, cls in enumerate(classes, 1):<br>  dataset[‘categories’].append({<br>      ‘id’: i,<br>      ‘name’: cls,<br>      ‘supercategory’: ‘beverage’<br>  })</p>
<p>def get_category_id(cls):<br>  for category in dataset[‘categories’]:<br>    if category[‘name’] == cls:<br>      return category[‘id’]</p>
<p>_indexes = sorted([f.split(‘.’)[0] for f in os.listdir(os.path.join(root_path, ‘annos’))])<br>if phase == ‘train’:<br>  indexes = [line for line in _indexes if int(line) &gt; split]<br>else:<br>  indexes = [line for line in _indexes if int(line) &lt;= split]</p>
<p>j = 1<br>for index in indexes:<br>  im = cv2.imread(os.path.join(root_path, ‘images/‘) + index + ‘.jpg’)<br>  height, width, _ = im.shape<br>  dataset[‘images’].append({<br>      ‘coco_url’: ‘’,<br>      ‘date_captured’: ‘’,<br>      ‘file_name’: index + ‘.jpg’,<br>      ‘flickr_url’: ‘’,<br>      ‘id’: int(index),<br>      ‘license’: 0,<br>      ‘width’: width,<br>      ‘height’: height<br>  })</p>
<p>  anno_file = os.path.join(root_path, ‘annos/‘) + index + ‘.txt’<br>  with open(anno_file) as f:<br>    lines = [line for line in f.readlines() if line.strip()]</p>
<pre><code>for i, line in enumerate(lines):
  parts = line.strip().split()
  cls = parts\[0\]
  x1 = int(parts\[1\])
  y1 = int(parts\[2\])
  x2 = int(parts\[3\])
  y2 = int(parts\[4\])
  width = max(0, x2 - x1)
  height = max(0, y2 - y1)
  dataset\[&apos;annotations&apos;\].append({
      &apos;area&apos;: width * height,
      &apos;bbox&apos;: \[x1, y1, width, height\],
      &apos;category\_id&apos;: get\_category_id(cls),
      &apos;id&apos;: j,
      &apos;image_id&apos;: int(index),
      &apos;iscrowd&apos;: 0,
      &apos;segmentation&apos;: \[\]
  })
  j += 1
</code></pre><p>folder = os.path.join(root_path, ‘annotations’)<br>if not os.path.exists(folder):<br>  os.makedirs(folder)<br>json_name = os.path.join(root_path, ‘annotations/{}.json’.format(phase))<br>with open(json_name, ‘w’) as f:<br>  json.dump(dataset, f)</p>
<p>可以<a href="https://github.com/Kongsea/yueye/blob/master/convert_to_detectron_json.py" target="_blank" rel="noopener">点击这里</a>去GitHub查看源代码。你可以根据自己数据集的格式，改写程序，将标注转化为COCO格式。</p>
<h4 id="2-3-设置指向自己的数据集"><a href="#2-3-设置指向自己的数据集" class="headerlink" title="2.3 设置指向自己的数据集"></a>2.3 设置指向自己的数据集</h4><p>修改$DETECTRON/lib/datasets/dataset_catalog.py文件，将其中描述COCO数据集的两个部分修改为如下所示：</p>
<p>‘coco_2014_train’: {<br>        IM_DIR:<br>            _DATA_DIR + ‘/animals/images’,<br>        ANN_FN:<br>            _DATA_DIR + ‘/animals/annotations/train.json’<br>},<br>‘coco_2014_val’: {<br>        IM_DIR:<br>            _DATA_DIR + ‘/animals/images’,<br>        ANN_FN:<br>            _DATA_DIR + ‘/animals/annotations/val.json’<br>},</p>
<p>其中，_DATA_DIR是Detectron的数据的根目录，即$DETECTRON/lib/datasets/data，其余顾名思义。</p>
<h3 id="3-新建配置文件，开始训练"><a href="#3-新建配置文件，开始训练" class="headerlink" title="3.新建配置文件，开始训练"></a>3.新建配置文件，开始训练</h3><p>到这里，设置好了相应的数据集，下面需要指定训练模型使用该数据集，Detectron是通过配置文件来指定的。</p>
<h4 id="3-1-新建配置文件"><a href="#3-1-新建配置文件" class="headerlink" title="3.1 新建配置文件"></a>3.1 新建配置文件</h4><p>可以直接复制Detectron自带的配置文件，并稍作修改即可，在$DETECTRON根目录下打开Terminal复制：</p>
<p>cd configs<br>mkdir animals<br>cp getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml animals/animals_1gpu_e2e_faster_rcnn_R-50-FPN.yaml</p>
<p>然后打开animals_1gpu_e2e_faster_rcnn_R-50-FPN.yaml进行编辑：</p>
<p>MODEL:<br>  TYPE: generalized_rcnn<br>  CONV_BODY: FPN.add_fpn_ResNet50_conv5_body<br>  NUM_CLASSES: 5<br>  FASTER_RCNN: True<br>NUM_GPUS: 1<br>SOLVER:<br>  WEIGHT_DECAY: 0.0001<br>  LR_POLICY: steps_with_decay<br>  BASE_LR: 0.0025<br>  GAMMA: 0.1<br>  MAX_ITER: 60000<br>  STEPS: [0, 30000, 40000]</p>
<h1 id="Equivalent-schedules-with…"><a href="#Equivalent-schedules-with…" class="headerlink" title="Equivalent schedules with…"></a>Equivalent schedules with…</h1><h1 id="1-GPU"><a href="#1-GPU" class="headerlink" title="1 GPU:"></a>1 GPU:</h1><h1 id="BASE-LR-0-0025"><a href="#BASE-LR-0-0025" class="headerlink" title="BASE_LR: 0.0025"></a>BASE_LR: 0.0025</h1><h1 id="MAX-ITER-60000"><a href="#MAX-ITER-60000" class="headerlink" title="MAX_ITER: 60000"></a>MAX_ITER: 60000</h1><h1 id="STEPS-0-30000-40000"><a href="#STEPS-0-30000-40000" class="headerlink" title="STEPS: [0, 30000, 40000]"></a>STEPS: [0, 30000, 40000]</h1><h1 id="2-GPUs"><a href="#2-GPUs" class="headerlink" title="2 GPUs:"></a>2 GPUs:</h1><h1 id="BASE-LR-0-005"><a href="#BASE-LR-0-005" class="headerlink" title="BASE_LR: 0.005"></a>BASE_LR: 0.005</h1><h1 id="MAX-ITER-30000"><a href="#MAX-ITER-30000" class="headerlink" title="MAX_ITER: 30000"></a>MAX_ITER: 30000</h1><h1 id="STEPS-0-15000-20000"><a href="#STEPS-0-15000-20000" class="headerlink" title="STEPS: [0, 15000, 20000]"></a>STEPS: [0, 15000, 20000]</h1><h1 id="4-GPUs"><a href="#4-GPUs" class="headerlink" title="4 GPUs:"></a>4 GPUs:</h1><h1 id="BASE-LR-0-01"><a href="#BASE-LR-0-01" class="headerlink" title="BASE_LR: 0.01"></a>BASE_LR: 0.01</h1><h1 id="MAX-ITER-15000"><a href="#MAX-ITER-15000" class="headerlink" title="MAX_ITER: 15000"></a>MAX_ITER: 15000</h1><h1 id="STEPS-0-7500-10000"><a href="#STEPS-0-7500-10000" class="headerlink" title="STEPS: [0, 7500, 10000]"></a>STEPS: [0, 7500, 10000]</h1><h1 id="8-GPUs"><a href="#8-GPUs" class="headerlink" title="8 GPUs:"></a>8 GPUs:</h1><h1 id="BASE-LR-0-02"><a href="#BASE-LR-0-02" class="headerlink" title="BASE_LR: 0.02"></a>BASE_LR: 0.02</h1><h1 id="MAX-ITER-7500"><a href="#MAX-ITER-7500" class="headerlink" title="MAX_ITER: 7500"></a>MAX_ITER: 7500</h1><h1 id="STEPS-0-3750-5000"><a href="#STEPS-0-3750-5000" class="headerlink" title="STEPS: [0, 3750, 5000]"></a>STEPS: [0, 3750, 5000]</h1><p>RPN:<br>  ASPECT_RATIOS: (0.5, 1, 2)<br>FPN:<br>  FPN_ON: True<br>  MULTILEVEL_ROIS: True<br>  MULTILEVEL_RPN: True<br>  RPN_ASPECT_RATIOS: (0.5, 1, 2)<br>FAST_RCNN:<br>  ROI_BOX_HEAD: fast_rcnn_heads.add_roi_2mlp_head<br>  ROI_XFORM_METHOD: RoIAlign<br>  ROI_XFORM_RESOLUTION: 7<br>  ROI_XFORM_SAMPLING_RATIO: 2<br>TRAIN:<br>  WEIGHTS: pretrained_models/ImageNetPretrained/MSRA/R-50.pkl<br>  DATASETS: (‘coco_2014_train’,)<br>  SCALES: (500,)<br>  SNAPSHOT_ITERS: 5000<br>  MAX_SIZE: 833<br>  BATCH_SIZE_PER_IM: 256<br>  RPN_PRE_NMS_TOP_N: 2000  # Per FPN level<br>TEST:<br>  DATASETS: (‘coco_2014_val’,)<br>  SCALES: (500,)<br>  MAX_SIZE: 833<br>  NMS: 0.5<br>  RPN_PRE_NMS_TOP_N: 1000  # Per FPN level<br>  RPN_POST_NMS_TOP_N: 1000<br>  FORCE_JSON_DATASET_EVAL: True<br>OUTPUT_DIR: .</p>
<p>主要修改以下内容： 1.MODEL里的NUM_CLASSES，根据自己的数据集进行修改，包括背景。 2.TRAIN和TEST里的DATASETS，设置为如上所示，因为我们已经修改了dataset_catalog.py中的相应内容并指向了我们的数据集，所以我们可以直接使用这两个数据集的名字。 3.TRAIN里的WEIGHTS是一个预训练的模型，如果本地有，修改指向它即可。 4.关于NUM_GPUS，这个需要与SOLVER里面的学习率等一干参数进行联动设置。</p>
<h4 id="3-2-开始训练"><a href="#3-2-开始训练" class="headerlink" title="3.2 开始训练"></a>3.2 开始训练</h4><p>设置好数据集和配置文件，即可开始训练模型了。回到$DETECTRON根目录，打开Terminal运行如下命令即可开始训练：</p>
<p>python tools/train_net.py –cfg configs/animals/animals_1gpu_e2e_faster_rcnn_R-50-FPN.yaml OUTPUT_DIR detectron-output</p>
<p>这样即可使用Detectron基于自己的数据集训练各种模型了。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.com/facebookresearch/Detectron/blob/master/lib/datasets/data/README.md" target="_blank" rel="noopener">Detectron官方设置数据集说明</a>。 <a href="https://github.com/facebookresearch/Detectron/blob/master/GETTING_STARTED.md" target="_blank" rel="noopener">Detectron官方GETTING STARTED</a>。 <a href="https://github.com/royhuang9/Detectron/blob/master/README.md" target="_blank" rel="noopener">使用Detectron训练PASCAL VOC数据集</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/13/debug-py-faster-rcnn-and-caffe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/13/debug-py-faster-rcnn-and-caffe/" itemprop="url">编译安装py-faster-rcnn踩坑记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-13T11:06:31+08:00">
                2018-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>因为之前一直用TensorFlow，所以在做目标检测用Faster-RCNN时，使用的一直是GitHub上的基于TensorFlow的Faster-RCNN的Repository，改来改去，进行的各种操作。但那么几个Repositories大同小异，基本上都是基于<a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="noopener">RBG大神的py-faster-rcnn</a>做的。因此，溯本追源，尽管其是基于caffe做出来的，但如果不好好研究一下py-faster-rcnn这个Repository的话，也似乎有点舍本逐末了。 可caffe的坑实在太多，这也是大家现在普遍都在转新的框架的原因之一吧；我一直讳谈、讳用caffe相关的东西，也大体上有这样一个原因。 果不其然，安装调试py-faster-rcnn时，就碰到了许多关于caffe的坑；当然，也有一些py-faster-rcnn自身的坑，不过多是因为该项目年久失修，解决起来并不算难。</p>
<h3 id="1-caffe的问题"><a href="#1-caffe的问题" class="headerlink" title="1. caffe的问题"></a>1. caffe的问题</h3><h4 id="1-1-hdf5-h相关问题"><a href="#1-1-hdf5-h相关问题" class="headerlink" title="1.1 hdf5.h相关问题"></a>1.1 hdf5.h相关问题</h4><p>如fatal error: hdf5.h: No such file or directory，等，可如此修改Makefile.config： 将INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include修改为： INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial 将Makefile（注意不是Makefile.config）中相应部分，由 LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5 修改为： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial</p>
<h4 id="1-2-OpenCV相关问题"><a href="#1-2-OpenCV相关问题" class="headerlink" title="1.2 OpenCV相关问题"></a>1.2 OpenCV相关问题</h4><p>出现如：.build_release/lib/libcaffe.so: undefined reference to cv::imread… 或者.build_release/lib/libcaffe.so: undefined reference to `cv::imdecode…的错误，这是由OpenCV造成的，在Makefile中对相应部分做修改： 将其修改为： LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial matio opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs 即在最后添加：opencv_imgcodecs</p>
<h4 id="1-3-numpy相关问题"><a href="#1-3-numpy相关问题" class="headerlink" title="1.3 numpy相关问题"></a>1.3 numpy相关问题</h4><p>关于numpy的相关问题主要在py-faster-rcnn自身，但是caffe中也会碰到，如下： fatal error: numpy/arrayobject.h: No such file or directory 将Makefile.config中相应位置加一个local： 即，将原来的： PYTHON_INCLUDE := /usr/include/python2.7 \ /usr/lib/python2.7/dist-packages/numpy/core/include 修改为： PYTHON_INCLUDE := /usr/include/python2.7 \ /usr/local/lib/python2.7/dist-packages/numpy/core/include</p>
<h4 id="1-4-cannot-find-lopencv-imgcodecs"><a href="#1-4-cannot-find-lopencv-imgcodecs" class="headerlink" title="1.4 cannot find -lopencv_imgcodecs"></a>1.4 cannot find -lopencv_imgcodecs</h4><p>遇到如下错误： /usr/bin/ld: cannot find -lopencv_imgcodecs collect2: error: ld returned 1 exit status Makefile:<strong><em>: recipe for target ‘.build_release/lib/libcaffe.so.1.0.0-rc3’ failed make: </em></strong> [.build_release/lib/libcaffe.so.1.0.0-rc3] Error 1 这个错误比较罕见，在搜索引擎里也难以搜到，主要是因为搜索时，搜索引擎会将-lopencv_imgcodecs理解为不含lopencv_imgcodecs，所以将关键词屏蔽了。 仔细搜索发现，这个错误是因为系统里安装的OpenCV是2.x，而你在Makefile.config里却将USE_OPENCV := 3给取消注释了，所以导致其去找了OpenCV 3.x的lopencv_imgcodecs相关函数，却不能找到。所以将这句保持原来的样子不变（即注释掉），编译即可。</p>
<h4 id="1-5-caffe新功能"><a href="#1-5-caffe新功能" class="headerlink" title="1.5 caffe新功能"></a>1.5 caffe新功能</h4><p>py-faster-rcnn自带的caffe版本比较陈旧，有一些新的功能不能支持；而盲目的clone新版本的caffe使用，却可能会带来其他问题。 比如对1080P和cuDNN v5的支持，如<a href="https://github.com/rbgirshick/py-faster-rcnn/issues/237" target="_blank" rel="noopener">这个issue</a>中提及的那样，需要首先将最新版的caffe merge来：</p>
<p>cd caffe-fast-rcnn<br>git remote add caffe <a href="https://github.com/BVLC/caffe.git" target="_blank" rel="noopener">https://github.com/BVLC/caffe.git</a><br>git fetch caffe<br>git merge -X theirs caffe/master</p>
<p>然后修改：将include/caffe/layers/python_layer.hpp中的self_.attr(“phase”) = static_cast<int>(this-&gt;phase_);一句删除。</int></p>
<h3 id="2-py-faster-rcnn自身的问题"><a href="#2-py-faster-rcnn自身的问题" class="headerlink" title="2. py-faster-rcnn自身的问题"></a>2. py-faster-rcnn自身的问题</h3><h4 id="2-1-numpy导致的问题"><a href="#2-1-numpy导致的问题" class="headerlink" title="2.1 numpy导致的问题"></a>2.1 numpy导致的问题</h4><p>py-faster-rcnn自身的问题不多，主要是在其推出后，numpy升级了一下版本，从原来的1.11逐步升级到现在的1.14，然后不再支持浮点数作索引，所以一些使用浮点数作索引的地方就报错了。 提前将索引进行一下转换即可，可以使用int，或者.astype(np.int)等等。</p>
<h4 id="2-2-BB的问题"><a href="#2-2-BB的问题" class="headerlink" title="2.2 BB的问题"></a>2.2 BB的问题</h4><p>在voc_eval.py文件中，对检测结果进行了一个eval，但如果没有检测到内容的话，这个BB将会为空，因此，下面的BB = BB[sorted_ind, :]会出错，所以我们需要对BB进行一个判断，如下：</p>
<p>if BB.shape[0] &gt; 0:</p>
<p>只有在BB不为空的时候，进行相应处理。 当然，下面的</p>
<p>nd = len(image_ids)<br>tp = np.zeros(nd)<br>fp = np.zeros(nd)</p>
<p>也需要提前放到if之前。</p>
<h3 id="3-其他参考"><a href="#3-其他参考" class="headerlink" title="3. 其他参考"></a>3. 其他参考</h3><p>3.1 使用py-faster-rcnn训练自己的数据集时，<a href="https://github.com/deboc/py-faster-rcnn/tree/master/help" target="_blank" rel="noopener">这篇资料</a>可作参考。 3.2 这里有一系列关于py-faster-rcnn的<a href="http://blog.csdn.net/sunyiyou9/article/details/52207486" target="_blank" rel="noopener">代码解读</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/10/plot-chinese-characters-on-images/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/10/plot-chinese-characters-on-images/" itemprop="url">使用Python在图像上标注汉字</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-10T17:46:03+08:00">
                2018-02-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>如果我们的classes是汉字，在使用Faster-RCNN检测完成后，需要将其标注到图片上查看效果时，可能会面临一些问题。一是Python2的编码问题比较混乱，可能带来错误；第二个是Python2的默认字体不支持中文，即使打印到图片上，也可能显示的是乱码。 因此，在将汉字classes打印到图片上的过程中，需要进行一些特殊的处理。我们在这里进行一下记录以便备忘。 在Python里，对图片进行处理时，我们通常使用Matplotlib或PIL，因此，这里我们也对这两个方法分别加以介绍。</p>
<h3 id="1-使用Matplotlib"><a href="#1-使用Matplotlib" class="headerlink" title="1.使用Matplotlib"></a>1.使用Matplotlib</h3><p>使用Matplotlib处理起来比较简单方便，只需要进行一个设置，如下：</p>
<p>import matplotlib as mpl</p>
<p>mpl.rcParams[‘font.sans-serif’] = [‘SimHei’]</p>
<p>通过这种方式，将Matplotlib的默认字体设置为一种支持中文的字体即可，这里我们将其设置为“SimHei”，即黑体。 然后按照正常的方式，将classes绘制到图片上即可。 还需要注意的是，将classes绘制到图片上时，如下：</p>
<p>class_name = ‘老虎’<br>ax.text(bbox[0], bbox[1] - 2,<br>        u’{:s} {:.3f}’.format(class_name.decode(‘utf-8’), score))</p>
<p>我们需要将type为str的class_namedecode，并将其转换为unicode类型。当然，直接这样转换也可以：</p>
<p>unicode(class_name.decode(‘utf-8’)) + str(score)</p>
<p>详细的代码可以参阅<a href="https://github.com/Kongsea/yueye/blob/master/plot_chinese_matplotlib.py" target="_blank" rel="noopener">GitHub上的程序</a>。</p>
<h3 id="2-使用PIL"><a href="#2-使用PIL" class="headerlink" title="2.使用PIL"></a>2.使用PIL</h3><p>PIL也是Python里用于处理图片的一个常用工具，因此我们对使用PIL绘制汉字也进行一下总结和介绍。 相对来说，使用PIL绘制汉字稍微复杂一下。它也是首先需要对字体进行设置，如下：</p>
<p>import PIL.ImageFont as ImageFont</p>
<p>try:<br>  font = ImageFont.truetype(‘wqy-microhei.ttc’, 14)<br>except IOError:<br>  font = ImageFont.load_default()</p>
<p>这里，我把字体设置为了“wqy-microhei.ttc”，即文泉驿，你也可以设置为其他字体，只是需要是系统已经安装了的字体即可。 随后的处理就是正常情况了，绘制矩形框，绘制汉字，显示图片即可。而这里绘制汉字，直接使用utf-8编码即可，无需转化为Unicode，如下：</p>
<p>draw.text(<br>    (left, top-14),<br>    class_name.decode(‘utf-8’),<br>    fill=’black’,<br>    font=font)</p>
<p>更详细的代码可以参阅<a href="https://github.com/Kongsea/yueye/blob/master/plot_chinese_PIL_ImageDraw.py" target="_blank" rel="noopener">GitHub上的程序</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/07/convert-your-own-custom-dataset-to-pascal-voc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/07/convert-your-own-custom-dataset-to-pascal-voc/" itemprop="url">将自己的数据集转换成pascal_voc格式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-07T21:37:08+08:00">
                2018-02-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在RCNN、Fast-RCNN、Faster-RCNN等一系列深度学习用于目标检测（Object Detection）的众多开源实现里，基本上都是基于pascal_voc的数据集进行处理的，给出了使用该数据集进行训练和测试的完整代码。 诚然，我们可以基于这些开源项目来进行定制，并在自己的数据集跑起来。但这样需要修改大量代码，稍有不慎可能带来很多注意不到的错误。而从另一个方面入手，如果将我们的数据集按照pascal_voc的格式进行转换，然后进行训练，则会简单地多，只需要修改很少量的代码即可。不过这样一来，我们的任务则集中在了将数据集转换为pascal_voc的格式上。</p>
<h3 id="1-pascal-voc数据集介绍"><a href="#1-pascal-voc数据集介绍" class="headerlink" title="1.pascal_voc数据集介绍"></a>1.pascal_voc数据集介绍</h3><p>在将我们的数据集转换为pascal_voc的数据格式时，需要注意一下数据放置的路径和文件夹层级结构，原始的pascal_voc结构格式大致如下： VOCdevkit2007 ├── results │   └── VOC2007 │   └── Main ├── VOC2007 │   ├── Annotations │   ├── ImageSets │   │   └── Main │   └── JPEGImages └── VOCcode 该数据集表示的是pascal_voc中voc_2007_*的数据集，其中VOCcode中是一些用于数据处理的MATLAB函数文件； VOC2007放置数据集中的各文件，主要包括JPEGImages中是图片，为jpg格式的文件，如果是其他格式，则需要对代码稍作修改；Annotation是中是标注数据，为xml格式的文件，为下面介绍的结构，如果是其他格式或者标注类型，则需要对代码作相应修改。 JPEGImages和Annotation是这两个文件夹中的各数据一一对应，均是6位数据的文件名；而ImageSets文件夹下面Main文件中则是一系列如train.txt、trainval.txt、val.txt或者test.txt的文件，这些文件实现了对数据集的划分，即将数据集划分为训练集、验证集、测试集等等。文件内容为相应的文件名，但不包含后缀。我们可以据这几个文件来选择数据集的名字，可以设置为如voc_2007_train、voc_2007_trainval或者voc_2007_test等等。</p>
<h3 id="2-pascal-voc数据集的xml标注文件"><a href="#2-pascal-voc数据集的xml标注文件" class="headerlink" title="2.pascal_voc数据集的xml标注文件"></a>2.pascal_voc数据集的xml标注文件</h3><p>对Images进行的操作十分简单，无需赘言，其着重需要注意的地方是将Annotations转换为pascal_voc的xml格式。这是pascal_voc的一个xml格式的annotation文件样例：</p>
<annotation><br>  <folder>VOC2007</folder><br>  <filename>000002.jpg</filename><br>  <size><br>    <width>335</width><br>    <height>500</height><br>    <depth>3</depth><br>  </size><br>  <object><br>    <name>cat</name><br>    <pose>Unspecified</pose><br>    <truncated>0</truncated><br>    <difficult>0</difficult><br>    <bndbox><br>      <xmin>139</xmin><br>      <ymin>200</ymin><br>      <xmax>207</xmax><br>      <ymax>301</ymax><br>    </bndbox><br>  </object><br></annotation>

<p>这里，需要注意的信息主要有：<folder>、<filename>、<size>，这些属于某张图片的基本信息;而后在<object>里记录的则是标注信息，主要有<name>和<bndbox>两个，name是标注的物体的class name，bndbox是该物体的bounding box信息。 我们只需要按照这个格式，并以其为模板，将自己的数据集转换过来即可。需要特别注意的是，有些图片上可能被标注的物体不只有一个。 转换程序的核心代码如下：</bndbox></name></object></size></filename></folder></p>
<p>tree = ET.parse(template_file)<br>root = tree.getroot()</p>
<p># filename<br>root.find(‘filename’).text = image_file<br># size<br>sz = root.find(‘size’)<br>im = cv2.imread(image_dir + image_file)<br>sz.find(‘height’).text = str(im.shape[0])<br>sz.find(‘width’).text = str(im.shape[1])<br>sz.find(‘depth’).text = str(im.shape[2])</p>
<p># object<br>obj_ori = root.find(‘object’)<br>root.remove(obj_ori)</p>
<p>for al in anno_lines:<br>  bb_info = al.split()</p>
<p>  x_1 = int(bb_info[1])<br>  y_1 = int(bb_info[2])<br>  x_2 = int(bb_info[3])<br>  y_2 = int(bb_info[4])</p>
<p>  obj = copy.deepcopy(obj_ori)</p>
<p>  obj.find(‘name’).text = bb_info[0].decode(‘utf-8’)<br>  bb = obj.find(‘bndbox’)<br>  bb.find(‘xmin’).text = str(x_1)<br>  bb.find(‘ymin’).text = str(y_1)<br>  bb.find(‘xmax’).text = str(x_2)<br>  bb.find(‘ymax’).text = str(y_2)</p>
<p>  root.append(obj)</p>
<p>xml_file = image_file.replace(‘jpg’, ‘xml’)</p>
<p>tree.write(target_dir + xml_file, encoding=’utf-8’, xml_declaration=True)</p>
<p>首先读入模板xml文件，然后对filename和size进行处理；接着从模板文件中取出object块，以其为模板，根据标注对象的数量来建立一个或多个object，并将其append到xml模板文件中，最后将处理完毕的文件写入到硬盘上。需要注意的是<code>bb_info[0].decode(&#39;utf-8&#39;)</code>这句，这是因为class name是汉字，而且使用的是Python2，所以需要进行一下处理。 详细的代码请参阅<a href="https://github.com/Kongsea/yueye/blob/master/convert_to_pascal_voc.py" target="_blank" rel="noopener">GitHub上的文件</a>。</p>
<h3 id="3-根据数据集修改代码"><a href="#3-根据数据集修改代码" class="headerlink" title="3.根据数据集修改代码"></a>3.根据数据集修改代码</h3><p>虽然GitHub上开源的各Faster-RCNN的Repositories已经考虑的相当周到，很多可以直接拿来使用，但如果在自己的数据集上进行训练，还是需要对其进行稍作改动的。而如果自己的数据与pascal_voc的差异较大的话，可能还需要作更多一些的修改。修改一般集中在一下几个方面</p>
<h4 id="3-1-修改数据集"><a href="#3-1-修改数据集" class="headerlink" title="3.1 修改数据集"></a>3.1 修改数据集</h4><p>如前述，首先把自己的数据集构建成pascal_voc的数据集格式；但这还不够，有时候可能我们并不像原始的pascal_voc那样，训练验证测试三个数据集都很完备。如果我们只有训练集和验证集，怎么办呢？我们可以将其看为训练集和测试集。训练集使用形如“voc_2007_train”的名字，验证集（或所谓测试集）使用“voc_2007_test”的名字。其对应于1中所述的Main文件夹下的train.txt和test.txt两个文件。然后在repository的lib/datasets文件夹下的factory.py文件中可以找到生成数据集的地方，如下：</p>
<p># Set up voc_<year><em><split><br>for year in [‘2007’, ‘2012’]:<br>  for split in [‘train’, ‘val’, ‘trainval’, ‘test’]:<br>    name = ‘voc</split></em>{}<em>{}’.format(year, split)<br>    \</em>_sets[name] = (lambda split=split, year=year: pascal_voc(split, year))</year></p>
<p>此处，可以看到对应于voc_2007_train和voc_2007_test的分别是函数pascal_voc(‘train’, ‘2007’)、pascal_voc(‘test’, ‘2007’)。这是使用pascal_voc类的构造函数。在构造函数里，我们需要进行下一步的修改。</p>
<h4 id="3-2-修改classes"><a href="#3-2-修改classes" class="headerlink" title="3.2 修改classes"></a>3.2 修改classes</h4><p>在pascal_voc类的构造函数里，我们可以看到有这样一行代码：</p>
<p>self._classes = (‘__background__’,  # always index 0<br>                        ‘aeroplane’, ‘bicycle’, ‘bird’, ‘boat’,<br>                        ‘bottle’, ‘bus’, ‘car’, ‘cat’, ‘chair’,<br>                        ‘cow’, ‘diningtable’, ‘dog’, ‘horse’,<br>                        ‘motorbike’, ‘person’, ‘pottedplant’,<br>                        ‘sheep’, ‘sofa’, ‘train’, ‘tvmonitor’)</p>
<p>其用以构建数据集的classes。但如果我们使用自己的数据集，显然需要对此进行针对性的修改。</p>
<h4 id="3-3-其他修改"><a href="#3-3-其他修改" class="headerlink" title="3.3 其他修改"></a>3.3 其他修改</h4><p>在这个构建函数里，可以看到，还可以对关于数据集的其他许多地方进行修改，包括数据集的名称、数据集的路径以及图片的后缀，等等。而如果你不嫌麻烦，或者想直接使用自己的数据集的原始标注而不想将标注文件转换为pascal_voc的xml文件的话，也可以修改这个pascal_voc类的成员函数——gt_roidb，进而修改它调用的私有成员函数_load_pascal_annotation，修改annotations的加载。</p>
<h4 id="3-4-如果classes使用了汉字"><a href="#3-4-如果classes使用了汉字" class="headerlink" title="3.4 如果classes使用了汉字"></a>3.4 如果classes使用了汉字</h4><p>如果classes使用了汉字，而你恰好使用的还是Python2，则在_load_pascal_annotaion中加载Annotation时，可能需要注意汉字的影响。即该函数中的这句代码：</p>
<p>cls = self._class_to_ind[obj.find(‘name’).text.lower().strip()]</p>
<p>如果不进行修改，其可能会提示KeyError，这是编码方式导致的。我将其修改为了：</p>
<p>cls = self._class_to_ind[obj.find(‘name’).text.strip().encode(‘utf-8’)]</p>
<p>当然，你可能需要根据自己的特殊情况对其进行修改。 此外，如果classes使用了汉字，可能还需要注意其他地方，即所有对classes进行了操作的地方，或者进行比较的地方，不然极可能得不到正确的结果。如：</p>
<p>R = [obj for obj in recs[imagename] if obj[‘name’] == classname]</p>
<p>需要修改为：</p>
<p>R = [obj for obj in recs[imagename] if obj[‘name’] == classname.decode(‘utf-8’)]</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>关于Faster-RCNN的模型训练时的数据的解释请参阅：<a href="http://blog.csdn.net/sloanqin/article/details/51537713" target="_blank" rel="noopener">faster-rcnn 之训练数据是如何准备的</a> xml文件的转换的有关内容请参阅这篇高质量的博客：<a href="http://imzack.me/post/training-rcnn-using-my-own-dataset.html" target="_blank" rel="noopener">使用自己的数据集训练 R-CNN</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/30/memo-of-tensorflow-dataset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/30/memo-of-tensorflow-dataset/" itemprop="url">使用TensorFlow Dataset读取数据备忘</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-30T17:51:56+08:00">
                2018-01-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在使用TensorFlow构建模型并进行训练时，如何读取数据并将数据恰当地送进模型，是一个首先需要考虑的问题。以往通常所用的方法无外乎以下几种： 1.建立placeholder，然后使用feed_dict将数据feed进placeholder进行使用。使用这种方法十分灵活，可以一下子将所有数据读入内存，然后分batch进行feed；也可以建立一个Python的generator，一个batch一个batch的将数据读入，并将其feed进placeholder。这种方法很直观，用起来也比较方便灵活，但是这种方法的效率较低，难以满足高速计算的需求。 2.使用TensorFlow的QueueRunner，通过一系列的Tensor操作，将磁盘上的数据分批次读入并送入模型进行使用。这种方法效率很高，但因为其牵涉到Tensor操作，不够直观，也不方便调试，所有有时候会显得比较困难。使用这种方法时，常用的一些操作包括tf.TextLineReader，tf.FixedLengthRecordReader以及tf.decode_raw等等。如果需要循环，条件操作，还需要使用TensorFlow的tf.while_loop，tf.case等操作，更是难上加难。 因此，在这种情况下，TensorFlow在后续的更新中，自1.x版本开始，逐步开发引入了tf.data.Dataset模块，使其数据读入的操作变得更为方便，而支持多线程（进程）的操作，也在效率上获得了一定程度的提高。本文就将使用tf.data.Dataset过程中的一些经验进行总结记录，以便备忘。 如我们所知，在使用TensorFlow建立模型进行训练的时候，可以很容易生成这样的文件，来表示数据：</p>
<p>data/01.jpg,猫<br>data/05.jpg,狗<br>data/03.jpg,猫<br>data/04.jpg,狗<br>data/06.jpg,狗<br>data/02.jpg,猫</p>
<p>这种数据格式可以很方便地进行各种操作，比如划分数据集、shuffle等等。所以我们就以将这样的数据通过tf.data.Dataset读入进行训练为例，来讲述其用法。 具体来说，使用tf.data.Dataset读取数据，本文讲述这样三种方法：</p>
<h3 id="1-首先将数据读入内存，然后使用tf-data-Dataset构建数据集"><a href="#1-首先将数据读入内存，然后使用tf-data-Dataset构建数据集" class="headerlink" title="1.首先将数据读入内存，然后使用tf.data.Dataset构建数据集"></a>1.首先将数据读入内存，然后使用tf.data.Dataset构建数据集</h3><p>具体来说，因为tf.data.Dataset.from_tensor_slices()函数会对tensor和numpy array的处理一视同仁，所以该函数既可以使用tensor参数，也可以直接使用numpy array作参数，使用numpy array作参数，即是第1种方法。 如下所示：</p>
<p>images = …<br>labels = …<br>data = tf.data.Dataset.from_tensor_slices((images, labels))<br>data = data.batch(batch_size)<br>iterator = tf.data.Iterator.from_structure(data.output_types,<br>                                           data.output_shapes)<br>init_op = iterator.make_initializer(data)<br>with tf.Session() as sess:<br>  sess.run(init_op)<br>  try:<br>    images, labels = iterator.get_next()<br>  except tf.errors.OutOfRangeError:<br>    sess.run(init_op)</p>
<p>第1~2行，首先，将数据images、labels读入内存； 第3~4行，使用读入内存的数据images、labels构建Dataset，并设置Dataset的batch大小； 第5行，基于此前构建的Dataset的数据类型和结构，构建一个iterator； 第6行，基于此前构建的Dataset构建一个初始化op。 随后的操作，即是在TensorFlow的session里，首先进行初始化操作，然后即可通过iterator的函数逐批获得数据，并进行使用了。 需要注意的是，iterator中的元素取完之后，会抛出OutOfRangeError异常，TensorFlow没有对这个异常进行处理，我们需要对其进行捕捉和处理。 本方法详细代码<a href="https://github.com/Kongsea/yueye/blob/master/tf_dataset_samples/ds_numpy.py" target="_blank" rel="noopener">可参阅这里</a>。</p>
<h3 id="2-使用tf-data-Dataset包装一个generator读入数据"><a href="#2-使用tf-data-Dataset包装一个generator读入数据" class="headerlink" title="2.使用tf.data.Dataset包装一个generator读入数据"></a>2.使用tf.data.Dataset包装一个generator读入数据</h3><p>1中方法虽然简单，但其将数据一次读入，在面对大数据集时会束手无策。因此，我们可以建立一个读入数据的generator，然后使用tf.data.Dataset对其进行包装转换，即可实现逐batch读入数据的目的。如下：</p>
<p>def gen():<br>  with open(‘train.csv’) as f:<br>    lines = [line.strip().split(‘,’) for line in f.readlines()]<br>  index = 0<br>  while True:<br>    image = cv2.imread(lines[index][0])<br>    image = cv2.resize(image, (224, 224))<br>    label = lines[index][1]<br>    yield (image, label)<br>    index += 1<br>    if index == len(lines):<br>      index = 0</p>
<p>batch_size = 2<br>data = tf.data.Dataset.from_generator(gen, (tf.float32, tf.int32),<br>                                      (tf.TensorShape([224, 224, 3]), tf.TensorShape([])))<br>data = data.batch(batch_size)<br>iter = data.make_one_shot_iterator()<br>with tf.Session() as sess:<br>  images, labels = iter.get_next()</p>
<p>如上，首先构建一个generator：gen，然后使用tf.data.Dataset的from_generator函数，通过指定数据类型，数据的shape等参数，构建一个Dataset，当然，随后也要指定一下batch_size，最后使用make_one_shot_iterator()函数，构建一个iterator。 然后其使用方法即与前述相同了，不过需要说明的是，这里是通过一个永无尽头的generator构建的Dataset，所以其可以一直取数据，而不会出现1中所述的OutOfRange的问题。 本方法详细代码<a href="https://github.com/Kongsea/yueye/blob/master/tf_dataset_samples/ds_generator.py" target="_blank" rel="noopener">可参阅这里</a>。</p>
<h3 id="3-基于Tensor操作构建Dataset"><a href="#3-基于Tensor操作构建Dataset" class="headerlink" title="3.基于Tensor操作构建Dataset"></a>3.基于Tensor操作构建Dataset</h3><p>前述两种方法，1中需要将数据一次全部读入内存，2中使用generator逐batch读入数据，虽然内存占用得到了控制，但是其效率仍然不高，读取速度较慢。在第3种方法里，我们通过TensorFlow提供的tensor操作来读取数据，并基于此，构建Dataset。 示例的代码片段如下：</p>
<p>def _parse_function(filename, label):<br>  image_string = tf.read_file(filename)<br>  image_decoded = tf.image.decode_jpeg(image_string, channels=3)<br>  image = tf.cast(image_decoded, tf.float32)<br>  image = tf.image.resize_images(image, [224, 224])<br>  return image, filename, label</p>
<p>images = tf.constant(image_names)<br>labels = tf.constant(labels)<br>images = tf.random_shuffle(images, seed=0)<br>labels = tf.random_shuffle(labels, seed=0)<br>data = tf.data.Dataset.from_tensor_slices((images, labels))</p>
<p>data = data.map(_parse_function, num_parallel_calls=4)<br>data = data.prefetch(buffer_size=batch_size * 10)<br>data = data.batch(batch_size)</p>
<p>iterator = tf.data.Iterator.from_structure(data.output_types,<br>                                           data.output_shapes)</p>
<p>init_op = iterator.make_initializer(data)<br>with tf.Session() as sess:<br>  sess.run(init_op)<br>  try:<br>    images, filenames, labels = iterator.get_next()<br>  except tf.errors.OutOfRangeError:<br>    sess.run(init_op)</p>
<p>首先读入image names以及相应的labels，然后通过tf.constant构建constant Tensor：images, labels，并可选择地对其进行shuffle。 接着使用tf.data.Dataset.from_tensor_slices()函数基于images和labels构建Dataset。 然后使用map函数将函数应用到该Dataset上，本例中，将解析图像的函数_parse_function应用到Dataset上，还指定了多线程并行操作的线程数。 随后指定prefetch的buffer_size，以及batch的大小。 最后，基于构建的Dataset建立iterator，并定义iterator的初始化操作op，然后就可以按照正常的方式进行使用了。 需要注意的是，本方法构建的Dataset也会有OutOfRange的异常出现，需要恰当地进行捕捉并处理。 本方法详细代码<a href="https://github.com/Kongsea/yueye/blob/master/tf_dataset_samples/ds_tensor.py" target="_blank" rel="noopener">可参阅这里</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/29/visualize-the-output-of-intermediate-layers-of-a-keras-model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/29/visualize-the-output-of-intermediate-layers-of-a-keras-model/" itemprop="url">Visualize the outputs of intermediate layers of a Keras model</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-12-29T20:46:03+08:00">
                2017-12-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>训练完成各种CNN的模型之后，为了查看模型的效果以及模型到底能够从原始图像中抽取什么样的特征，有时候我们需要模型的中间输出结果，并将其图示出来进行查看。在TensorFlow中这很简单，直接将中间层的Tensor作为输出，以图像数据通过feed_dict进行输入，然后使用tf.Session将Tensor的结果run出来图示即可。但Keras对模型的输入输出以及训练过程整合的比较严密，耦合度较高，尤其是使用Keras自带的一些经典模型进行fine-tuning时，想要得到其中间层的结果并将其输出并不容易。 下面我们就来看一下，如何取出Keras模型中的某一层输出，并图示出来进行查看。</p>
<h3 id="1-使用layer别名得到输出并图示"><a href="#1-使用layer别名得到输出并图示" class="headerlink" title="1.使用layer别名得到输出并图示"></a>1.使用layer别名得到输出并图示</h3><p>这种方式需要原始模型支持，或者重新对原始模型进行一下定义和复现。 首先我们来看用来得到模型输出数据的函数，如下：</p>
<p>def layer_to_visualize(layer):<br>  inputs = [K.learning_phase()] + model.inputs</p>
<p>  _convout1_f = K.function(inputs, [layer.output])</p>
<p>  def convout1_f(X):</p>
<pre><code># The \[0\] is to disable the training phase flag
return \_convout1\_f(\[0\] + \[X\])
</code></pre><p>  convolutions = convout1_f(img_to_visualize)<br>  convolutions = np.squeeze(convolutions)</p>
<p>  print (‘Shape of conv:’, convolutions.shape)</p>
<p>  num = convolutions.shape[2]<br>  n = int(np.ceil(np.sqrt(num)))</p>
<h1 id="Visualization-of-each-filter-of-the-layer"><a href="#Visualization-of-each-filter-of-the-layer" class="headerlink" title="Visualization of each filter of the layer"></a>Visualization of each filter of the layer</h1><p>  fig = plt.figure()<br>  for i in range(num):<br>    ax = fig.add_subplot(n, n, i + 1)<br>    ax.imshow(convolutions[…, i], cmap=’gray’)<br>  plt.show()<br>  fig.close()</p>
<p>如上的函数，输入为某一层的名字，即可将该层的所有feature maps进行输出。 下面我们进行详细分析：</p>
<ol>
<li>第2行使用模型的状态（训练还是验证），以及模型的输入（即接下来输入的图像数据所对应的Tensor），构建一个输入；</li>
<li>第4行使用backend的function构建一个函数，用于对输入进行处理；</li>
<li>第6~8行对第4行中构建的函数进行封装；需要注意的是，这里将函数输入中的模型状态直接设置为了0，对应模型处于验证测试状态；</li>
<li>第10、11行以图像img_to_visualize作为输入，直接得到卷积过后的feature maps，并将得到的numpy array进行squeeze，以便后续处理；</li>
<li>随后即是将得到的feature maps进行可视化显示了：比如4中得到的对应于feature maps的numpy array的shape为[32, 32, 128]，则可以在12×12的grid上进行显示，每个块显示一个32×32的feature map。</li>
</ol>
<p>定义好了这个函数，在使用时，需要定义的模型进行匹配，如果模型不匹配，则需要重新进行一下定义。模型的定义需要满足如下条件：</p>
<p>model = Sequential()<br>model.add(Conv2D(64, kernel_size=(3, 3), padding=’same’, input_shape=(64, 64, 1)))<br>conv1out = Activation(‘relu’)<br>model.add(conv1out)<br>model.add(MaxPool2D())<br>model.add(Conv2D(128, kernel_size=(3, 3), padding=’same’), activation=’relu’)</p>
<p>…model definition…</p>
<p>model.compile(optimizer=’…’, loss=’…’, metrics=[‘…’])</p>
<p>model.load_weights(‘*.h5’)</p>
<p>即为需要visualize的层定义一个名字，如conv1out；然后即可使用上面定义的函数<code>layer_to_visualize</code>进行可视化：layer_to_visualize(conv1out)。在最后可视化之前，注意到函数中用到的model需要提前定义好，而图像数据img_to_visualize也需要提前加载进去准备好，该数据需要与model的输入Tensor维度匹配。 <a href="https://github.com/Kongsea/yueye/blob/master/visualize_outputs_keras_model1.py" target="_blank" rel="noopener">完整代码请点击查看</a>。</p>
<h3 id="2-直接加载模型，使用layer编号得到输出并图示"><a href="#2-直接加载模型，使用layer编号得到输出并图示" class="headerlink" title="2.直接加载模型，使用layer编号得到输出并图示"></a>2.直接加载模型，使用layer编号得到输出并图示</h3><p>1中方法固然也比较方便，但对模型有要求；而模型不满足要求时，还需要重新定义，略为复杂。 我们还可以使用另外一种方法，直接将已经保存的模型加载进来，然后一次将整个模型每一层的输出都全部得到，最后根据需求将某些层的输出进行图示即可。当然，此种方法虽然不需要模型图的重定义，但也需要预先对模型比较熟悉，不然无法找到某些层对应的编号，便无法获得其对应的输出。 这种方法首先需要定义可以一次得到所有层的输出的函数：</p>
<p>def get_layer_outputs():<br>  img_to_visualize = get_image()<br>  plt.imshow(img_to_visualize[…, 0])<br>  plt.show()<br>  img_to_visualize = np.expand_dims(img_to_visualize, 0)<br>  outputs = [layer.output for layer in model.layers]  # all layer outputs<br>  comp_graph = [K.function([model.input] + [K.learning_phase()], [output])<br>                for output in outputs]  # evaluation functions</p>
<h1 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h1><p>  layer_outputs_list = [op([img_to_visualize, 1.]) for op in comp_graph]<br>  layer_outputs = []</p>
<p>  for layer_output in layer_outputs_list:<br>    print(layer_output[0][0].shape, end=’\n——————-\n’)<br>    layer_outputs.append(layer_output[0][0])</p>
<p>  return layer_outputs</p>
<p>这个函数里，第2~5行中img_to_visualize与1中类似，是输入图像，这几行对图像进行处理的代码也与1中类似，此处不再赘述； 第6~8行构建得到输出的函数，也使用了K.function以及leaning_phase等； 第9行往后到结束，使用构建的函数获得模型每一层的输出。 随后定义函数将得到的某一层的输出数据进行输出显示，如下：</p>
<p>def plot_layer_outputs(layer_number):<br>  layer_outputs = get_layer_outputs()</p>
<p>  x_max = layer_outputs[layer_number].shape[0]<br>  y_max = layer_outputs[layer_number].shape[1]<br>  n = layer_outputs[layer_number].shape[2]</p>
<p>  L = []<br>  for i in range(n):<br>    L.append(np.zeros((x_max, y_max)))</p>
<p>  for i in range(n):<br>    for x in range(x_max):<br>      for y in range(y_max):<br>        L[i][x][y] = layer_outputs[layer_number][x][y][i]</p>
<p>  fig = plt.figure()<br>  for i, c in enumerate(L):<br>    ax = fig.add_subplot(np.ceil(n**0.5), np.ceil(n**0.5), i + 1)<br>    ax.imshow(c, cmap=’gray’)<br>  plt.show()</p>
<p>这个函数比较简单，我们对此进行一下简单解释。 首先第2行利用上面定义的函数，获得模型所有层的输出； 然后第4~6行得到所取出层的各种参数，比如大小，一共多少个feature maps等等； 第8~15行将对应的输出赋给一个列表，以备后续显示处理； 随后将得到的输出的各个feature maps绘制出来。 有了这两个函数，即可直接使用如<code>plot_layer_outputs(3)</code>来进行调用，绘制模型第3层的输出feature maps了。 <a href="https://github.com/Kongsea/yueye/blob/master/visualize_outputs_keras_model2.py" target="_blank" rel="noopener">完整代码请点击查看</a>。</p>
<h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><p>除了这两种方法外，还有一些其他方法可以使用，请参考<a href="https://stackoverflow.com/q/41711190/4049614" target="_blank" rel="noopener">这个问题及其回答</a>。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="John Doe" />
          <p class="site-author-name" itemprop="name">John Doe</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">434</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">108</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
