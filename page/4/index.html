<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>Hexo</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/15/tensorflow-multiple-gpu-and-reading-data-using-queue-runner-example/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/15/tensorflow-multiple-gpu-and-reading-data-using-queue-runner-example/" itemprop="url">TensorFlow Multiple GPU and Reading data using Queue Runner Example</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-15T20:14:52+08:00">
                2016-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’3D convolutional neural network trained<br>   to reduce the False Positive Rate for the LUNA datasets.<br>   The LUNA datasets are organized in the CIFAR architecture.</p>
<p>   Author: Kong Haiyang<br>‘’’<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import os<br>import sys<br>import time<br>import math<br>import numpy as np<br>from six.moves import xrange<br>import tensorflow as tf<br>import csv<br>import cv2</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 10, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 64, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 2, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 8,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_integer(‘NUM_LABEL’, 1, “How many Label bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(<br>    ‘NUM_IMAGE’, 40 ** 3, “How many Image bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(‘BYTE_LENGTH’, 4, “Byte length of label or image bytes.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_string(‘XAVIER_INIT’,<br>                           ‘tf.contrib.layers.xavier_initializer(seed=SEED)’,<br>                           “Initialize with XAVIER_INIT.”)</p>
<p>IMAGE_SIZE = FLAGS.IMAGE_SIZE<br>PIXEL_DATA_SIZE = FLAGS.PIXEL_DATA_SIZE<br>NUM_CHANNELS = FLAGS.CHANNEL_NUMBER<br>NUM_LABELS = FLAGS.LABEL_NUMBER<br>SEED = FLAGS.SEED<br>BATCH_SIZE = FLAGS.BATCH_SIZE<br>NUM_EPOCHS = FLAGS.NUM_EPOCHS<br>EVAL_BATCH_SIZE = FLAGS.EVAL_BATCH_SIZE<br>XAVIER_INIT = FLAGS.XAVIER_INIT<br>TOWER_NAME = FLAGS.TOWER_NAME<br>NUM_GPU = FLAGS.NUM_GPU<br>NUM_PREPROCESS_THREADS = FLAGS.NUM_PREPROCESS_THREADS<br>CSV_FILE = FLAGS.CSV_FILE<br>BIN_FILE = FLAGS.BIN_FILE<br>NUM_LABEL = FLAGS.NUM_LABEL<br>NUM_IMAGE = FLAGS.NUM_IMAGE<br>BYTE_LENGTH = FLAGS.BYTE_LENGTH<br>DTYPE = tf.float32</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def get_noaug_first(CSV_FILE, BIN_FILE, no, count):<br>  lines = readCSV(CSV_FILE)[1:]<br>  data = np.empty([count, IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1], dtype=float)<br>  labels = np.empty(count, dtype=int)<br>  i = count_ = 0<br>  length = (NUM_LABEL + NUM_IMAGE) <em> 4<br>  with open(BIN_FILE, ‘rb’) as f:<br>    for line in lines:<br>      if line[1] == str(no) and line[-1] == ‘0’ and line[-2] == ‘1’:<br>        f.seek(i </em> length)<br>        buf = f.read(length)<br>        data[count_, …] = (np.frombuffer(buf[4:], dtype=np.float32)).reshape(<br>            IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1)<br>        labels[count_] = np.frombuffer(buf[0:4], dtype=np.float32).astype(np.int64)<br>        count_ += 1<br>      i += 1<br>  return data, labels</p>
<p>def init_bin_file(BIN_FILE):<br>  bin_file_name = [BIN_FILE]<br>  for f in bin_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqb = tf.train.string_input_producer(bin_file_name, num_epochs=1)<br>  record_bytes = (NUM_LABEL + NUM_IMAGE) * BYTE_LENGTH<br>  rb = tf.FixedLengthRecordReader(record_bytes=record_bytes)<br>  return fqb, rb</p>
<p>def init_csv_file(CSV_FILE):<br>  csv_file_name = [CSV_FILE]<br>  for f in csv_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqc = tf.train.string_input_producer(csv_file_name, num_epochs=1)<br>  rc = tf.TextLineReader(skip_header_lines=True)<br>  return fqc, rc</p>
<p>def get_data_without_no(fqb, rb, fqc, rc, val_no, test_no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.logical_or(tf.equal(subsetid, tf.constant(<br>      val_no, dtype=tf.int32)), tf.equal(subsetid, tf.constant(test_no, dtype=tf.int32)))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_data_with_no(fqb, rb, fqc, rc, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.not_equal(<br>      subsetid, tf.constant(no, dtype=tf.int32))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_noaug_with_no(fqb, rb, fqc, rc, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      class_flag = tf.string_to_number(split_values.values[-2], out_type=tf.int32)<br>      noaug = tf.string_to_number(split_values.values[-1], out_type=tf.int32)<br>      return subsetid, class_flag, noaug<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    subsetid, class_flag, noaug = getID()<br>    return subsetid, class_flag, noaug, label, image<br>  subsetid, class_flag, noaug, label, image = getBIN()<br>  cond = lambda subsetid, class_flag, noaug, label, image: tf.logical_or(tf.not_equal(subsetid, tf.constant(no, dtype=tf.int32)),<br>                                                                         tf.logical_or(tf.not_equal(class_flag, tf.constant(1, dtype=tf.int32)), tf.not_equal(noaug, tf.constant(0, dtype=tf.int32))))<br>  doRead = lambda subsetid, class_flag, noaug, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, class_flag, noaug, label, image])<br>  return result</p>
<p>def get_train_data(fqb, rb, fqc, rc, val_no, test_no):<br>  subsetid, label, image = get_data_without_no(fqb, rb, fqc, rc, val_no, test_no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_test_data(fqb, rb, fqc, rc, no):<br>  subsetid, label, image = get_data_with_no(fqb, rb, fqc, rc, no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_noaug_data(fqb, rb, fqc, rc, no):<br>  subsetid, class_flag, noaug, label, image = get_noaug_with_no(fqb, rb, fqc, rc, no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, cfs, noaugs, labels, images = tf.train.batch(<br>      [subsetid, class_flag, noaug, label, image],<br>      batch_size=BATCH_SIZE // 10,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return sis, cfs, noaugs, labels, images</p>
<p>def get_size(CSV_FILE):<br>  ss = [0] <em> 10<br>  noaug = [0] </em> 10<br>  with open(CSV_FILE) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      if line[0] != ‘candidateID’:<br>        ss[int(line[1])] += 1<br>        if line[-1] == ‘0’ and line[-2] == ‘1’:<br>          noaug[int(line[1])] += 1<br>  return ss, noaug</p>
<p>def _weight_on_cpu(name, shape):<br>  with tf.device(‘/cpu:0’):<br>    var = tf.get_variable(name, shape, DTYPE, tf.truncated_normal_initializer(stddev=0.1))<br>  return var</p>
<p>def _bias_on_cpu(name, shape):<br>  with tf.device(‘/cpu:0’):<br>    var = tf.get_variable(name, shape, DTYPE, tf.constant_initializer(0.0))<br>  return var</p>
<p>def model(data, isTraining, keep_prob):<br>  with tf.variable_scope(‘conv1’) as scope:<br>    W1 = _weight_on_cpu(‘W1’, [3, 3, 3, NUM_CHANNELS, 16])<br>    conv = tf.nn.conv3d(data, W1, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b1 = _bias_on_cpu(‘b1’, [16])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b1))<br>  with tf.variable_scope(‘conv2’) as scope:<br>    W2 = _weight_on_cpu(‘W2’, [3, 3, 3, 16, 24])<br>    conv = tf.nn.conv3d(relu, W2, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b2 = _bias_on_cpu(‘b2’, [24])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b2))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’) as scope:<br>    W3 = _weight_on_cpu(‘W3’, [3, 3, 3, 24, 32])<br>    conv = tf.nn.conv3d(pool, W3, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b3 = _bias_on_cpu(‘b3’, [32])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b3))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’) as scope:<br>    W4 = _weight_on_cpu(‘W4’, [3, 3, 3, 32, 48])<br>    conv = tf.nn.conv3d(pool, W4, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b4 = _bias_on_cpu(‘b4’, [48])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b4))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv5’) as scope:<br>    W5 = _weight_on_cpu(‘W5’, [3, 3, 3, 48, 64])<br>    conv = tf.nn.conv3d(pool, W5, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b5 = _bias_on_cpu(‘b5’, [64])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b5))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’) as scope:<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] <em> ps[4]])<br>  with tf.variable_scope(‘fc1’) as scope:<br>    fcw1 = _weight_on_cpu(‘fcw1’, [2\</em>*3 * 64, 32])<br>    fcb1 = _bias_on_cpu(‘fcb1’, [32])<br>    hidden = tf.nn.relu(tf.matmul(reshape, fcw1) + fcb1)</p>
<pre><code>hidden = tf.cond(isTraining,
                 lambda: tf.nn.dropout(hidden, keep_prob),
                 lambda: hidden)
</code></pre><p>  with tf.variable_scope(‘fc2’) as scope:<br>    fcw2 = _weight_on_cpu(‘fcw2’, [32, NUM_LABELS])<br>    fcb2 = _bias_on_cpu(‘fcb2’, [NUM_LABELS])<br>    out = tf.add(tf.matmul(hidden, fcw2), fcb2)<br>  return out</p>
<p>def loss(logits, labels):<br>  “””Add L2Loss to all the trainable variables.<br>  “””<br>  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(<br>      logits, labels, name=’cross_entropy_per_example’)<br>  cross_entropy_mean = tf.reduce_mean(cross_entropy, name=’cross_entropy’)<br>  tf.add_to_collection(‘losses’, cross_entropy_mean)</p>
<p>  return tf.add_n(tf.get_collection(‘losses’), name=’total_loss’)</p>
<p>def tower_loss(images, labels, isTraining, scope):<br>  logits = model(images, isTraining, 0.5)<br>  _ = loss(logits, labels)<br>  losses = tf.get_collection(‘losses’, scope)<br>  total_loss = tf.add_n(losses, name=’total_loss’)</p>
<p>  loss_averages = tf.train.ExponentialMovingAverage(0.9, name=’avg’)<br>  loss_averages_op = loss_averages.apply(losses + [total_loss])</p>
<p>  with tf.control_dependencies([loss_averages_op]):<br>    total_loss = tf.identity(total_loss)<br>  return total_loss, logits</p>
<p>def average_gradients(tower_grads):<br>  “””Calculate the average gradient for each shared variable across all towers.<br>  Note that this function provides a synchronization point across all towers.<br>  “””<br>  average_grads = []<br>  for grad_and_vars in zip(*tower_grads):<br>    grads = []<br>    for g, _ in grad_and_vars:<br>      expanded_g = tf.expand_dims(g, 0)<br>      grads.append(expanded_g)</p>
<pre><code>grad = tf.concat(0, grads)
grad = tf.reduce_mean(grad, 0)
v = grad\_and\_vars\[0\]\[1\]
grad\_and\_var = (grad, v)
average\_grads.append(grad\_and_var)
</code></pre><p>  return average_grads</p>
<p>def eval_in_batches(data, sess, eval_prediction, eval_data, isTraining):<br>  size = data.shape[0]<br>  if size &lt; EVAL_BATCH_SIZE:<br>    raise ValueError(“batch size for evals larger than dataset: %d” % size)</p>
<h1 id="size-size-NUM-GPU-comment-this-will-cause-tf-exception"><a href="#size-size-NUM-GPU-comment-this-will-cause-tf-exception" class="headerlink" title="size -= size % NUM_GPU  # comment this will cause tf exception?"></a>size -= size % NUM_GPU  # comment this will cause tf exception?</h1><p>  predictions = np.ndarray(shape=(size, NUM_LABELS), dtype=np.float32)<br>  for begin in xrange(0, size, EVAL_BATCH_SIZE):<br>    end = begin + EVAL_BATCH_SIZE<br>    if end &lt;= size:<br>      predict = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[begin:end, …], isTraining: False})<br>      predictions[begin:end, :] = np.vstack(predict)<br>    else:<br>      batch_predictions = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[-EVAL_BATCH_SIZE:, …], isTraining: False})<br>      predictions[begin:, :] = batch_predictions[begin - size:, :]<br>  return predictions</p>
<p>def error_rate(predictions, labels):<br>  “””Return the error rate based on dense predictions and sparse labels.”””<br>  return 100.0 - (100.0 * np.sum(np.argmax(predictions, 1) == labels) /<br>                  predictions.shape[0])</p>
<p>def lunaTrain(VIEW_DIRECTORY, imgName, csvName, ss_list, noaug_list):<br>  with tf.Graph().as_default(), tf.device(‘/cpu:0’):<br>    for cross in range(10):<br>      sssstttt = time.time()<br>      print(‘Cross {}…’.format(cross))<br>      WORK_DIRECTORY = os.path.join(VIEW_DIRECTORY, ‘Cross{}’.format(cross))<br>      testNo = cross<br>      valNo = (cross + 1) % 10<br>      st = time.time()<br>      train_size = sum(ss_list) - ss_list[testNo] - ss_list[valNo]<br>      test_no_aug_data, test_no_aug_label = get_noaug_first(<br>          CSV_FILE, BIN_FILE, testNo, noaug_list[testNo])<br>      val_no_aug_data, val_no_aug_label = get_noaug_first(<br>          CSV_FILE, BIN_FILE, valNo, noaug_list[valNo])<br>      print(‘Reading no aug data finished in {:.2f} seconds…’.format(time.time() - st))<br>      st = time.time()<br>      fqbt, rbt = init_bin_file(BIN_FILE)<br>      fqct, rct = init_csv_file(CSV_FILE)<br>      fqbe, rbe = init_bin_file(BIN_FILE)<br>      fqce, rce = init_csv_file(CSV_FILE)<br>      data_node = tf.placeholder(tf.float32, shape=(<br>          None, IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))<br>      labels_node = tf.placeholder(tf.int64, shape=(None,))<br>      isTraining = tf.placeholder(tf.bool, name=’isTrain’)</p>
<pre><code>batch = tf.Variable(0, trainable=False)
learning\_rate = tf.train.exponential\_decay(0.01, batch * BATCH\_SIZE, train\_size / 5,
                                           0.95, staircase=True)
opt = tf.train.MomentumOptimizer(learning_rate, 0.9)

split\_images = tf.split(0, NUM\_GPU, data_node)
split\_labels = tf.split(0, NUM\_GPU, labels_node)

eval_predictions = \[\]
tower_grads = \[\]
for i in xrange(NUM_GPU):
  with tf.device(&apos;/gpu:%d&apos; % i):
    with tf.name\_scope(&apos;%s\_%d&apos; % (TOWER_NAME, i)) as scope:
      loss, logits = tower\_loss(split\_images\[i\], split_labels\[i\], isTraining, scope)
      predictions = tf.nn.softmax(logits)
      eval_predictions.append(predictions)
      tf.get\_variable\_scope().reuse_variables()

      grads = opt.compute_gradients(loss)
      tower_grads.append(grads)

grads = average\_gradients(tower\_grads)
apply\_gradient\_op = opt.apply_gradients(grads)

variable_averages = tf.train.ExponentialMovingAverage(0.9999)
variables\_averages\_op = variable\_averages.apply(tf.trainable\_variables())

train\_op = tf.group(apply\_gradient\_op, variables\_averages_op)

train\_label\_node, train\_data\_node = get\_train\_data(
    fqbt, rbt, fqct, rct, valNo, testNo)
val\_label\_node, val\_data\_node = get\_test\_data(fqbe, rbe, fqce, rce, valNo)
test\_label\_node, test\_data\_node = get\_test\_data(fqbe, rbe, fqce, rce, testNo)

saver = tf.train.Saver(tf.all_variables())

TRAIN\_FREQUENCY = train\_size // BATCH_SIZE // 20
VAL\_FREQUENCY = train\_size // BATCH_SIZE
TEST\_FREQUENCY = train\_size // BATCH_SIZE * 5

config = tf.ConfigProto(allow\_soft\_placement=True, log\_device\_placement=False)
with tf.Session(config=config) as sess:
  summary\_writer = tf.train.SummaryWriter(WORK\_DIRECTORY, sess.graph)
  sess.run(tf.initialize\_local\_variables())
  sess.run(tf.initialize\_all\_variables())
  coord = tf.train.Coordinator()
  threads = tf.train.start\_queue\_runners(sess=sess, coord=coord)
  try:
    while not coord.should_stop():
      start_time = time.time()
      for step in xrange(int(NUM\_EPOCHS * train\_size) // BATCH_SIZE):
        train\_data, train\_label = sess.run(\[train\_data\_node, train\_label\_node\])
        feed\_dict = {data\_node: train_data,
                     labels\_node: train\_label, isTraining: True}
        _, l, lr = sess.run(\[train\_op, loss, learning\_rate\], feed\_dict=feed\_dict)
        if step != 0 and step % TRAIN_FREQUENCY == 0:
          et = time.time() - start_time
          print(&apos;Step %d (epoch %.2f), %.1f ms&apos; %
                (step, float(step) * BATCH\_SIZE / train\_size, 1000 * et / TRAIN_FREQUENCY))
          print(&apos;Minibatch loss: %.3f, learning rate: %.6f&apos; % (l, lr))
          start_time = time.time()
        if step != 0 and VAL\_FREQUENCY != 0 and step % VAL\_FREQUENCY == 0:
          val\_data, val\_label = sess.run(\[val\_data\_node, val\_label\_node\])
          valE = error\_rate(eval\_in_batches(
              val\_data, sess, eval\_predictions, data\_node, isTraining), val\_label)
          print(&apos;Validation error: %.3f%%&apos; % valE)
          valPE = error\_rate(eval\_in_batches(
              val\_no\_aug\_data, sess, eval\_predictions, data\_node, isTraining), val\_no\_aug\_label)
          print(&apos;Validation error of no aug Positive: %.3f%%&apos; % valPE)
          val_data = 0
          start_time = time.time()
        if step != 0 and TEST\_FREQUENCY != 0 and step % TEST\_FREQUENCY == 0:
          test\_data, test\_label = sess.run(\[test\_data\_node, test\_label\_node\])
          test\_error = error\_rate(eval\_in\_batches(
              test\_data, sess, eval\_predictions, data\_node, isTraining), test\_label)
          print(&apos;Test error: %.3f%%&apos; % test_error)
          test\_errorP = error\_rate(eval\_in\_batches(
              test\_no\_aug\_data, sess, eval\_predictions, data\_node, isTraining), test\_no\_aug\_label)
          print(&apos;Test error of no aug Positive: %.3f%%&apos; % test_errorP)
          test_data = 0
          start_time = time.time()
      else:
        checkpoint\_path = os.path.join(WORK\_DIRECTORY, &apos;model.ckpt&apos;)
        saver.save(sess, checkpoint\_path, global\_step=step)
  except tf.errors.OutOfRangeError:
    print(&apos;Done training -- epoch limit reached&apos;)
  finally:
    coord.request_stop()
  coord.join(threads)
print(&apos;All costs {:.2f} seconds...&apos;.format(time.time() - sssstttt))
train\_data = val\_data = test_data = 0
train\_labels = val\_labels = test_labels = 0
</code></pre><p>def main(_):<br>  viewPath = ‘/home/kong/4T/official3D_110W’<br>  csvName = ‘/home/kong/4T/official3D_110W/Shuffle.csv’<br>  imgName = ‘/home/kong/4T/official3D_110W/shuffle3D.bin’</p>
<p>  ss_list, noaug_list = get_size(CSV_FILE)<br>  lunaTrain(viewPath, imgName, csvName, ss_list, noaug_list)</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/15/use-tensorflow-queuerunner-to-read-data-from-a-binary-file-according-to-some-conditions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/15/use-tensorflow-queuerunner-to-read-data-from-a-binary-file-according-to-some-conditions/" itemprop="url">Use TensorFlow QueueRunner to read data from a binary file according to some conditions</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-15T20:11:07+08:00">
                2016-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import os<br>import sys<br>import time</p>
<p>import math<br>import numpy as np<br>from six.moves import xrange<br>import tensorflow as tf<br>import csv</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 10, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 128, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 2, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 8,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_string(‘XAVIER_INIT’,<br>                           ‘tf.contrib.layers.xavier_initializer(seed=SEED)’,<br>                           “Initialize with XAVIER_INIT.”)</p>
<p>IMAGE_SIZE = FLAGS.IMAGE_SIZE<br>PIXEL_DATA_SIZE = FLAGS.PIXEL_DATA_SIZE<br>NUM_CHANNELS = FLAGS.CHANNEL_NUMBER<br>NUM_LABELS = FLAGS.LABEL_NUMBER<br>SEED = FLAGS.SEED<br>BATCH_SIZE = FLAGS.BATCH_SIZE<br>NUM_EPOCHS = FLAGS.NUM_EPOCHS<br>EVAL_BATCH_SIZE = FLAGS.EVAL_BATCH_SIZE<br>XAVIER_INIT = FLAGS.XAVIER_INIT<br>TOWER_NAME = FLAGS.TOWER_NAME<br>NUM_GPU = FLAGS.NUM_GPU<br>CSV_FILE = FLAGS.CSV_FILE<br>BIN_FILE = FLAGS.BIN_FILE<br>NUM_PREPROCESS_THREADS = FLAGS.NUM_PREPROCESS_THREADS</p>
<p>DTYPE = tf.float32<br>label_nums = 1<br>image_nums = 40**3</p>
<p>def init_bin_file(BIN_FILE):<br>  bin_file_name = [BIN_FILE]<br>  for f in bin_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  filename_queue_bin = tf.train.string_input_producer(<br>      bin_file_name, num_epochs=1)<br>  label_nums = 1<br>  image_nums = 40 <em> 40 </em> 40<br>  record_bytes = (label_nums + image_nums) * 4<br>  reader_bin = tf.FixedLengthRecordReader(record_bytes=record_bytes)<br>  return filename_queue_bin, reader_bin</p>
<p>def init_csv_file(CSV_FILE):<br>  csv_file_name = [CSV_FILE]<br>  for f in csv_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  filename_queue_csv = tf.train.string_input_producer(<br>      csv_file_name, num_epochs=1)<br>  reader_csv = tf.TextLineReader(skip_header_lines=True)<br>  return filename_queue_csv, reader_csv</p>
<p>def get_data_without_no(filename_queue_bin, reader_bin, record_bytes, filename_queue_csv,<br>                        reader_csv, label_nums, image_nums, val_no, test_no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = reader_csv.read(filename_queue_csv)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = reader_bin.read(filename_queue_bin)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [label_nums]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [label_nums], [image_nums]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.logical_or(tf.equal(subsetid, tf.constant(<br>      val_no, dtype=tf.int32)), tf.equal(subsetid, tf.constant(test_no, dtype=tf.int32)))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_data_with_no(filename_queue_bin, reader_bin, record_bytes,<br>                     filename_queue_csv, reader_csv, label_nums, image_nums, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = reader_csv.read(filename_queue_csv)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = reader_bin.read(filename_queue_bin)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [label_nums]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [label_nums], [image_nums]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.not_equal(<br>      subsetid, tf.constant(no, dtype=tf.int32))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_noaug_with_no(filename_queue_bin, reader_bin, record_bytes,<br>                      filename_queue_csv, reader_csv, label_nums, image_nums, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = reader_csv.read(filename_queue_csv)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      class_flag = tf.string_to_number(split_values.values[-2], out_type=tf.int32)<br>      noaug = tf.string_to_number(split_values.values[-1], out_type=tf.int32)<br>      return subsetid, class_flag, noaug<br>    key, value = reader_bin.read(filename_queue_bin)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [label_nums]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [label_nums], [image_nums]),<br>                       shape=[40, 40, 40, 1])<br>    subsetid, class_flag, noaug = getID()<br>    return subsetid, class_flag, noaug, label, image<br>  subsetid, class_flag, noaug, label, image = getBIN()<br>  cond = lambda subsetid, class_flag, noaug, label, image: tf.logical_or(tf.not_equal(subsetid, tf.constant(no, dtype=tf.int32)),<br>                                                                         tf.logical_or(tf.not_equal(class_flag, tf.constant(1, dtype=tf.int32)), tf.not_equal(noaug, tf.constant(0, dtype=tf.int32))))<br>  doRead = lambda subsetid, class_flag, noaug, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, class_flag, noaug, label, image])<br>  return result</p>
<p>def get_train_data(filename_queue_bin, reader_bin, record_bytes,<br>                   filename_queue_csv, reader_csv, label_nums, image_nums, val_no, test_no):<br>  subsetid, label, image = get_data_without_no(filename_queue_bin, reader_bin, record_bytes,<br>                                               filename_queue_csv, reader_csv, label_nums, image_nums, val_no, test_no)</p>
<p>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  return sis, labels, images</p>
<p>def get_test_data(filename_queue_bin, reader_bin, record_bytes,<br>                  filename_queue_csv, reader_csv, label_nums, image_nums, no):<br>  subsetid, label, image = get_data_with_no(filename_queue_bin, reader_bin, record_bytes,<br>                                            filename_queue_csv, reader_csv, label_nums, image_nums, no)</p>
<p>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  return sis, labels, images</p>
<p>def get_noaug_data(filename_queue_bin, reader_bin, record_bytes,<br>                   filename_queue_csv, reader_csv, label_nums, image_nums, no):<br>  subsetid, class_flag, noaug, label, image = get_noaug_with_no(filename_queue_bin, reader_bin, record_bytes,<br>                                                                filename_queue_csv, reader_csv, label_nums, image_nums, no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, cfs, noaugs, labels, images = tf.train.batch(<br>      [subsetid, class_flag, noaug, label, image],<br>      batch_size=BATCH_SIZE // 10,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  return sis, cfs, noaugs, labels, images</p>
<p>def main(_):<br>  fqb, rb = init_bin_file(BIN_FILE)<br>  fqc, rc = init_csv_file(CSV_FILE)<br>  record_bytes = (1 + 40**3) * 4<br>  sis, cfs, noaugs, labels, images = get_noaug_data(fqb, rb, record_bytes,<br>                                                    fqc, rc, label_nums, image_nums, 5)<br>  with tf.Session() as sess:<br>    sess.run(tf.initialize_local_variables())<br>    sess.run(tf.initialize_all_variables())<br>    coord = tf.train.Coordinator()<br>    threads = tf.train.start_queue_runners(sess=sess, coord=coord)<br>    try:<br>      while not coord.should_stop():<br>        sis_, cfs_, noaugs_, labels_, images_ = sess.run(<br>            [sis, cfs, noaugs, labels, images])<br>        print(sis_)<br>    except tf.errors.OutOfRangeError:<br>      print(‘Done training – epoch limit reached’)<br>    finally:<br>      coord.request_stop()<br>    coord.join(threads)</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/07/vscode-using-git-accompany-with-visual-studio-online/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/07/vscode-using-git-accompany-with-visual-studio-online/" itemprop="url">VSCode using git accompanied with github or Visual Studio online</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-07T21:14:12+08:00">
                2016-12-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/经验知识/" itemprop="url" rel="index">
                    <span itemprop="name">经验知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VSCode-with-github"><a href="#VSCode-with-github" class="headerlink" title="VSCode with github:"></a>VSCode with github:</h1><p>1、在github上创建项目 2、使用git clone <a href="https://github.com/xxxxxxx/xxxxx.git克隆到本地" target="_blank" rel="noopener">https://github.com/xxxxxxx/xxxxx.git克隆到本地</a> 3、编辑项目 4、git add . （将改动添加到暂存区） 5、git commit -m “提交说明” 6、git push origin master 将本地更改推送到远程master分支。 这样你就完成了向远程仓库的推送。 如果在github的remote上已经有了文件，可能会出现错误。此时应当先pull一下，即： <code>git pull origin master</code> 然后再进行： <code>git push origin master</code></p>
<h1 id="VSCode-with-Visual-Studio-online"><a href="#VSCode-with-Visual-Studio-online" class="headerlink" title="VSCode with Visual Studio online"></a>VSCode with Visual Studio online</h1><p>1.在<a href="http://www.visualstudio.com" title="Visual Studio online" target="_blank" rel="noopener">Visual Studio online</a>上创建项目 2.git clone https://×××.visualstudio.com/_git/××× 3.编辑项目 4.git push -u origin –all</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/05/memo-ubuntu-file-operations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/05/memo-ubuntu-file-operations/" itemprop="url">Ubuntu：远程复制文件、远程图形界面、恢复误删文件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-05T20:35:33+08:00">
                2016-12-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/经验知识/" itemprop="url" rel="index">
                    <span itemprop="name">经验知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近一段时间在Ubuntu的使用中积累了一些不能算是经验的经验，为防以后忘记，再浪费精力搜寻解决途径，现在做一下简单备忘。</p>
<h1 id="1-远程登录"><a href="#1-远程登录" class="headerlink" title="1.远程登录"></a>1.远程登录</h1><blockquote>
<p>首先是关于远程登录的一些操作。 如果登录一台Ubuntu系统的计算机，需要计算机上安装openssh服务端，使用如下命令完成：</p>
<p>[shell]sudo apt-get install openssh-server[/shell]</p>
<p>（可能也需要本地电脑安装[shell]sudo apt-get insall ssh[/shell]，或者[shell]sudo apt-get install openssh-client[/shell]，没有环境测试，不敢确认。） 远程登录一台用户名为admin的，IP为192.168.12.5的Ubuntu系统（其他Linux系统应该也可以，未测试）的计算机，可以使用如下命令： [shell]ssh <a href="mailto:admin@192.168.12.5" target="_blank" rel="noopener">admin@192.168.12.5</a>[/shell] 或者 [shell]ssh -l admin 192.168.12.5[/shell] 查看一台Ubuntu系统计算机的IP，可以使用[shell]ifconfig[/shell]命令。</p>
</blockquote>
<h1 id="2-远程复制文件"><a href="#2-远程复制文件" class="headerlink" title="2.远程复制文件"></a>2.远程复制文件</h1><blockquote>
<p>在服务器和本地计算机之间复制文件，如果需要将远程计算机上的文件复制到本地，使用 [shell]sudo scp <a href="mailto:admin@192.168.12.5" target="_blank" rel="noopener">admin@192.168.12.5</a>:/home/admin/file.tar.gz /home/kong/[/shell] 回车依次输入当前用户密码和远程计算机用户密码即可。 需要注意的是，复制回来的文件需要root权限才可以使用。可以使用[shell]sudo chmod 777 filename[/shell]将其修改为所有用户可用。 如果需要将本地文件复制到远程计算机上，则使用 [shell]scp /home/kong/file.tar.gz <a href="mailto:admin@192.168.12.5" target="_blank" rel="noopener">admin@192.168.12.5</a>:/home/admin/[/shell] 回车后输入远程计算机的密码即可。 复制文件夹与此类似，使用如下命令： [shell]scp -r <a href="mailto:admin@192.168.12.5" target="_blank" rel="noopener">admin@192.168.12.5</a>:/home/admin/directory/ /home/kong/[/shell]</p>
</blockquote>
<h1 id="3-挂载远程文件到本地"><a href="#3-挂载远程文件到本地" class="headerlink" title="3.挂载远程文件到本地"></a>3.挂载远程文件到本地</h1><blockquote>
<p>使用sshfs，有可能需要首先安装： [shell]sudo apt-get install sshfs[/shell] 安装完成后，使用类似如下的命令进行挂载： [shell]sshfs –o cache=yes,allow_other <a href="mailto:user@192.168.198.107" target="_blank" rel="noopener">user@192.168.198.107</a>:/home/user/code /home/user/code #将用户名为user的192.168.198.107上的/home/user/code挂载到本地/home/user/code上[/shell] 或 [shell]sshfs -o allow_other <a href="mailto:admin6@192.168.198.107" target="_blank" rel="noopener">admin6@192.168.198.107</a>:/home/admin6/kong ./ #将用户名为admin6的192.168.198.107上的/home/admin6/kong挂载到当前文件夹上[/shell]</p>
</blockquote>
<h1 id="4-图形界面远程登录"><a href="#4-图形界面远程登录" class="headerlink" title="4.图形界面远程登录"></a>4.图形界面远程登录</h1><blockquote>
<p>使用软件Vinagre，使用[shell]sudo apt-get install vinagre[/shell]安装。 安装完成后，打开Ubuntu自带的Desktop Sharing进行一些设置，在其中，将Allow other users to view your desktop和Allow other users to control your desktop选中，然后选中Require the user to enter this password，并设置密码，设置完成。 然后在其他计算机上，就可以打开Vinagre连接这台电脑了。需要注意的是连接协议选择VNC，Host输入该电脑IP，连接后选择全屏即可正常操作。全屏的切换快捷键是F11。</p>
</blockquote>
<h1 id="5-恢复误删文件"><a href="#5-恢复误删文件" class="headerlink" title="5.恢复误删文件"></a>5.恢复误删文件</h1><blockquote>
<p>有时候会不经意间误删一些文件，在Ubuntu下也是如此，使用extundelete可以恢复误删的文件。 记住误删的大体时间，使用如 [shell]date -d “Dec 5 17:00” +%s[/shell] 所示的命令，查看误删时间转换为extundelete所需要的时间，如1492141200。然后使用如下所示的命令恢复文件： [shell]extundelete /dev/sdb –after 1492141200 –restore-all –output-dir directory[/shell] 其中[shell]/dev/sdb[/shell]表示误删文件所在的磁盘名，可以使用[shell]df -l[/shell]来查看你的磁盘列表； [shell]–after 1492141200[/shell]即上一条命令转换过来的时间 [shell]–restore-all[/shell]表示将指定时间后删除的所有文件都恢复，我也试过指定特定目录，如：[shell]–restore-directory /media/kong/tmp_zhang[/shell]，但不知为何，不能成功 [shell]–output-dir[/shell]表示恢复文件到某个路径，directory即为文件夹的path</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/03/my-vscode-user-settings/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/03/my-vscode-user-settings/" itemprop="url">VSCode配置备忘</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-03T15:10:45+08:00">
                2016-12-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/经验知识/" itemprop="url" rel="index">
                    <span itemprop="name">经验知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Visual Studio Code (VSCode)是微软开源的一款跨平台编辑器，顾名思义，其相当于在Visual Studio 集成开发环境的基础上精简而来的代码编辑器。因为其开源、跨平台的特性，又由于其各种响应速度，而且背靠微软这棵大树，所以我在Ubuntu上选择它作为我的Python程序编辑器。而搭配上<a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.python" title="VSCode Python 调试插件" target="_blank" rel="noopener">Python调试插件</a>，更可以直接进行程序调试，基本上能够满足我的需求。 因为VSCode的各种参数设置与众不同，所以以下简单备忘一下我的VSCode的配置文件（通过File-&gt;Preferences-&gt;User Settings打开）： [python] // Place your settings in this file to overwrite the default settings { // “editor.fontFamily”: “‘DejaVu Sans Mono for Powerline’”, “editor.fontFamily”: “‘Fira Code’”, “editor.fontLigatures”: true, // Controls the font size. “editor.fontSize”: 22, “editor.renderIndentGuides”: true, “editor.occurrencesHighlight”: false, // Columns at which to show vertical rulers “editor.rulers”: [ 100 ], // Arguments passed in. Each argument is a separate item in the array. “python.formatting.autopep8Args”: [ “–max-line-length=100”, “–indent-size=2” ], // Format a file on save. A formatter must be available, the file must not be auto-saved, and editor must not be shutting down. “editor.formatOnSave”: true, // Format the document upon saving. “python.formatting.formatOnSave”: true, “python.linting.pylintArgs”: [ “–include-naming-hint=n”, “–disable=W0311”, “–disable=C0103”, “–disable=E1101” ], “files.trimTrailingWhitespace”: true, // The number of spaces a tab is equal to. This setting is overriden based on the file contents when `editor.detectIndentation` is on. “editor.tabSize”: 2, “files.exclude”: { “.vs<em>“: true, “</em>.<em>~”: true, “</em>.pyc”: true, “<em>/</em>.pyc”: true }, “files.autoSave”: “onWindowChange”, “git.confirmSync”: false, “window.zoomLevel”: 0, “editor.minimap.enabled”: true, “editor.minimap.maxColumn”: 120, “workbench.welcome.enabled”: false, “workbench.colorTheme”: “Monokai”, “workbench.iconTheme”: “vs-nomo-dark” } [/python]</p>
<p>简单说明一下：</p>
<p>1.配置了字体，我使用了<a href="https://github.com/tonsky/FiraCode" title="Fira Code字体" target="_blank" rel="noopener">Fira Code</a>这款字体，并将字号设置为了18；</p>
<p>2.设置了最大列数提醒的位置；</p>
<p>3.设置了autopep8自动格式化Python代码的的一些参数；</p>
<p>4.设置保存文件时自动格式化Python代码；</p>
<p>5.设置了pylint一些警告、错误提示的参数；</p>
<p>6.设置保存时，自动将Python代码的一些空格给trim掉；</p>
<p>7.设置Tab Size为2个空格；</p>
<p>8.将一些编译后而不想在编辑器里看到的文件隐藏；</p>
<p>9.将编辑器的自动保存关闭。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/11/06/luna-3d-test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/06/luna-3d-test/" itemprop="url">luna 3d test</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-11-06T21:48:34+08:00">
                2016-11-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’3D convolutional neural network trained<br>   to reduce the False Positive Rate for the LUNA datasets.<br>   The LUNA datasets are organized in the CIFAR architecture.</p>
<p>   Author: Kong Haiyang<br>‘’’</p>
<p>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import os<br>import sys<br>import time<br>import math<br>import numpy as np<br>from six.moves import xrange<br>import tensorflow as tf<br>import pprocess<br>import csv</p>
<p>IMAGE_SIZE = 40<br>PIXELDATA_SIZE = 4<br>NUM_CHANNELS = 1<br>NUM_LABELS = 2<br>SEED = 66478<br>BATCH_SIZE = 128<br>NUM_EPOCHS = 10<br>EVAL_BATCH_SIZE = 64<br>XAVIER_INIT = tf.contrib.layers.xavier_initializer(seed=SEED)</p>
<p>class lunaDataSet:<br>  data_filename = “”<br>  csv_filename = “”<br>  all_count = test_count = val_count = train_count = 0<br>  val_no_aug_pos = []<br>  test_no_aug_pos = []<br>  train_batch_index = [0]<br>  is_parallel = False<br>  nproc = 1<br>  __fptr = None<br>  __csv_lines = 0<br>  __columns, __rows, __heights, __byte_length = IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, PIXELDATA_SIZE<br>  __t_length = 1 + __columns <em> __rows </em> __heights * __byte_length<br>  __num_of_read = __train_rec_index = __test_rec_index = __val_rec_index = 0L</p>
<p>  def __init__(self, datafile, csvfile, is_parallel=True):<br>    self.data_filename = datafile<br>    self.csv_filename = csvfile<br>    self.__fptr = open(self.data_filename, ‘rb’)<br>    self.__csv_lines = readCSV(self.csv_filename)[1:]<br>    self.is_parallel = is_parallel<br>    if (self.is_parallel):<br>      self.nproc = pprocess.get_number_of_cores() - 1</p>
<p>  def __del__(self):<br>    self.<strong>fptr.close()
    </strong>csvLines = 0</p>
<p>  def getDataNum(self, testNo, valNo, train_group_size=0):<br>    self.test_count = self.val_count = self.train_count = 0<br>    self.val_no_aug_pos = []<br>    self.test_no_aug_pos = []<br>    for line in self.__csv_lines:<br>      if line[1] == testNo:<br>        if line[-2] == ‘1’ and line[-1] == ‘0’:<br>          self.test_no_aug_pos.append(self.test_count)<br>        self.test_count += 1<br>      elif line[1] == valNo:<br>        if line[-2] == ‘1’ and line[-1] == ‘0’:<br>          self.val_no_aug_pos.append(self.val_count)<br>        self.val_count += 1<br>      else:<br>        self.train_count += 1<br>        if (train_group_size != 0 and self.train_count % train_group_size == 0):<br>          self.train_batch_index.append(<br>              self.test_count + self.val_count + self.train_count)</p>
<pre><code>self.all\_count = self.test\_count + self.val\_count + self.train\_count
if (train\_group\_size != 0 and self.train\_count % train\_group_size != 0):
  self.train\_batch\_index.append(self.all_count)
</code></pre><p>  def __getValData(self, testNo, valNo, train_group_size=0):<br>    tempfp = self.__fptr.tell()  # will overflow if tempfp is too big.</p>
<pre><code>if (0 == self.all_count):
  self.getDataNum(testNo, valNo, train\_group\_size)

val\_data = np.empty(\[self.val\_count, self.\_\_rows, self.\_\_columns,
                     self.__heights, 1\], dtype=float)
val\_labels = np.empty(self.val\_count, dtype=int)

vali = 0
self.__fptr.seek(0)
relative_Offset = 0
for i in range(self.all_count):
  line = self.\_\_csv\_lines\[i\]
  if line\[1\] == valNo:
    if (relative_Offset &gt; 0):
      self.\_\_fptr.seek(relative\_Offset * self.\_\_t\_length, 1)
    bufCIFAR = self.\_\_fptr.read(self.\_\_t_length)
    val_labels\[vali\] = np.frombuffer(
        bufCIFAR\[0\], dtype=np.uint8).astype(np.int64)
    val_data\[vali, ...\] = (np.frombuffer(
        bufCIFAR\[1:\], dtype=np.float32)).reshape(self.\_\_rows, self.\_\_columns, self.__heights, 1)
    vali += 1
    relative_Offset = 0
  else:
    relative_Offset += 1

self.__fptr.seek(tempfp)  # if tempfp is too big, this sentence will become a bug.
return val\_labels, val\_data
</code></pre><p>  def getValData(self, testNo, valNo, train_group_size=0):<br>    return self.__getValData(testNo, valNo, train_group_size)</p>
<p>  def __getTestData(self, testNo, valNo, train_group_size=0):<br>    tempfp = self.__fptr.tell()  # will overflow if tempfp is too big.</p>
<pre><code>if (0 == self.all_count):
  self.getDataNum(testNo, valNo, train\_group\_size)

test\_data = np.empty(\[self.test\_count, self.\_\_rows, self.\_\_columns,
                      self.__heights, 1\], dtype=float)
test\_labels = np.empty(self.test\_count, dtype=int)

testi = 0
self.__fptr.seek(0)
relative_Offset = 0
for i in range(self.all_count):
  line = self.\_\_csv\_lines\[i\]
  if line\[1\] == testNo:
    if (relative_Offset &gt; 0):
      self.\_\_fptr.seek(relative\_Offset * self.\_\_t\_length, 1)
    bufCIFAR = self.\_\_fptr.read(self.\_\_t_length)
    test_labels\[testi\] = np.frombuffer(
        bufCIFAR\[0\], dtype=np.uint8).astype(np.int64)
    test_data\[testi, ...\] = (np.frombuffer(
        bufCIFAR\[1:\], dtype=np.float32)).reshape(self.\_\_rows, self.\_\_columns, self.__heights, 1)
    testi += 1
    relative_Offset = 0
  else:
    relative_Offset += 1

self.__fptr.seek(tempfp)  # if tempfp is too big, this sentence will become a bug.
return test\_labels, test\_data
</code></pre><p>  def getTestData(self, testNo, valNo, train_group_size=0):<br>    return self.__getTestData(testNo, valNo, train_group_size)</p>
<p>  def __getTrainData(self, testNo, valNo, num=[0]):<br>    if self.all_count == 0:<br>      self.getDataNum(testNo, valNo)</p>
<pre><code>if self.\_\_num\_of\_read == self.all\_count:
  return 0, 0

if self.\_\_train\_rec_index == 0:
  self.__fptr.seek(0)

if (num\[0\] == 0 or self.\_\_train\_rec\_index + num\[0\] &gt; self.train\_count):
  num\[0\] = self.train\_count - self.\_\_train\_rec\_index
if num\[0\] == 0:  # which means no more train data
  train_data = 0
  train_labels = 0
else:
  train\_data = np.empty(\[num\[0\], self.\_\_rows, self.__columns,
                         self.__heights, 1\], dtype=float)
  train_labels = np.empty(num\[0\], dtype=int)

traini = 0
relative_Offset = 0

for i in range(self.all\_count - long(self.\_\_num\_of\_read)):
  line = self.\_\_csv\_lines\[self.\_\_num\_of_read + i\]
  if line\[1\] == testNo:
    self.\_\_test\_rec_index += 1
    relative_Offset = 0
  elif line\[1\] == valNo:
    self.\_\_val\_rec_index += 1
    relative_Offset += 1
  else:
    if (traini == num\[0\]):
      if (relative_Offset &gt; 0):
        self.\_\_fptr.seek(relative\_Offset * self.\_\_t\_length, 1)
      break
    if (relative_Offset &gt; 0):
      self.\_\_fptr.seek(relative\_Offset * self.\_\_t\_length, 1)
    bufCIFAR = self.\_\_fptr.read(self.\_\_t_length)
    train_labels\[traini\] = np.frombuffer(
        bufCIFAR\[0\], dtype=np.uint8).astype(np.int64)
    train_data\[traini, ...\] = (np.frombuffer(
        bufCIFAR\[1:\], dtype=np.float32)).reshape(self.\_\_rows, self.\_\_columns, self.__heights, 1)
    traini += 1
    self.\_\_train\_rec_index += 1
    relative_Offset = 0

self.\_\_num\_of\_read = self.\_\_train\_rec\_index + self.\_\_test\_rec\_index + self.\_\_val\_rec\_index

return train\_data, train\_labels
</code></pre><p>  def getTrainData(self, testNo, valNo, num=[0]):<br>    return self.__getTrainData(testNo, valNo, num)</p>
<p>Wb = {<br>    ‘W1’: tf.Variable(tf.truncated_normal([3, 3, 3, NUM_CHANNELS, 16], stddev=0.1, seed=SEED)),<br>    ‘b1’: tf.Variable(tf.zeros([16])),<br>    ‘W2’: tf.Variable(tf.truncated_normal([3, 3, 3, 16, 32], stddev=0.1, seed=SEED)),<br>    ‘b2’: tf.Variable(tf.zeros([32])),<br>    ‘W3’: tf.Variable(tf.truncated_normal([3, 3, 3, 32, 48], stddev=0.1, seed=SEED)),<br>    ‘b3’: tf.Variable(tf.zeros([48])),<br>    ‘W4’: tf.Variable(tf.truncated_normal([3, 3, 3, 48, 64], stddev=0.1, seed=SEED)),<br>    ‘b4’: tf.Variable(tf.zeros([64])),<br>    ‘fcw1’: tf.Variable(tf.truncated_normal([2**3 * 64, 32], stddev=0.1, seed=SEED)),<br>    ‘fcb1’: tf.Variable(tf.zeros([32])),<br>    ‘fcw2’: tf.Variable(tf.truncated_normal([32, NUM_LABELS], stddev=0.1, seed=SEED)),<br>    ‘fcb2’: tf.Variable(tf.zeros([NUM_LABELS]))<br>}</p>
<p>def model(data, keep_prob):<br>  with tf.variable_scope(‘conv1’):<br>    conv = tf.nn.conv3d(data, Wb[‘W1’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b1’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv2’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W2’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b2’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W3’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b3’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W4’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b4’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’):<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] * ps[4]])<br>  with tf.variable_scope(‘fc1’):<br>    hidden = tf.nn.relu(tf.matmul(reshape, Wb[‘fcw1’]) + Wb[‘fcb1’])<br>  with tf.variable_scope(‘dropout’):<br>    hidden = tf.nn.dropout(hidden, keep_prob, seed=SEED)<br>  with tf.variable_scope(‘fc2’):<br>    out = tf.matmul(hidden, Wb[‘fcw2’]) + Wb[‘fcb2’]<br>  return out</p>
<p>def eval_in_batches(data, sess, eval_prediction, eval_data):<br>  size = data.shape[0]<br>  if size &lt; EVAL_BATCH_SIZE:<br>    raise ValueError(“batch size for evals larger than dataset: %d” % size)<br>  predictions = np.ndarray(shape=(size, NUM_LABELS), dtype=np.float32)<br>  for begin in xrange(0, size, EVAL_BATCH_SIZE):<br>    end = begin + EVAL_BATCH_SIZE<br>    if end &lt;= size:<br>      predictions[begin:end, :] = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[begin:end, …]})<br>    else:<br>      batch_predictions = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[-EVAL_BATCH_SIZE:, …]})<br>      predictions[begin:, :] = batch_predictions[begin - size:, :]<br>  return predictions</p>
<p>def error_rate(predictions, labels):<br>  “””Return the error rate based on dense predictions and sparse labels.”””<br>  return 100.0 - (100.0 * np.sum(np.argmax(predictions, 1) == labels) /<br>                  predictions.shape[0])</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def lunaTrain(VIEW_DIRECTORY, imgName, csvName):<br>  for cross in range(2):<br>    sssstttt = time.time()<br>    print(‘Cross {}…’.format(cross))<br>    WORK_DIRECTORY = os.path.join(VIEW_DIRECTORY, ‘Cross{}’.format(cross))<br>    testNo = str(cross)<br>    valNo = str((cross + 1) % 10)<br>    st = time.time()<br>    view_dataset = lunaDataSet(imgName, csvName, is_parallel=False)<br>    num_group_batches = 300<br>    train_group_size = [num_group_batches * BATCH_SIZE]<br>    val_labels, val_data = view_dataset.getValData(testNo, valNo, train_group_size[0])<br>    test_labels, test_data = view_dataset.getTestData(testNo, valNo, train_group_size[0])<br>    print(‘Reading validation and test data costs {:.2f} seconds…’.format(<br>        time.time() - st))</p>
<pre><code>num\_epochs = NUM\_EPOCHS
train\_size = view\_dataset.train_count
group\_count = int(math.ceil(float(train\_size) / train\_group\_size\[0\]))

train\_data\_node = tf.placeholder(tf.float32, shape=(
    BATCH\_SIZE, IMAGE\_SIZE, IMAGE\_SIZE, IMAGE\_SIZE, NUM_CHANNELS))
train\_labels\_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))
eval_data = tf.placeholder(tf.float32, shape=(
    EVAL\_BATCH\_SIZE, IMAGE\_SIZE, IMAGE\_SIZE, IMAGE\_SIZE, NUM\_CHANNELS))
keep_hidden = tf.placeholder(tf.float32)
logits = model(train\_data\_node, keep_hidden)
loss = tf.reduce\_mean(tf.nn.sparse\_softmax\_cross\_entropy\_with\_logits(
    logits, train\_labels\_node))

batch = tf.Variable(0)
learning\_rate = tf.train.exponential\_decay(0.01, batch * BATCH\_SIZE, train\_size / 10,
                                           0.95, staircase=True)
optimizer = tf.train.MomentumOptimizer(
    learning\_rate, 0.9).minimize(loss, global\_step=batch)
train_prediction = tf.nn.softmax(logits)
eval\_prediction = tf.nn.softmax(model(eval\_data, 1))

start_time = time.time()
saver = tf.train.Saver()
with tf.Session() as sess:
  tf.initialize\_all\_variables().run()
  print(&apos;Initialized!&apos;)
  st = time.time()
  summary\_writer = tf.train.SummaryWriter(WORK\_DIRECTORY, sess.graph)
  accumulate_count = 0
  TRAIN\_FREQUENCY = train\_size // BATCH_SIZE // 10
  VAL\_FREQUENCY = train\_size // BATCH_SIZE
  TEST\_FREQUENCY = VAL\_FREQUENCY * 2
  for groupstep in xrange(group_count):
    train\_data, train\_labels = view_dataset.getTrainData(
        testNo, valNo, train\_group\_size)
    if (train_data is 0):
      continue
    for step in xrange(int(math.ceil(train\_group\_size\[0\] * 1. / BATCH\_SIZE) * num\_epochs)):
      accumulate_count += 1
      offset = step * \
          BATCH\_SIZE % (train\_group\_size\[0\] - train\_group\_size\[0\] % BATCH\_SIZE)
      batch\_data = train\_data\[offset:(offset + BATCH_SIZE), ...\]
      if (batch\_data.shape\[0\] != BATCH\_SIZE):
        continue
      batch\_labels = train\_labels\[offset:(offset + BATCH_SIZE)\]
      feed\_dict = {train\_data\_node: batch\_data,
                   train\_labels\_node: batch\_labels, keep\_hidden: 0.5}
      _, l, lr, predictions = sess.run(\[optimizer, loss, learning\_rate, train\_prediction\],
                                       feed\_dict=feed\_dict)

      if accumulate\_count != 0 and accumulate\_count % TRAIN_FREQUENCY == 0:
        elapsed\_time = time.time() - start\_time
        start_time = time.time()
        print(&apos;Step %d (epoch %.2f), %.1f ms&apos; %
              (accumulate\_count, float(accumulate\_count) * BATCH\_SIZE / train\_size, 1000 * elapsed\_time / TRAIN\_FREQUENCY))
        print(&apos;Minibatch loss: %.3f, learning rate: %.6f&apos; % (l, lr))
        trE = error\_rate(predictions, batch\_labels)
        print(&apos;Minibatch error: %.3f%%&apos; % trE)
      if accumulate\_count != 0 and VAL\_FREQUENCY != 0 and accumulate\_count % VAL\_FREQUENCY == 0:
        valE = error\_rate(eval\_in_batches(
            val\_data, sess, eval\_prediction, eval\_data), val\_labels)
        print(&apos;Validation error: %.3f%%&apos; % valE)
        valPE = error\_rate(eval\_in_batches(
            val\_data\[view\_dataset.val\_no\_aug\_pos, ...\], sess, eval\_prediction, eval\_data), val\_labels\[view\_dataset.val\_no\_aug\_pos\])
        print(&apos;Validation error of no aug Positive: %.3f%%&apos; % valPE)
      if accumulate\_count != 0 and TEST\_FREQUENCY != 0 and accumulate\_count % TEST\_FREQUENCY == 0:
        test\_error = error\_rate(eval\_in\_batches(
            test\_data, sess, eval\_prediction, eval\_data), test\_labels)
        print(&apos;Test error: %.3f%%&apos; % test_error)
        test\_errorP = error\_rate(eval\_in\_batches(
            test\_data\[view\_dataset.test\_no\_aug\_pos, ...\], sess, eval\_prediction, eval\_data), test\_labels\[view\_dataset.test\_no\_aug\_pos\])
        print(&apos;Test error of no aug Positive: %.3f%%&apos; % test_errorP)
  else:
    checkpoint\_path = os.path.join(WORK\_DIRECTORY, &apos;model.ckpt&apos;)
    saver.save(sess, checkpoint\_path, global\_step=accumulate_count)
  print(&apos;Train finished in {:.2f} seconds...&apos;.format(time.time() - st))
  preds = eval\_in\_batches(test\_data, sess, eval\_prediction, eval_data)
  test\_error = error\_rate(preds, test_labels)
  with open(os.path.join(WORK_DIRECTORY, &apos;result.txt&apos;), &apos;w&apos;) as f:
    np.savetxt(f, np.c_\[preds, test_labels\])
  print(&apos;Test error: %.3f%%&apos; % test_error)
  test\_errorP = error\_rate(eval\_in\_batches(
      test\_data\[view\_dataset.test\_no\_aug\_pos, ...\], sess, eval\_prediction, eval\_data), test\_labels\[view\_dataset.test\_no\_aug\_pos\])
  print(&apos;Test error of no aug Positive: %.3f%%&apos; % test_errorP)
  print(&apos;All costs {:.2f} seconds...&apos;.format(time.time() - sssstttt))
  train\_data = val\_data = test_data = 0
  train\_labels = val\_labels = test_labels = 0
</code></pre><p>def main():<br>  viewPath = ‘/home/kong/400G/new_detect’<br>  csvName = ‘/home/kong/400G/new_detect/Shuffle.csv’</p>
<p>  imgName = ‘/home/kong/400G/new_detect/shuffle3D.bin’<br>  lunaTrain(viewPath, imgName, csvName)</p>
<p>if __name__ == ‘__main__‘:<br>  main()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/11/06/3d/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/06/3d/" itemprop="url">3D</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-11-06T21:48:00+08:00">
                2016-11-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Generate-CSV-file"><a href="#Generate-CSV-file" class="headerlink" title="Generate CSV file"></a>Generate CSV file</h1><p>import csv<br>import random<br>import numpy as np</p>
<p>PI = np.pi</p>
<p>csvName = ‘/home/kong/400G/new_detect/augTable.csv’</p>
<p># 71<br>with open(csvName, ‘wb’) as f:<br>  csvwriter = csv.writer(f)<br>  firstLine = [‘augID’]<br>  firstLine.append(‘rotateAngleX’)<br>  firstLine.append(‘rotateAngleY’)<br>  firstLine.append(‘rotateAngleZ’)<br>  firstLine.append(‘displacementX’)<br>  firstLine.append(‘displacementY’)<br>  firstLine.append(‘displacementZ’)<br>  firstLine.append(‘zoom’)<br>  csvwriter.writerow(firstLine)<br>  for i in range(71):<br>    if i &lt; 20:<br>      line = [i]<br>      line.extend([0, 0, 0, 0, 0, 0, 1])<br>      csvwriter.writerow(line)<br>    else:<br>      line = [i]<br>      line.append(‘{:.2f}’.format(random.random() <em> PI / 6))<br>      line.append(‘{:.2f}’.format(random.random() </em> PI / 6))<br>      line.append(‘{:.2f}’.format(random.random() <em> PI / 6))<br>      line.append(random.randint(-5, 5))<br>      line.append(random.randint(-5, 5))<br>      line.append(random.randint(-5, 5))<br>      line.append(‘{:.2f}’.format(1 + random.random() </em> 0.2 - 0.1))<br>      csvwriter.writerow(line)</p>
<h1 id="Generate-Binary-files"><a href="#Generate-Binary-files" class="headerlink" title="Generate Binary files:"></a>Generate Binary files:</h1><p>import csv<br>import os<br>import numpy as np<br>import SimpleITK as sitk<br>import time<br>import sys<br>import pprocess<br>import cv2<br>from scipy.ndimage.interpolation import zoom</p>
<p>CUT_SIZE = 64<br>SAVE_SIZE = 40</p>
<p>def createPatchCoodinates(centralCoor, size):<br>  topMostPoint = np.array(<br>      [centralCoor[0] - size / 2, centralCoor[1] - size / 2, centralCoor[2] - size / 2])<br>  pointOne = np.array([centralCoor[0] + size / 2, centralCoor[1] -<br>                       size / 2, centralCoor[2] - size / 2])<br>  pointTwo = np.array([centralCoor[0] - size / 2, centralCoor[1] +<br>                       size / 2, centralCoor[2] - size / 2])<br>  pointThree = np.array(<br>      [centralCoor[0] - size / 2, centralCoor[1] - size / 2, centralCoor[2] + size / 2])</p>
<p>  coordinates = np.vstack((topMostPoint, pointOne, pointTwo, pointThree))<br>  return coordinates</p>
<p>def translate(coordinates, translation):<br>  translation = np.vstack((translation, translation, translation, translation))<br>  coordinates = coordinates + translation<br>  return coordinates</p>
<p>def zoom_diy(coordinates, zoomCenter, scale):<br>  for i in range(coordinates.shape[0]):<br>    coordinates[i, :] = (coordinates[i, :] - zoomCenter) * scale + zoomCenter<br>  return coordinates</p>
<p>def rotate(coordinates, rotateCenter, rotateAngle):<br>  rotation = sitk.Euler3DTransform()<br>  rotation.SetCenter(rotateCenter)<br>  rotation.SetRotation(rotateAngle[0], rotateAngle[1], rotateAngle[2])<br>  coordinates = np.array(coordinates, np.int32)<br>  for i in range(coordinates.shape[0]):<br>    point = np.array(coordinates, np.float)<br>    point = tuple(point[i, :])<br>    rotatePoint = rotation.TransformPoint(point)<br>    coordinates[i, :] = np.array(rotatePoint)</p>
<p>  return coordinates</p>
<p>def pointBoardcastToMatrix(coordinates, patchSize):<br>  topMostPoint, pointOne, pointTwo, pointThree = coordinates[<br>      0], coordinates[1], coordinates[2], coordinates[3]</p>
<p>  point1VectorZ = np.linspace(<br>      0, pointOne[0] - topMostPoint[0], patchSize).reshape(patchSize, 1, 1)<br>  point1VectorY = np.linspace(<br>      0, pointOne[1] - topMostPoint[1], patchSize).reshape(patchSize, 1, 1)<br>  point1VectorX = np.linspace(<br>      0, pointOne[2] - topMostPoint[2], patchSize).reshape(patchSize, 1, 1)<br>  point2VectorZ = np.linspace(<br>      0, pointTwo[0] - topMostPoint[0], patchSize).reshape(patchSize, 1)<br>  point2VectorY = np.linspace(<br>      0, pointTwo[1] - topMostPoint[1], patchSize).reshape(patchSize, 1)<br>  point2VectorX = np.linspace(<br>      0, pointTwo[2] - topMostPoint[2], patchSize).reshape(patchSize, 1)<br>  point3VectorZ = np.linspace(0, pointThree[0] - topMostPoint[0], patchSize)<br>  point3VectorY = np.linspace(0, pointThree[1] - topMostPoint[1], patchSize)<br>  point3VectorX = np.linspace(0, pointThree[2] - topMostPoint[2], patchSize)</p>
<p>  xCoorMatrix = point1VectorX + point2VectorX + point3VectorX + topMostPoint[2]<br>  yCoorMatrix = point1VectorY + point2VectorY + point3VectorY + topMostPoint[1]<br>  zCoorMatrix = point1VectorZ + point2VectorZ + point3VectorZ + topMostPoint[0]</p>
<p>  coordinates = [zCoorMatrix, yCoorMatrix, xCoorMatrix]<br>  return coordinates</p>
<p>def neighbourInterpolate(coordinates, oriImage):<br>  coordinates = np.round(coordinates).astype(np.int16)<br>  zCoorMatrix, yCoorMatrix, xCoorMatrix = coordinates[0], coordinates[1], coordinates[2]<br>  shape = zCoorMatrix.shape<br>  zCoorLine = tuple(zCoorMatrix.reshape(1, -1)[0])<br>  yCoorLine = tuple(yCoorMatrix.reshape(1, -1)[0])<br>  xCoorLine = tuple(xCoorMatrix.reshape(1, -1)[0])<br>  totalCoor = [zCoorLine, yCoorLine, xCoorLine]<br>  interpolatedImage = oriImage[totalCoor].reshape(shape)<br>  return interpolatedImage</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def normalizePlanes(npzarray):<br>  maxHU = 400.<br>  minHU = -1000.<br>  npzarray = (npzarray - minHU) / (maxHU - minHU)<br>  npzarray[npzarray &gt; 1] = 1.<br>  npzarray[npzarray &lt; 0] = 0.<br>  return npzarray</p>
<p>def saveImageSlice(image, path):<br>  if not os.path.exists(path):<br>    os.makedirs(path)<br>  for index in np.arange(image.shape[0]):<br>    sliceTemp = image[index, :, :]<br>    cv2.imwrite(path + str(index) + ‘.png’, sliceTemp * 255)</p>
<p>def worldToVoxelCoord(worldCoord, origin, outputSpacing):<br>  stretchedVoxelCoord = np.absolute(worldCoord - origin)<br>  voxelCoord = stretchedVoxelCoord / outputSpacing<br>  return voxelCoord</p>
<p>def view_bar(args, num, total):<br>  rate = 1.0 <em> num / total<br>  rate_num = int(rate </em> 100)<br>  r = ‘\rProcess {} task percentage (%): ‘.format(args) + ‘{}’.format(rate_num)<br>  sys.stdout.write(r)<br>  sys.stdout.flush()</p>
<p>def aug3d(borderedImage, rotateCenter, rotateAngle, displacement, zoomScale, patchSize):<br>  coordinates = createPatchCoodinates(rotateCenter, patchSize)<br>  coordinates = translate(coordinates, displacement)<br>  coordinates = rotate(coordinates, rotateCenter, rotateAngle)<br>  coordinates = zoom_diy(coordinates, rotateCenter, zoomScale)<br>  coordinates = pointBoardcastToMatrix(coordinates, patchSize)<br>  interpolatedImage = neighbourInterpolate(coordinates, borderedImage)<br>  return interpolatedImage</p>
<p>def interpolatefilter(inputpath):<br>  inputimage = sitk.ReadImage(inputpath)<br>  origin = inputimage.GetOrigin()<br>  spacing = inputimage.GetSpacing()<br>  direction = inputimage.GetDirection()<br>  outputspacing = (spacing[0], spacing[0], spacing[0])<br>  size = inputimage.GetSize()<br>  tmp = int(spacing[2] * size[2] / spacing[0])<br>  if tmp % 2 != 0:<br>    tmp = tmp - 1</p>
<p>  outputsize = (size[0], size[1], tmp)</p>
<p>  resamplefilter = sitk.ResampleImageFilter()<br>  resamplefilter.SetOutputDirection(direction)<br>  resamplefilter.SetSize(outputsize)<br>  resamplefilter.SetOutputOrigin(origin)<br>  resamplefilter.SetOutputSpacing(outputspacing)<br>  outputimage = resamplefilter.Execute(inputimage)<br>  outputsize = outputimage.GetSize()<br>  numpyImage = sitk.GetArrayFromImage(outputimage)<br>  numpyImage = normalizePlanes(numpyImage)<br>  return numpyImage, list(outputsize), spacing</p>
<p>def createImageBorder(numpyImage, outputsize):<br>  BackImage = np.zeros(((800, 800, 800)))<br>  BackImage[400 - int(outputsize[2] / 2):400 + int(outputsize[2] / 2),<br>            400 - int(outputsize[1] / 2):400 + int(outputsize[1] / 2),<br>            400 - int(outputsize[0] / 2):400 + int(outputsize[0] / 2)] = numpyImage<br>  return BackImage</p>
<p>def write_csv(processorID, line_start, line_end):<br>  fBin = open(os.path.join(binOutputPath + ‘/‘ +<br>                           ‘view{}’.format(processorID) + ‘.bin’), ‘wb’)<br>  uidTemp = -1<br>  for line in xrange(line_start, line_end):<br>    cand = csvLines[line]</p>
<pre><code>rotateAngle = np.array(augLines\[int(cand\[-1\])\]\[1:4\], np.float)\[::-1\]
displacement = np.array(augLines\[int(cand\[-1\])\]\[4:7\], np.int)\[::-1\]
zoomScale = float(augLines\[int(cand\[-1\])\]\[-1\])
if cand\[2\] != uidTemp:
  mhdOriginalPath = originalPath + &apos;/subset{}/{}.mhd&apos;.format(cand\[1\], cand\[2\])
  interpolatedImage, outputsize, spacing = interpolatefilter(mhdOriginalPath)
  BackImage = createImageBorder(interpolatedImage, outputsize)
  uidTemp = cand\[2\]
  print &apos;\\n{}&apos;.format(cand\[2\])

rotateCenter = np.round(np.array(cand\[5:2:-1\], np.float) * spacing\[::-1\] / spacing\[0\])
rotateCenter += (400 - np.array(outputsize\[::-1\]) / 2)
augImage = aug3d(BackImage, rotateCenter, rotateAngle,
                 displacement, zoomScale, CUT_SIZE)
augImage = zoom(augImage, float(SAVE\_SIZE) / CUT\_SIZE)
# saveImageSlice(augImage, &apos;test/&apos;)
# imageCompare = BackImage\[rotateCenter\[0\] - 20:rotateCenter\[0\] + 20,
#                          rotateCenter\[1\] - 20:rotateCenter\[1\] + 20,
#                          rotateCenter\[2\] - 20:rotateCenter\[2\] + 20\]
# saveImageSlice(imageCompare, &apos;test1/&apos;)
fBin.write(chr(int(cand\[-2\])))
augImage.astype(&apos;float32&apos;).tofile(fBin)

# real time plot the task progress
if (line - line_start) % 10 == 0:
  view\_bar(1, line - line\_start, line\_end - line\_start - 1)
elif line == line\_end - line\_start - 1:
  view\_bar(1, line - line\_start, line\_end - line\_start - 1)
</code></pre><p>  fBin.close()</p>
<p># Global parameters</p>
<p>csvName = ‘/home/kong/400G/new_detect/LUNASTable.csv’<br>augName = ‘/home/kong/400G/new_detect/augTable.csv’<br>originalPath = ‘/home/kong/4T/nodule_project’<br>binOutputPath = ‘/home/kong/400G/new_detect’<br>csvLines = readCSV(csvName)[1:]<br>augLines = readCSV(augName)[1:]</p>
<p>ProcessorNum = pprocess.get_number_of_cores() - 1</p>
<p>def main():</p>
<h1 id="series-do"><a href="#series-do" class="headerlink" title="series do"></a>series do</h1><h1 id="st-time-time"><a href="#st-time-time" class="headerlink" title="st = time.time()"></a>st = time.time()</h1><h1 id="write-csv-0-0-len-csvLines"><a href="#write-csv-0-0-len-csvLines" class="headerlink" title="write_csv(0, 0, len(csvLines))"></a>write_csv(0, 0, len(csvLines))</h1><h1 id="print-‘-nseries-costs-2f-seconds…’-format-time-time-st"><a href="#print-‘-nseries-costs-2f-seconds…’-format-time-time-st" class="headerlink" title="print(‘\nseries costs {:.2f} seconds…’.format(time.time() - st))"></a>print(‘\nseries costs {:.2f} seconds…’.format(time.time() - st))</h1><h1 id="parallel-do"><a href="#parallel-do" class="headerlink" title="parallel do"></a>parallel do</h1><h1 id="define-parallel-parameters"><a href="#define-parallel-parameters" class="headerlink" title="define parallel parameters"></a>define parallel parameters</h1><p>  list_of_args = range(ProcessorNum)<br>  group_num = len(csvLines) // ProcessorNum<br>  cutPoint = np.empty([ProcessorNum, 2], dtype=int)<br>  for row in range(ProcessorNum):</p>
<pre><code># start point
cutPoint\[row, 0\] = row * group_num
if row == ProcessorNum - 1:
  # stop point
  cutPoint\[row, 1\] = len(csvLines)
else:
  # stop point
  cutPoint\[row, 1\] = row * group\_num + group\_num - 1 + 1
</code></pre><h1 id="starting-parallel-reading"><a href="#starting-parallel-reading" class="headerlink" title="starting parallel reading"></a>starting parallel reading</h1><p>  st = time.time()<br>  results = pprocess.Map()<br>  parallel_function = results.manage(pprocess.MakeParallel(write_csv))<br>  for args in list_of_args:<br>    parallel_function(args, cutPoint[args, 0], cutPoint[args, 1])<br>  print(‘\nStarting Parallel time {:.2f} seconds…’.format(time.time() - st))</p>
<p>  st = time.time()<br>  results[:]</p>
<h1 id="parallel-results-results"><a href="#parallel-results-results" class="headerlink" title="parallel_results = results[:]"></a>parallel_results = results[:]</h1><p>  print(‘\nParallel costs {:.2f} seconds…’.format(time.time() - st))</p>
<p>if __name__ == ‘__main__‘:<br>  main()</p>
<h1 id="a-np-zeros-10-10-np-float"><a href="#a-np-zeros-10-10-np-float" class="headerlink" title="a=np.zeros((10,10),np.float)"></a>a=np.zeros((10,10),np.float)</h1><h1 id="a-0-8-1-6-1"><a href="#a-0-8-1-6-1" class="headerlink" title="a[0:8,1:6]=1"></a>a[0:8,1:6]=1</h1><h1 id="a-8-8-1"><a href="#a-8-8-1" class="headerlink" title="a[8,8]=1"></a>a[8,8]=1</h1><h1 id="print-a"><a href="#print-a" class="headerlink" title="print a"></a>print a</h1><h1 id="b-transform-rotate-a-60"><a href="#b-transform-rotate-a-60" class="headerlink" title="b=transform.rotate(a,60)"></a>b=transform.rotate(a,60)</h1><h1 id="print-b"><a href="#print-b" class="headerlink" title="print b"></a>print b</h1><h1 id="fig-plt-figure"><a href="#fig-plt-figure" class="headerlink" title="fig=plt.figure()"></a>fig=plt.figure()</h1><h1 id="ax-fig-add-subplot-2-1-1"><a href="#ax-fig-add-subplot-2-1-1" class="headerlink" title="ax = fig.add_subplot(2,1,1)"></a>ax = fig.add_subplot(2,1,1)</h1><h1 id="ax-imshow-a"><a href="#ax-imshow-a" class="headerlink" title="ax.imshow(a)"></a>ax.imshow(a)</h1><h1 id="ax-fig-add-subplot-2-1-2"><a href="#ax-fig-add-subplot-2-1-2" class="headerlink" title="ax = fig.add_subplot(2,1,2)"></a>ax = fig.add_subplot(2,1,2)</h1><h1 id="ax-imshow-b"><a href="#ax-imshow-b" class="headerlink" title="ax.imshow(b)"></a>ax.imshow(b)</h1><h1 id="plt-show"><a href="#plt-show" class="headerlink" title="plt.show()"></a>plt.show()</h1><p>  print ‘finished’</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/10/06/bash-to-install-tensorflow-in-ubuntu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/10/06/bash-to-install-tensorflow-in-ubuntu/" itemprop="url">Ubuntu上安装TensorFlow脚本备忘</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-10-06T17:44:33+08:00">
                2016-10-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[shell]#!/bin/bash # uninstall amazon # uninstall libreOffice sudo apt-get update sudo add-apt-repository ppa:hzwhuang/ss-qt5 sudo apt-get update sudo apt-get install shadowsocks-qt5[/shell] [shell] # install fonts # Fira Code: <a href="https://github.com/tonsky/FiraCode" target="_blank" rel="noopener">https://github.com/tonsky/FiraCode</a> # fonts is stored in ~/Downloads/ # cd /usr/share/fonts # sudo mkdir -p winFonts # sudo cp ~/Downloads/<em>.ttf winFonts # cd winFonts # sudo chmod 644 </em>.ttf # sudo mkfontscale # sudo mkfontdir # sudo fc-cache -fv # sudo cp -r your_Chrome_config_path/.config/google-chrome ~/.config/google-chrome # Firefox install addons –&gt; autoProxy # setup the proxy to download Chrome and install it # run from terminal using google-chrome –proxy-server=socks5://127.0.0.1:1080 # to start chrome and login your google account to Synchronize your settings # uninstall Firefox # sudo cp sudo cp -r your_easystroke_configuration_path/.easystroke ~/ sudo apt-get install easystroke # setting resolution cvt 1440 900 sudo xrandr –newmode “1440x900_60.00” 106.50 1440 1528 1672 1904 900 903 909 934 -hsync +vsync sudo xrandr –addmode VGA-0 1440x900_60.00 # add to system # sudo gedit ~/.profile and add: sudo echo “cvt 1440 900” &gt;&gt; ~/.profile sudo echo ‘sudo xrandr –newmode “1440x900_60.00” 106.50 1440 1528 1672 1904 900 903 909 934 -hsync +vsync’ &gt;&gt; ~/.profile sudo echo “sudo xrandr –addmode VGA-0 1440x900_60.00” &gt;&gt; ~/.profile # sudo cp -r your_vscode_configuration_path/.vscode ~/ # sudo cp -r your_vscode_config_path/.config/Code ~/.config/Code # download VScode deb package and install it sudo apt-get install nautilus-open-terminal sudo apt-get install htop sudo add-apt-repository ppa:shutter/ppa sudo apt-get update &amp;&amp; sudo apt-get install shutter # ref: <a href="http://blog.csdn.net/songrotek/article/details/50770154" target="_blank" rel="noopener">http://blog.csdn.net/songrotek/article/details/50770154</a> # ref: <a href="https://github.com/saiprashanths/dl-setup" target="_blank" rel="noopener">https://github.com/saiprashanths/dl-setup</a> # sudo edit /etc/modprobe.d/blacklist-nouveau.conf sudo echo “blacklist nouveau” &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf sudo echo “blacklist lbm-nouveau” &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf sudo echo “options nouveau modeset=0” &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf sudo echo “alias nouveau off” &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf sudo echo “alias lbm-nouveau off” &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf sudo update-initramfs -u sudo reboot sudo apt-get update sudo apt-get upgrade sudo apt-get install build-essential cmake g++ gfortran git pkg-config python-dev software-properties-common wget sudo apt-get autoremove sudo rm -rf /var/lib/apt/lists/<em> # Ctrl+Alt+F1 to tty1 sudo service lightdm stop sudo sh cuda</em>.run –no-opengl-libs sudo service lightdm start # sudo gedit ~/.bashrc to add Path sudo echo “export CUDA_HOME=/usr/local/cuda” &gt;&gt; ~/.bashrc sudo echo “export PATH=$PATH:/usr/local/cuda/bin” &gt;&gt; ~/.bashrc sudo echo “export LD_LIBRARY_PATH=:/usr/local/cuda/lib64” &gt;&gt; ~/.bashrc # then source source ~/.bashrc # validate the installation cd /usr/local/cuda/samples/1_Utilities/deviceQuery sudo make sudo ./deviceQuery # or using nvcc -V nvidia-smi # install cudnn # cudnn-7.5-linux-x64-v5.1 tar -zxf cudnn<em>.tgz cd cuda sudo cp lib64/</em> /usr/local/cuda/lib64/ sudo cp include/cudnn.h /usr/local/cuda/include/ sudo chmod a+r /usr/local/cuda/lib64/libcudnn<em> # may need to run: sudo ldconfig /usr/local/cuda/lib64 # update your system sudo apt-get update &amp;&amp; sudo apt-get upgrade sudo apt-get install linux-source sudo apt-get install linux-headers-`uname -r` # prepare to install deep learning libraries sudo apt-get update &amp;&amp; sudo apt-get install -y python-numpy python-scipy python-nose python-h5py python-skimage python-matplotlib python-pandas python-sklearn python-sympy sudo apt-get install python-pip python-dev sudo apt-get clean &amp;&amp; sudo apt-get autoremove rm -rf /var/lib/apt/lists/</em> # install TensorFlow # restore /.pip/pip.conf to the original state export TF_BINARY_URL=<a href="https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux\_x86\_64.whl" target="_blank" rel="noopener">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux\_x86\_64.whl</a> sudo pip install –upgrade $TF_BINARY_URL # if having errors running TensorFlow, copy links manually using libcudnn.so.5.0.5 # to make links of libcudnn.so and libcudnn.so.5.0 # after install TensorFlow, modify /.pip/pip.conf to use the mirror in China # [global] # index-url = <a href="https://pypi.tuna.tsinghua.edu.cn/simple/" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple/</a> # install SimpleITK sudo pip install <a href="https://sourceforge.net/projects/simpleitk/files/SimpleITK/0.9.1/Python/SimpleITK-0.9.1-cp27-none-linux\_x86\_64.whl#md5=1cd1bc22eb8072ab7fc63212a56c47c7" target="_blank" rel="noopener">https://sourceforge.net/projects/simpleitk/files/SimpleITK/0.9.1/Python/SimpleITK-0.9.1-cp27-none-linux\_x86\_64.whl#md5=1cd1bc22eb8072ab7fc63212a56c47c7</a> # install iPython (using it: ipython notebook ipynb_file_path) sudo apt-get update sudo pip install IPython sudo pip install jupyter sudo apt-get install python-vigra sudo apt-get install python-opencv ## install oh-my-zsh (!don’t use it, or it will cause cudnn error) # sudo rm -r .oh-my-zsh/ # sudo apt-get install zsh # wget <a href="https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh" target="_blank" rel="noopener">https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh</a> -O - | sh # chsh -s /bin/zsh # sudo gedit .zshrc #change theme to ‘ys’ # install autopep8 sudo pip install –upgrade autopep8 # install pinyin-input sudo apt-get remove ibus sudo apt-get autoremove sudo apt-get update sudo dpkg -i sogou*.deb # Terminal run ‘im-config’ to select fcitx # Terminal run ‘fcitx-config-gtk3’ to add ‘sogou’ (need unselect ‘Only Show Current Language’) # ref: <a href="http://www.voidcn.com/blog/Lmerissa/article/p-5016128.html" target="_blank" rel="noopener">http://www.voidcn.com/blog/Lmerissa/article/p-5016128.html</a> # if control center not completed using # sudo apt-get remove unity-control-center # sudo apt-get install unity-control-center sudo pip install pprocess[/shell]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/08/26/generate-augmentation-table/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/08/26/generate-augmentation-table/" itemprop="url">生成augmentation Table</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-08-26T21:27:53+08:00">
                2016-08-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>根据augmentation的需求，如augmentation多少个，使用什么样的augmentation等等，生成一个augmentation Table，以供后续使用。</p>
<p>‘’’Write the table of augmentation ID</p>
<p>Author: Kong Haiyang<br>‘’’<br>import csv<br>import numpy as np</p>
<p>filename = ‘/home/kong/400G/augTable.csv’</p>
<p>with open(filename, ‘wb’) as f:<br>    zoom = np.linspace(-0.1, 0.1, 7)<br>    rotate = np.linspace(-20, 20, 7)<br>    moveud = np.linspace(-1, 1, 3)<br>    movelr = np.linspace(-1, 1, 3)<br>    csvwriter = csv.writer(f, delimiter=’,’)<br>    line = []<br>    line.append(‘augID’)<br>    line.append(‘zoomID’)<br>    line.append(‘rotateID’)<br>    line.append(‘moveUDID’)<br>    line.append(‘moveLRID’)<br>    csvwriter.writerow(line)<br>    line[0] = 0<br>    line[1] = 0<br>    line[2] = 0<br>    line[3] = 0<br>    line[4] = 0<br>    csvwriter.writerow(line)<br>    countAug = 1<br>    for i in range(7):<br>        for j in range(7):<br>            for k in range(3):<br>                for l in range(3):<br>                    if not(zoom[i] or rotate[j] or moveud[k] or movelr[l]):<br>                        continue<br>                    line[0] = countAug<br>                    line[1] = zoom[i]<br>                    line[2] = rotate[j]<br>                    line[3] = moveud[k]<br>                    line[4] = movelr[l]<br>                    csvwriter.writerow(line)<br>                    countAug += 1<br>                    if countAug == 408:<br>                        break<br>                if countAug == 408:<br>                    break<br>            if countAug == 408:<br>                break<br>        if countAug == 408:<br>            break</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/05/31/a-note-to-install-tensorflow-on-ubuntu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/05/31/a-note-to-install-tensorflow-on-ubuntu/" itemprop="url">安装Ubuntu搭建TensorFlow框架笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-05-31T21:15:09+08:00">
                2016-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>既已转行，自然需要全心投入深度学习的探索和研究之中。深度学习的学习和实现离不开一些经典的深度学习框架，从Caffe到Theano，从MXnet到TensorFlow，优秀的框架层出不穷，但我想基于Google目前在深度学习领域的地位，以及Google推出TensorFlow之后受到的关注和影响，TensorFlow都不容忽视。又加之最近TensorFlow在迭代更新之后，已经没有了明显的短板和弱点，而我自己对深度学习的入门和研究也日渐需要一个平台框架来实现一些东西，思虑再三，决定开始选定并搭建TensorFlow环境了。 搭建TensorFlow特别容易，要么是Linux下一行命令，要么是Windows下使用docker，但很遗憾，我在Windows下安装docker出了问题，而刚好，公司给我们几个博士一人配了一台很不错的新电脑，以便进行深度学习的研究，既然电脑是全新的，而考虑到深度学习的研发通常都是在Ubuntu上进行，既然绕不开，就果断装一个，索性折腾一番吧。 但是自此开始，我进了坑。 原本电脑上安装的有Windows 7，加之我对Ubuntu并不熟悉，权衡之下，决定安装双系统。从Windows 7下直接硬盘安装Ubuntu的教程网上比比皆是，但我的安装却没有那么顺利。要么是磁盘出现各种错误提示，诸如： [shell]Filesystem type is ntfs, partition type 0x07[/shell] [shell]Filesystem type is fat, partition type 0x0c[/shell] 要么是安装完成，但重启之后，直接进不了系统，只是在暗色的屏幕的左上角闪动着一个白色短划线的鼠标符号。面对这样的情况，我真是直接无语了。无奈，只好放弃了一段时间，还好，当时我对TensorFlow的搭建需求并不迫切。好吧，其实是我当时已经山穷水尽没有招数了。 再后来，我想着这样也不是办法，便找到了公司负责网络和计算机的同事，让他帮忙看看是怎么回事儿。他直接把电脑搬走了，准备亲自处理。一周之后，我发现他依然还在努力着试图解决这个让人无语的问题，甚至他把电脑的装机商都找了来，却依然束手无策。 我有些等不及了，去找了他，仔细地问了一下进展。结果发现，他把连接在独显上的显示器线改到了集显（主板）上，安装完Ubuntu之后，已经可以进入系统，但独显并不能直接用，因为Ubuntu自身似乎没有带这块Titan X显卡的驱动。 我们当时压根没有经验，而且也没有想到问题的复杂性，便从网上搜索，然后去NVIDIA的官网下载了驱动，安装虽然并不容易，诸如需要首先屏蔽nouveau，关闭X server等等，但一路也是安装了下来。 然而，安装完成重启时，问题来了，在Ubuntu的用户登录界面上，我们正确地输入了密码，但是系统黑了一下屏幕，却再次回到了登录界面上，系统依然进不去。我已经彻底无语了。 还好，那个周末在华为有一个深度学习的meetup，我抱着求助的心态去了。虽然最后也没有找到什么明确的主意，但有个朋友告诉我他按照CSDN上的一篇博客里的方法成功了。我如获至宝一样，从那个会上回来后，就赶快趁着周末又折腾了起来。 不过可能是我陷的坑比较深吧，依然没有成功爬出来。安装完重启之后，最开始虽然能进入系统，但安装完CUDA后，按教程执行重启，依然进不去系统，还是卡在用户登录的界面。可这时，我竟然在搜索一圈没有找到可用的方法之后，愚蠢地选择了重装。当然，在重装系统后，安装完CUDA，按有些教程上所说的，不选择[shell]sudo apt-get upgrade[/shell]，不过依然没用，重启还是进不了系统。 不知道最后是上天垂怜，还是我基本上把所有的坑已经都蹚遍了，最后在一篇教程中看到说使用deb包安装CUDA时，其中的opengl把系统原来的给覆盖了，导致系统无法加载桌面，改成使用.run包进行安装，安装时配上参数[shell]–no-opengl-libs[/shell]即可。 终于，在最后的最后，我成功地安装好了Ubuntu系统和显卡驱动，以及使用显卡进行计算所需的CUDA和cuDNN驱动程序。进行到这里，搭建TensorFlow，已经不过是一句命令的事情了。 最后，将整个过程简记如下：</p>
<blockquote>
<p>1.进入BIOS，修改显卡的优先级顺序，将Onboard VGA放到第一位，我们使用集显用于显示，将独显留出来用于计算； 2.重启，如果显示器连接线连接到了独显上，在重启的过程中将其更改到直接连接在主板上的VGA口上，否则显示器会没有内容可显示； 3.使用U盘启动盘安装Ubuntu，选择擦除整个磁盘，系统自动分区的方法进行安装：Erase disk and Install Ubuntu； 4.安装完成Ubuntu后，不要安装显卡驱动，选择直接以.run文件安装CUDA，因为其中带有显卡驱动（<a href="http://blog.csdn.net/songrotek/article/details/50770154" target="_blank" rel="noopener">参考这篇文章中的相应内容</a>）：</p>
<p>4.1关闭与Nvidia内核不兼容的nouveau 4.2Ctrl+Alt+F1进入tty下，关闭lightdm(X driver)：[shell]sudo service lightdm stop[/shell]，然后安装cuda：[shell]sudo sh cuda*.run –no-opengl-libs[/shell]；安装完毕重新启动lightdm：[shell]sudo service lightdm start[/shell]</p>
<p>； 5.随后安装cuDNN等，然后重启，安装完成； 6.如果系统分辨率不能调整，比如显示器显示unknown display，则使用网上如cvt等方法手动添加分辨率，进行设置； 7.安装TensorFlow，完成。</p>
</blockquote>
<p>总结一下，我想我的问题和难度在于，我的电脑有3块硬盘，单是安装Ubuntu就走了许多弯路，然后显卡和显示器的切换又碰到了不少问题，最后就是安装显卡的驱动时，又有许多弯路没有避开。设想一下，如果最开始就站在把问题综合考虑起来的高度，以 Ubuntu NVIDIA Titan X Deep learning 为关键词进行搜索，或许会少遇到许多问题吧。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="John Doe" />
          <p class="site-author-name" itemprop="name">John Doe</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">434</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">108</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
