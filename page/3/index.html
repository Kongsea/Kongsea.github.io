<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://kongsea.github.io/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://kongsea.github.io/page/3/"/>





  <title>Hexo</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2017/memo-python-regular-expression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/memo-python-regular-expression/" itemprop="url">Python正则表达式简记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-22T11:39:45+08:00">
                2017-04-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>正则表达式听起来有些让人头痛，但有时候又特别有用，尤其是一些程序中，其更是避不开的存在。不过Python提供了一个方便使用和处理正则表达式的包——re模块，使得在Python中使用正则表达式十分方便。可虽然如此，对正则表达式还是需要进行一番学习，方能在使用时得心应手，挥洒自如。 虽然目前我对正则表达式的学习和掌握还远远达不到这个境界，不过以目前的掌握，也已经足够在写代码时使用了。下面就对这些东西进行一下记录，以方便以后复习和使用。</p>
<h1 id="1-匹配字母、数字和任意字符"><a href="#1-匹配字母、数字和任意字符" class="headerlink" title="1.匹配字母、数字和任意字符"></a>1.匹配字母、数字和任意字符</h1><blockquote>
<p>1.可以直接使用任意字符匹配其本身，但如以下所列有特殊意义的字符除外； 2.使用.(英文句号)匹配任意除换行符(‘\n’)之外的字符； 3.使用\w匹配任意单词字符，包括大小写英文字母、数字及下划线（_）； 4.使用\d匹配任意数字； 5.可以使用[]内放字符来匹配其中的任意字符，如[abc]匹配任意a或b或c，如[a-z]匹配任意小写字母； 6.因为.用来匹配任意字符，所以匹配.要使用\来转义，即：\.；但放在[]内例外，放在[]内的.只表示普通的.。</p>
</blockquote>
<h1 id="2-指定开头匹配、结尾匹配"><a href="#2-指定开头匹配、结尾匹配" class="headerlink" title="2.指定开头匹配、结尾匹配"></a>2.指定开头匹配、结尾匹配</h1><blockquote>
<p>有时候需要指定是在开头还是结尾匹配，比如看文件名是否以yueye开头，等等。 当然，指定以yueye开头可以直接使用’yueye’进行匹配，但指定结尾以及同时指定开头和结尾还不能直接使用这种形式。可以使用以下方式： 1.指定开头，以^表示，如：’^\d’指示以数字开头； 2.指定结尾，以$表示，如：’\d$’指示以数字结尾。 即指示开头的^放在字符串开头，指示结尾的$放在字符串结尾。</p>
</blockquote>
<h1 id="3-指定连续多少个"><a href="#3-指定连续多少个" class="headerlink" title="3.指定连续多少个"></a>3.指定连续多少个</h1><blockquote>
<p>有时候需要指定匹配连续多少个数字，或者连续多少个某字符，使用以下方式： 1.’?’指示0次或1次，即最多一次，可能没有； 2.’*’指示0次或多次，即可能没有； 3.’+’指示1次或多次，即至少一次； 4.{}指示固定次数，如’\d{3}’表示三个数字。</p>
</blockquote>
<h1 id="4-使用规范"><a href="#4-使用规范" class="headerlink" title="4.使用规范"></a>4.使用规范</h1><p>Python中re模块的使用通常如下（匹配以数字开头的.py文件）：</p>
<p>import re<br>c = re.compile(‘^\d.<em>\.py’)<br>m = re.match(c, ‘2python.py’) #可以先将匹配模式compile了，也可以直接将其传入，即 m = re.match(‘^\d.</em>\.py’, ‘2python.py’)<br>if m:</p>
<h1 id="如果匹配，返回m是一个-sre-SRE-Match的object，m-group-返回匹配结果"><a href="#如果匹配，返回m是一个-sre-SRE-Match的object，m-group-返回匹配结果" class="headerlink" title="如果匹配，返回m是一个_sre.SRE_Match的object，m.group()返回匹配结果"></a>如果匹配，返回m是一个_sre.SRE_Match的object，m.group()返回匹配结果</h1><p>else:</p>
<p>  #如果不匹配，返回m是None</p>
<h1 id="5-示例"><a href="#5-示例" class="headerlink" title="5.示例"></a>5.示例</h1><p>此处仅举一些我碰到的一些例子： 找到当前目录下所有以view开头紧跟数字（至少有一个数字）命名的.bin文件：</p>
<p>import re<br>bin_names = [p for _, _, pt in walk(os.getcwd()) for p in pt if re.match(‘^view\d+\.bin$’, p)]</p>
<p>判断用户输入是否符合邮箱格式：</p>
<p>import re<br>m = re.match(‘[\w.-]+@\w+\.\w+’, input)<br>if m:</p>
<h1 id="input-is-an-email-address"><a href="#input-is-an-email-address" class="headerlink" title="input is an email address"></a>input is an email address</h1><p>else:</p>
<h1 id="input-is-not-an-email-address"><a href="#input-is-not-an-email-address" class="headerlink" title="input is not an email address"></a>input is not an email address</h1><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://oncemore2020.github.io/blog/python-re/" target="_blank" rel="noopener">这是一篇写的很好的Python正则表达式的文章</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2017/wordpress-code-highlight-using-crayon/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/wordpress-code-highlight-using-crayon/" itemprop="url">WordPress中inline和code block代码高亮插件使用备忘</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-20T20:54:48+08:00">
                2017-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/网站相关/" itemprop="url" rel="index">
                    <span itemprop="name">网站相关</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近因为博文中需要使用大量代码，而视同普通文字的代码排版着实让人头痛，所以一直物色着一个代码高亮插件。 但是我又一直懒得折腾，趁闲暇之余试过几个WordPress的代码高亮插件，却大多功能太过简单，根本不能符合要求；或者是与我的博客主题略有冲突，造成无法使用，甚至对以往的博文造成影响。还好，最终发现了一款不错的插件，一番折腾之后，终于可以正常使用了，所以记录一下，以备以后遗忘之时查询。 这款插件的名字是Crayon Syntax Highlighter。 我所需要的代码高亮功能无非两种，一种是原地高亮，如：<code>sudo apt-get update</code>；另一种是代码块高亮，如下所示：</p>
<p>with tf.Session() as sess:<br>  sess.run(tf.local_variables_initializer())<br>  sess.run(tf.global_variables_initializer())<br>  print(sess.run(result, feed_dict={a: 2, b: 3}))</p>
<p>但是很遗憾，大多数代码高亮插件都需要使用博客主题的&lt; pre &gt;，而我的博客主题中却把&lt; pre &gt;进行了重定义，故而不能使用。 不过经过我的配置，Crayon Syntax Highlighter终于满足了我的要求。具体设置如下：</p>
<h1 id="1-lt-pre-gt"><a href="#1-lt-pre-gt" class="headerlink" title="1.&lt; pre &gt;"></a>1.&lt; pre &gt;</h1><blockquote>
<p>因为我的主题中&lt; pre &gt;已有所用，故需要将插件设置中的“捕获 &lt; pre &gt; 标签为插件所用”取消选中。</p>
</blockquote>
<h1 id="2-代码块高亮"><a href="#2-代码块高亮" class="headerlink" title="2.代码块高亮"></a>2.代码块高亮</h1><blockquote>
<p>使用&lt; code lang=””&gt;来定义代码块高亮，比如上面的Python程序即使用了&lt; code lang=”python”&gt;。 这一项，需要在插件设置中作相应设置：选中“捕获 &lt; code&gt; 标签为插件所用”，并将其设置为“块标签”。</p>
</blockquote>
<h1 id="3-原地高亮"><a href="#3-原地高亮" class="headerlink" title="3.原地高亮"></a>3.原地高亮</h1><blockquote>
<p>使用{language}来定义原地高亮，比如上面的原地高亮使用了{language}…{/language}，其中language指定语言类型。 这一项，需要在插件设置中，选中“捕获如{p-h-p}{/p-h-p}形式的行内标签”（注意php没有短划线，此处加上防止生效）。</p>
</blockquote>
<p>不过比较遗憾的是，我的设置完成之后，如切换行号是否显示、代码自动换行等仍然不能正常使用，而且，其中“允许代码复制/粘贴”需要取消选中才能允许，也有点奇怪。不过目前的功能还是已经基本上够我使用了。</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>昨天写完这篇文章后，WP提示升级，以及之前碰到了诸多问题，所以就点了升级，结果升级完成后，其他插件正常使用，而插件Crayon Syntax Highlighter则不能启用。无奈之下，继续寻找，找到了另一款插件——Enlighter。 该插件虽然效果不如Crayon惊艳，但也可以不使用&lt; pre &gt;来实现inline和code block两种代码高亮方式。两种高亮方式均使用同一种形式，即将需要高亮的代码包围在[ python]和[/ python]之间即可。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2017/memo-pickle-python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/memo-pickle-python/" itemprop="url">Python之pickle应用简记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-20T16:05:50+08:00">
                2017-04-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在Python程序中，有时候会需要对一些数据进行保存，而Python的pickle模块就是专门用来对数据进行序列化的。需要说明的是Python还有一个cPickle模块，其与pickle具有相同的功能，但因为其是C语言进行实现的，效率上相比pickle要好很多，所以可以使用cPickle完全替代pickle。 下面简单记录几个例子，以便备忘，可以在用到时直接查询、模仿使用。</p>
<h1 id="1-使用cPickle替代pickle"><a href="#1-使用cPickle替代pickle" class="headerlink" title="1.使用cPickle替代pickle"></a>1.使用cPickle替代pickle</h1><p>[python]import cPickle as pickle import random[/python] 使用如上的import即可将cPickle替换为pickle。</p>
<h1 id="2-保存一个数据"><a href="#2-保存一个数据" class="headerlink" title="2.保存一个数据"></a>2.保存一个数据</h1><p>[python]seed_num = 2000 shuffle_seed = random.sample(range(seed_num), seed_num) with open(‘shuffle_seed.pkl’, ‘wb’) as fss: pickle.dump(shuffle_seed, fss, protocol=pickle.HIGHEST_PROTOCOL)[/python] 如上程序片段，将一个列表shuffle_seed进行保存。而dump的参数中，[python]protocol=pickle.HIGHEST_PROTOCOL[/python]可以始终使用，因为这个参数可以将压缩比提高到最大，而且我测试，保存速度也是最快的。</p>
<h1 id="3-保存多个数据"><a href="#3-保存多个数据" class="headerlink" title="3.保存多个数据"></a>3.保存多个数据</h1><p>保存多个数据时，可以将多个数据构造成字典，然后保存该字典，如下： [python]seed_num = 2000 seed_num_sample = 10 shuffle_seed = random.sample(range(seed_num), seed_num) shuffle_seed_sample = random.sample(range(seed_num_sample), seed_num_sample) sss_dict = {‘shuffle_seed’: shuffle_seed, ‘shuffle_seed_sample’: shuffle_seed_sample} with open(‘shuffle_seed.pkl’, ‘wb’) as fss: pickle.dump(sss_dict, fss, protocol=pickle.HIGHEST_PROTOCOL)[/python]</p>
<h1 id="4-载入一个数据"><a href="#4-载入一个数据" class="headerlink" title="4.载入一个数据"></a>4.载入一个数据</h1><p>直接使用如下程序： [python]with open(‘shuffle_seed.pkl’, ‘rb’) as f: ss = pickle.load(f)[/python]</p>
<h1 id="5-载入多个数据"><a href="#5-载入多个数据" class="headerlink" title="5.载入多个数据"></a>5.载入多个数据</h1><p>将载入的数据作为字典进行处理，即可得到各个数据： [python]with open(‘shuffle_seed.pkl’, ‘rb’) as f: ss = pickle.load(f) shuffle_seed = ss[‘shuffle_seed’] shuffle_seed_sample = ss[‘shuffle_seed_sample’][/python]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2017/cross-with-ubuntu-terminal-using-shadowsocks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/cross-with-ubuntu-terminal-using-shadowsocks/" itemprop="url">让Ubuntu系统的Terminal通过Shadowsocks科学上网</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-14T11:55:24+08:00">
                2017-03-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/人工智能/" itemprop="url" rel="index">
                    <span itemprop="name">人工智能</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Ubuntu上使用Shadowsocks访问被屏蔽的网站已经十分方便了，但是有时候在Terminal上执行命令访问某些被屏蔽的网址时，比如googleapi.com，或者某些即使没有屏蔽但速度很慢的网站时，还是需要在Terminal上科学上网的。 可我试图用很多人推荐的安装polipo的方式去弄，安装配置都完全按照推荐的方式去做，却始终没有成功。所幸，今天同事找了另一种方法，安装Proxychains，最终成功了，故记录一下，以防忘记。</p>
<h1 id="1-安装Proxychains"><a href="#1-安装Proxychains" class="headerlink" title="1.安装Proxychains"></a>1.安装Proxychains</h1><p>[shell]sudo apt-get install proxychains[/shell]</p>
<h1 id="2-配置Proxychains"><a href="#2-配置Proxychains" class="headerlink" title="2.配置Proxychains"></a>2.配置Proxychains</h1><p>新建配置文件：</p>
<p>[shell]sudo touch ~/.proxychains/proxychains.conf[/shell]</p>
<p>编辑配置文件：</p>
<p>[shell]sudo gedit ~/.proxychains/proxychains.conf[/shell]</p>
<p>为： [shell]strict_chain proxy_dns remote_dns_subnet 224 tcp_read_time_out 15000 tcp_connect_time_out 8000 localnet 127.0.0.0/255.0.0.0 quiet_mode [ProxyList] socks5 127.0.0.1 1080[/shell] 当然，如果你的Shadowsocks配置有所不同，则需要做一下修改。</p>
<h1 id="3-其他配置"><a href="#3-其他配置" class="headerlink" title="3.其他配置"></a>3.其他配置</h1><p>配置好以后，就可以在需要科学上网的命令前加上proxychains即可，比如：</p>
<p>[shell]proxychains curl ip.gs[/shell]</p>
<p>则显示的IP就是翻过去的IP。 如果嫌proxychains太长，不好输入，还可以设置一个别名。 使用[shell]sudo gedit ~/.bashrc[/shell]在打开的文件中添加：</p>
<p>[shell]alias pc=’proxychains’[/shell]</p>
<p>然后source一下，就可以在以后写命令的时候，直接在命令前加pc即可：</p>
<p>[shell]pc curl ip.gs[/shell]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2017/memo-my-daughter-name/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/memo-my-daughter-name/" itemprop="url">小女取名记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-07T14:26:57+08:00">
                2017-01-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/经验知识/" itemprop="url" rel="index">
                    <span itemprop="name">经验知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>其实从年初老婆怀孕，我们就开始酝酿孩子的名字了。不过因为提前并不知道是个女孩儿还是男孩儿，而且也并不能提前预知孩子的五行八字，所以对名字的思考仅只限于思考而已。作为与老婆的闲聊之资，我们也偶尔会对未来畅想，宝宝叫什么好呢？ 最初因为我们有一个自古排过来的辈分，到孩子这儿，辈分是“德”，而我和老婆恰恰对这个字都比较喜欢，所以取名就变成了选字。而当然，这任务就跑到了我的头上。当时为了让老婆开心，我也煞费苦心凭空选择了许多。最后，经老婆拍板，选择了“xian”字；这样，如是女孩儿，可以叫娴；若是男孩儿，可以取贤。两个字都还算可以，不算太俗，也不生疏，而且直接称呼小xian为小名，似乎也算不错。我们就这样初步确定了名字。 念叨着宝宝的名字，时间来到了11月，经老婆孕期的坚持锻炼，身体状况保持到一种超乎寻常的状态，她硬是以30多岁的高龄将宝宝顺产带到了这个世上。是我最渴望的女儿，但开心激动之余，又要面对名字这个被老婆寄予厚望的问题。可很遗憾，女儿的生辰八字与五行属火的德字不搭，德娴自是叫不了了。 那好吧，我就以自己仅有的能力和水平尝试着为女儿取个名字吧。</p>
<h1 id="1-分析八字五行"><a href="#1-分析八字五行" class="headerlink" title="1.分析八字五行"></a>1.分析八字五行</h1><blockquote>
<p>既要取名，那就按照传统，首先分析一下女儿的八字五行吧。根据八字进行分析，我是在这个页面上进行的：<a href="http://xingming.fututa.com/zxwx/" target="_blank" rel="noopener">http://xingming.fututa.com/zxwx/</a> 女儿的分析结果是这样的：</p>
<p><img src="https://img.yueye.org/2017/01/07/01.jpg" alt="" title="五行八字"></p>
<p>五行分布很不均匀，完全没有木；但是她的喜用神是金，次喜水，也喜木。所以必须要有一个五行属金的字；而我们的姓氏五行恰好属木，故已经确定了两个字。至于第三个字，那只能综合五行和三才进行选择了。</p>
</blockquote>
<h1 id="2-选定三才"><a href="#2-选定三才" class="headerlink" title="2.选定三才"></a>2.选定三才</h1><blockquote>
<p>这里有一个完整的姓名三才配置吉凶表：<a href="http://wenku.baidu.com/view/0ae3ae3231126edb6f1a10ee.html" target="_blank" rel="noopener">http://wenku.baidu.com/view/0ae3ae3231126edb6f1a10ee.html</a> 因为我们的姓氏五行属木，所以只能在表格中查找木开头，且含有金和水的配置。查询发现三才配置木水金的效果最佳，因此，最终选定姓名的三才配置为木水金。即姓名的第二字和第三字分别取五行属水和五行属金的汉字。 当然，选定三才的过程中，也有一些网站可以辅助，比如在<a href="http://xingming.fututa.com/baziqiming/这个页面中，输入姓氏，选定性别和出生时间，即有推荐的八字用神组合，据此可以选定姓名三才。" target="_blank" rel="noopener">http://xingming.fututa.com/baziqiming/这个页面中，输入姓氏，选定性别和出生时间，即有推荐的八字用神组合，据此可以选定姓名三才。</a></p>
</blockquote>
<h1 id="3-选择汉字"><a href="#3-选择汉字" class="headerlink" title="3.选择汉字"></a>3.选择汉字</h1><blockquote>
<p>确定了汉字的五行之后，即可选择相应的汉字了，比如这里是五行属金的500个精选汉字：<a href="http://wenku.baidu.com/view/d075f64cc850ad02de8041de.html" target="_blank" rel="noopener">http://wenku.baidu.com/view/d075f64cc850ad02de8041de.html</a> 我们可以从中选择自己喜欢的一些记录下来。</p>
<p><img src="https://img.yueye.org/2017/01/07/02.jpg" alt="" title="五行属水和五行属金的精选汉字"></p>
<p>图中是我选择的五行属水和五行属金的汉字。 需要特别说明的是，有些汉字在作为名字最终敲定时，还需要进行仔细研究其五行，不要偏听偏信某一个网站的分类方法。比如图中五行属水的汉字中，“诗”字我最开始特别中意，但到最后仔细搜查了才发现，更多研究者将其作为五行属金的汉字；图中五行属金的汉字中，更多研究者却将“元”字作为五行属火的汉字；诸如此类。</p>
</blockquote>
<h1 id="4-敲定笔画"><a href="#4-敲定笔画" class="headerlink" title="4.敲定笔画"></a>4.敲定笔画</h1><blockquote>
<p>选定了三才，确定了名字中汉字的五行后，下一步就是敲定笔画。而确定笔画，就需要考虑名字的五格了，即天、地、人、外、总五格，其中最重要的是人、地、总三格，而天格由姓氏确定，我们无能为力，影响也小。 这里有一个完整的三才五格算法表：<a href="http://wenku.baidu.com/view/75a968aed1f34693daef3e4e.html" target="_blank" rel="noopener">http://wenku.baidu.com/view/75a968aed1f34693daef3e4e.html</a> 综合五格进行选择，根据姓氏的笔画，再从表格中选择意义为吉的数字，灵活组合，即可选出比较恰当的姓名笔画数。 需要特别说明的是，在考虑五格时，汉字的笔画更普遍的是以康熙字典中该汉字的笔画数来进行确定，而且还有一些其他的特殊情况，在最终选定汉字时，还需进行考虑。</p>
</blockquote>
<h1 id="5-其他参考"><a href="#5-其他参考" class="headerlink" title="5.其他参考"></a>5.其他参考</h1><blockquote>
<p>最后敲定好名字后，可以在诸如<a href="http://www.fututa.com/ceming这样的网页上对姓名进行一下分析测试。" target="_blank" rel="noopener">http://www.fututa.com/ceming这样的网页上对姓名进行一下分析测试。</a> 也需要对汉字的五行和笔画进行一个详细的调研，以确保没有错误发生。</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2016/transform-voxel-coordinate-to-world-coordinate-of-dicom-files/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/transform-voxel-coordinate-to-world-coordinate-of-dicom-files/" itemprop="url">Transform voxel coordinates to world coordinates of DICOM files</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-24T14:13:17+08:00">
                2016-12-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>import numpy as np<br>import SimpleITK as sitk<br>import csv<br>import os<br>import linecache<br>import inspect</p>
<p>seriesuid_label = ‘seriesuid’<br>coordX_label = ‘coordX’<br>coordY_label = ‘coordY’<br>coordZ_label = ‘coordZ’<br>CADProbability_label = ‘probability’<br>SpacingDict = {}</p>
<p>import fnmatch</p>
<p>def getDicomDir(dir, uid, resultList, dataFormat=’mhd’):<br>  for root, dirnames, filenames in os.walk(dir):<br>    if len(filenames) != 0:<br>      for filename in fnmatch.filter(filenames, ‘*.’ + dataFormat):<br>        if dataFormat.lower() == ‘mhd’:<br>          if (filename == uid + ‘.mhd’):<br>            resultList.append(os.path.join(dir, filename))<br>            break<br>        elif dataFormat.lower() == ‘dcm’:<br>          if (os.path.basename(dir) == uid):<br>            resultList.append(dir)<br>            break<br>    for dirname in dirnames:<br>      getDicomDir(os.path.join(dir, dirname), uid, resultList, dataFormat)</p>
<p>def readCSV(filename):<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def getSpacingInfo(filepath, dataFormat=’mhd’):<br>  if dataFormat.lower() == ‘mhd’:<br>    inputimage = sitk.ReadImage(filepath)<br>  elif dataFormat.lower() == ‘dcm’:<br>    reader = sitk.ImageSeriesReader()<br>    filenames = reader.GetGDCMSeriesFileNames(filepath)<br>    reader.SetFileNames(filenames)<br>    inputimage = reader.Execute()<br>  else:<br>    print “Unsupport file type: %s. Code line %d in function getSpacingInfo().” % (dataFormat, inspect.stack()[0][2])<br>    exit()<br>  spacing = inputimage.GetSpacing()<br>  origin = inputimage.GetOrigin()<br>  direction = inputimage.GetDirection()<br>  return spacing + origin + direction</p>
<p>def mhdReader(inputpath):<br>  dicomPath = ‘/home/kong/4T/LIDC-IDRI/LIDC-IDRI-0038/1.3.6.1.4.1.14519.5.2.1.6279.6001.127335250316932247803669656678/1.3.6.1.4.1.14519.5.2.1.6279.6001.117383608379722740629083782428’<br>  reader = sitk.ImageSeriesReader()<br>  filenames = reader.GetGDCMSeriesFileNames(dicomPath)<br>  reader.SetFileNames(filenames)<br>  inputimage = reader.Execute()<br>  spacing = inputimage.GetSpacing()<br>  origin = inputimage.GetOrigin()<br>  direction = inputimage.GetDirection()<br>  voxelCoord = [1, 1, 1]<br>  result = voxelCoordToWorld(voxelCoord, spacing, origin, direction)<br>  return spacing, origin, direction</p>
<p>def voxelCoordToWorld(voxelCoord, outputSpacing, origin, direction):<br>  direcArray = np.array(direction).reshape((3, 3))<br>  spacingArray = np.diag(outputSpacing)<br>  voxelArray = np.array(voxelCoord).reshape((3, 1))<br>  orginArray = np.array(origin).reshape((3, 1))<br>  result = np.matmul(np.matmul(direcArray, spacingArray), voxelArray) + orginArray<br>  return result.reshape(3)</p>
<p>def worldToVoxelCoord(worldCoord, origin, outputSpacing):<br>  stretchedVoxelCoord = np.absolute(worldCoord - origin)<br>  voxelCoord = stretchedVoxelCoord / outputSpacing<br>  return voxelCoord</p>
<p>def initialSpacingDict(spacing_filename):<br>  spacingLines = readCSV(spacing_filename)[1:]<br>  for spacingLine in spacingLines:<br>    SpacingDict[spacingLine[0]] = np.array(spacingLine[1:], dtype=’float’)</p>
<p>def transformFile_PixelToWorld(csvfile, ImgDir, spacing_filename, outfile, dataFormat=’mhd’):<br>  initialSpacingDict(spacing_filename)<br>  results = readCSV(csvfile)<br>  header = results[0]<br>  i = 1<br>  with open(outfile, “wb”) as f:<br>    csvwriter = csv.writer(f, delimiter=’,’)<br>    csvwriter.writerow(header)<br>    for result in results[1:]:<br>      nodule_seriesuid = result[header.index(seriesuid_label)]<br>      if i % 10 == 0:<br>        print “progress: %d/%d” % (i, len(results) - 1)<br>      i += 1<br>      if not SpacingDict.has_key(nodule_seriesuid):<br>        resultList = []<br>        getDicomDir(ImgDir, nodule_seriesuid, resultList, dataFormat=dataFormat)<br>        if (len(resultList) &gt; 1):<br>          print “more than one dicom folds was found. “ \<br>                “The first one will be used. “ \<br>                “All the found folds are showed as follows:”<br>          print resultList<br>        if (len(resultList) == 0):<br>          print ‘No dicom file of case %s is found’ % nodule_seriesuid<br>          print ‘This line will be ignored. Line data: ‘ + str(result)<br>          continue<br>        resultList = resultList[0]<br>        SpacingDict[nodule_seriesuid] = getSpacingInfo(resultList, dataFormat)</p>
<pre><code>  # SpacingDict\[nodule_seriesuid\] = \[spacing,origin,direction\]
coordX = float(result\[header.index(coordX_label)\])
coordY = float(result\[header.index(coordY_label)\])
coordZ = float(result\[header.index(coordZ_label)\])
worldCoord = voxelCoordToWorld(\[coordX, coordY, coordZ\],  SpacingDict\[nodule_seriesuid\]\[
                               0:3\], SpacingDict\[nodule\_seriesuid\]\[3:6\],  SpacingDict\[nodule\_seriesuid\]\[6:\])
csvwriter.writerow(\[nodule_seriesuid, str(worldCoord\[0\]), str(
    worldCoord\[1\]), str(worldCoord\[2\]), result\[header.index(CADProbability_label)\]\])
</code></pre><p>def startTransform():<br>  csvfile = ‘/home/kong/4T/evaluationScript/results_own.csv’<br>  dicomDir = ‘/home/kong/4T/LIDC-IDRI’<br>  outfile = ‘/home/kong/4T/evaluationScript/results_own_world.csv’<br>  spacing_filename = ‘/home/kong/4T/evaluationScript/annotations/spacing.csv’<br>  transformFile_PixelToWorld(csvfile, dicomDir, spacing_filename, outfile, ‘mhd’)</p>
<p>if __name__ == ‘__main__‘:<br>  startTransform()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2016/test-the-models-trained-using-3d-cnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/test-the-models-trained-using-3d-cnn/" itemprop="url">Test the models trained using 3D CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-24T14:11:20+08:00">
                2016-12-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’This function calculates if the axis is a nodule using 3D model.<br>   the output is the posibility of an axis whether it is a nodule.</p>
<p>   Author: Kong Haiyang<br>‘’’<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import SimpleITK as sitk<br>import os<br>import sys<br>from os import walk<br>import numpy as np<br>import csv<br>import time<br>import cv2<br>from scipy.ndimage.interpolation import zoom</p>
<p>from six.moves import urllib<br>from six.moves import xrange<br>import tensorflow as tf</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Channels of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 4, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 128, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 1, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 12,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_integer(‘NUM_LABEL’, 1, “How many Label bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(<br>    ‘NUM_IMAGE’, 40 ** 3, “How many Image bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_LENGTH’, 4, “Length of label or image pixel.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_bool(‘SAVE_MODEL’, True, ‘Save model or not.’)<br>tf.app.flags.DEFINE_bool(‘USE_OFFICIAL’, True, ‘Use official csv or not.’)<br>tf.app.flags.DEFINE_integer(‘CUT_SIZE’, 64, ‘Size of block cutting out.’)<br>tf.app.flags.DEFINE_integer(‘SAVE_SIZE’, 40, ‘Size of block saved.’)</p>
<p>XAVIER_INIT = tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)</p>
<p>def normalizePlanes(npzarray):<br>  maxHU = 400.<br>  minHU = -1000.<br>  npzarray = (npzarray - minHU) / (maxHU - minHU)<br>  npzarray[npzarray &gt; 1] = 1.<br>  npzarray[npzarray &lt; 0] = 0.<br>  return npzarray</p>
<p>def saveImageSlice(image, cc, path):<br>  if not os.path.exists(path):<br>    os.makedirs(path)<br>  imageTemp = image[cc[0] - 32:cc[0] + 32, …]<br>  for index in np.arange(imageTemp.shape[0]):<br>    sliceTemp = imageTemp[index, :, :].copy()<br>    cv2.rectangle(sliceTemp, (cc[2] - 32, cc[1] - 32),<br>                  (cc[2] + 32, cc[1] + 32), (255, 255, 255))<br>    cv2.imwrite(path + str(index) + ‘.png’, sliceTemp * 255)</p>
<p>def worldToVoxelCoord(worldCoord, origin, outputSpacing):<br>  stretchedVoxelCoord = np.absolute(worldCoord - origin)<br>  voxelCoord = stretchedVoxelCoord / outputSpacing<br>  return voxelCoord</p>
<p>def interpolatefilter(inputpath):<br>  inputimage = sitk.ReadImage(inputpath)<br>  origin = inputimage.GetOrigin()<br>  spacing = inputimage.GetSpacing()<br>  direction = inputimage.GetDirection()<br>  outputspacing = (spacing[0], spacing[0], spacing[0])<br>  size = inputimage.GetSize()<br>  tmp = int(spacing[2] * size[2] / spacing[0])<br>  if tmp % 2 != 0:<br>    tmp = tmp - 1</p>
<p>  outputsize = (size[0], size[1], tmp)<br>  resamplefilter = sitk.ResampleImageFilter()<br>  resamplefilter.SetOutputDirection(direction)<br>  resamplefilter.SetSize(outputsize)<br>  resamplefilter.SetOutputOrigin(origin)<br>  resamplefilter.SetOutputSpacing(outputspacing)<br>  outputimage = resamplefilter.Execute(inputimage)<br>  numpyImage = sitk.GetArrayFromImage(outputimage)<br>  numpyImage = normalizePlanes(numpyImage)<br>  return numpyImage, list(outputsize), spacing, outputspacing, origin</p>
<p>def createImageBorder(numpyImage, outputsize):<br>  BackImage = np.zeros(((800, 800, 800)))<br>  BackImage[400 - int(outputsize[2] / 2):400 + int(outputsize[2] / 2),<br>            400 - int(outputsize[1] / 2):400 + int(outputsize[1] / 2),<br>            400 - int(outputsize[0] / 2):400 + int(outputsize[0] / 2)] = numpyImage<br>  return BackImage</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def readSpecialLine(csvLines, uid):<br>  coor = []<br>  oriAxis = []<br>  label = []<br>  for line in csvLines:<br>    if line[0] == uid:<br>      coor.append(np.array(line[-2:0:-1], np.float))<br>      oriAxis.append(line[1:-1])<br>      label.append(int(line[-1]))<br>  return coor, label, oriAxis</p>
<p>Wb = {<br>    ‘W11’: tf.get_variable(‘W11’, [3, 3, 3, FLAGS.CHANNEL_NUMBER, 16], tf.float32, XAVIER_INIT),<br>    ‘b11’: tf.Variable(tf.zeros([16])),<br>    ‘W12’: tf.get_variable(‘W12’, [3, 3, 3, 16, 24], tf.float32, XAVIER_INIT),<br>    ‘b12’: tf.Variable(tf.zeros([24])),<br>    ‘W2’: tf.get_variable(‘W2’, [3, 3, 3, 24, 32], tf.float32, XAVIER_INIT),<br>    ‘b2’: tf.Variable(tf.zeros([32])),<br>    ‘W3’: tf.get_variable(‘W3’, [3, 3, 3, 32, 48], tf.float32, XAVIER_INIT),<br>    ‘b3’: tf.Variable(tf.zeros([48])),<br>    ‘W4’: tf.get_variable(‘W4’, [3, 3, 3, 48, 64], tf.float32, XAVIER_INIT),<br>    ‘b4’: tf.Variable(tf.zeros([64])),<br>    ‘fcw1’: tf.get_variable(‘fcw1’, [2**3 * 64, 32], tf.float32, XAVIER_INIT),<br>    ‘fcb1’: tf.Variable(tf.zeros([32])),<br>    ‘fcw2’: tf.get_variable(‘fcw2’, [32, FLAGS.LABEL_NUMBER], tf.float32, XAVIER_INIT),<br>    ‘fcb2’: tf.Variable(tf.zeros([FLAGS.LABEL_NUMBER]))<br>}</p>
<p>def model(data):<br>  with tf.variable_scope(‘conv1’):<br>    conv = tf.nn.conv3d(data, Wb[‘W11’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b11’]))<br>    conv = tf.nn.conv3d(relu, Wb[‘W12’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b12’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv2’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W2’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b2’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W3’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b3’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W4’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b4’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’):<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] * ps[4]])<br>  with tf.variable_scope(‘fc1’):<br>    hidden = tf.nn.relu(tf.matmul(reshape, Wb[‘fcw1’]) + Wb[‘fcb1’])<br>  with tf.variable_scope(‘fc2’):<br>    out = tf.matmul(hidden, Wb[‘fcw2’]) + Wb[‘fcb2’]<br>  return out</p>
<p>def LUNAtest(ssNo, image):<br>  modelPath = ‘/home/kong/4T/official3D_110W/Cross{}’.format(ssNo)<br>  test_data_node = tf.placeholder(<br>      tf.float32, (None, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, FLAGS.CHANNEL_NUMBER))<br>  test_prediction = tf.nn.softmax(model(test_data_node))</p>
<p>  def test_in_batches(data, sess):<br>    size = data.shape[0]<br>    predictions = np.ndarray(shape=(size, FLAGS.LABEL_NUMBER), dtype=np.float32)<br>    for begin in xrange(0, size, FLAGS.EVAL_BATCH_SIZE):<br>      end = begin + FLAGS.EVAL_BATCH_SIZE<br>      if end &lt;= size:<br>        predictions[begin:end, :] = sess.run(<br>            test_prediction,<br>            feed_dict={test_data_node: data[begin:end, …]})<br>      else:<br>        batch_predictions = sess.run(<br>            test_prediction,<br>            feed_dict={test_data_node: data[-FLAGS.EVAL_BATCH_SIZE:, …]})<br>        predictions[begin:, :] = batch_predictions[begin - size:, :]<br>    return predictions</p>
<p>  saver = tf.train.Saver()<br>  with tf.Session() as sess:<br>    ckpt = tf.train.get_checkpoint_state(modelPath)<br>    ckpt.model_checkpoint_path = os.path.join(modelPath, ckpt.model_checkpoint_path)<br>    if ckpt and ckpt.model_checkpoint_path:<br>      saver.restore(sess, ckpt.model_checkpoint_path)<br>    predictions = test_in_batches(image, sess)<br>  return predictions</p>
<p>def test_official(mhdOriginalPath, uid, ssNo, csvLines, count):<br>  print(‘Processing No. {}…’.format(count))<br>  axis, label, oriAxis = readSpecialLine(csvLines, uid)<br>  interpolatedImage, outputsize, _, outputspacing, origin = interpolatefilter(<br>      mhdOriginalPath)<br>  BackImage = createImageBorder(interpolatedImage, outputsize)<br>  ccList = []<br>  for a in axis:<br>    cutCenter = worldToVoxelCoord(a, origin[::-1], outputspacing)<br>    cutCenter += (400 - np.array(outputsize[::-1]) / 2)<br>    ccList.append(cutCenter)<br>  ccList = np.round(ccList).astype(np.int)<br>  image = np.empty([len(ccList), FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, 1])<br>  for index, cc in enumerate(ccList):<br>    cutTemp = BackImage[cc[0] - 32:cc[0] + 32,<br>                        cc[1] - 32:cc[1] + 32,<br>                        cc[2] - 32:cc[2] + 32]<br>    cutTemp = zoom(cutTemp, float(FLAGS.SAVE_SIZE) / FLAGS.CUT_SIZE)<br>    image[index, :, :, :, 0] = cutTemp<br>  results = LUNAtest(ssNo, image)<br>  return results, oriAxis, label</p>
<p>def genPath(originalPath):<br>  ‘’’generate a dict with the uid as keys<br>     and the subset number as values.<br>  ‘’’<br>  pathDict = {}<br>  for (dirpath, dirnames, filenames) in walk(originalPath):<br>    dirnames.sort()<br>    filenames.sort()<br>    if(len(filenames) &lt; 20):<br>      continue<br>    else:<br>      for filename in filenames:<br>        if filename.endswith(‘.mhd’):<br>          pathDict.setdefault(filename[:-4], dirpath[-1])<br>  return pathDict</p>
<p>def main(_):<br>  filePath = ‘/home/kong/4T/nodule_project’<br>  pathDict = genPath(filePath)<br>  csvHeader = [‘seriesuid’, ‘coordX’, ‘coordY’, ‘coordZ’, ‘probability’]<br>  if FLAGS.USE_OFFICIAL:<br>    csvName = ‘/home/kong/4T/evaluationScript/candidates_V2.csv’<br>    csvLines = readCSV(csvName)[1:]<br>    count = 0<br>    with open(‘results_official_v2.csv’, ‘wb’) as f:<br>      csvwriter = csv.writer(f)<br>      csvwriter.writerow(csvHeader)<br>      for uid in pathDict:<br>        ssNo = pathDict[uid]<br>        mhdFileName = (filePath + ‘/subset{}/‘ + ‘{}.mhd’).format(ssNo, uid)<br>        result, axis, label = test_official(mhdFileName, uid, ssNo, csvLines, count)<br>        for i in range(len(axis)):<br>          writeContent = [uid]<br>          writeContent.extend(axis[i])<br>          writeContent.append(result)<br>          csvwriter.writerow(writeContent)<br>        count += 1<br>  else:<br>    pass</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2016/test-3d-models-using-official-candidates-or-candidates-detected-ourselves/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/test-3d-models-using-official-candidates-or-candidates-detected-ourselves/" itemprop="url">Test 3D models using official candidates or candidates detected ourselves</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-20T21:02:13+08:00">
                2016-12-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’This function calculates if the axis is a nodule using 3D model.<br>   the output is the posibility of an axis whether it is a nodule.</p>
<p>   Author: Kong Haiyang<br>‘’’<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function<br>import SimpleITK as sitk</p>
<p>import os<br>import sys<br>from os import walk<br>import numpy as np<br>import csv<br>import time<br>import cv2<br>from scipy.ndimage.interpolation import zoom</p>
<p>from six.moves import urllib<br>from six.moves import xrange<br>import tensorflow as tf</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Channels of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 4, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 128, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 1, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 12,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_integer(‘NUM_LABEL’, 1, “How many Label bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(<br>    ‘NUM_IMAGE’, 40 ** 3, “How many Image bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_LENGTH’, 4, “Length of label or image pixel.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_bool(‘SAVE_MODEL’, True, ‘Save model or not.’)<br>tf.app.flags.DEFINE_bool(‘USE_OFFICIAL’, True, ‘Use official csv or not.’)<br>tf.app.flags.DEFINE_integer(‘CUT_SIZE’, 64, ‘Size of block cutting out.’)<br>tf.app.flags.DEFINE_integer(‘SAVE_SIZE’, 40, ‘Size of block saved.’)</p>
<p>XAVIER_INIT = tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)</p>
<p>def normalizePlanes(npzarray):<br>  maxHU = 400.<br>  minHU = -1000.<br>  npzarray = (npzarray - minHU) / (maxHU - minHU)<br>  npzarray[npzarray &gt; 1] = 1.<br>  npzarray[npzarray &lt; 0] = 0.<br>  return npzarray</p>
<p>def saveImageSlice(image, cc, path):<br>  if not os.path.exists(path):<br>    os.makedirs(path)<br>  imageTemp = image[cc[0] - 32:cc[0] + 32, …]<br>  for index in np.arange(imageTemp.shape[0]):<br>    sliceTemp = imageTemp[index, :, :].copy()<br>    cv2.rectangle(sliceTemp, (cc[2] - 32, cc[1] - 32),<br>                  (cc[2] + 32, cc[1] + 32), (255, 255, 255))<br>    cv2.imwrite(path + str(index) + ‘.png’, sliceTemp * 255)</p>
<p>def worldToVoxelCoord(worldCoord, origin, outputSpacing):<br>  stretchedVoxelCoord = np.absolute(worldCoord - origin)<br>  voxelCoord = stretchedVoxelCoord / outputSpacing<br>  return voxelCoord</p>
<p>def interpolatefilter(inputpath):<br>  inputimage = sitk.ReadImage(inputpath)<br>  origin = inputimage.GetOrigin()<br>  spacing = inputimage.GetSpacing()<br>  direction = inputimage.GetDirection()<br>  outputspacing = (spacing[0], spacing[0], spacing[0])<br>  size = inputimage.GetSize()<br>  tmp = int(spacing[2] * size[2] / spacing[0])<br>  if tmp % 2 != 0:<br>    tmp = tmp - 1</p>
<p>  outputsize = (size[0], size[1], tmp)<br>  resamplefilter = sitk.ResampleImageFilter()<br>  resamplefilter.SetOutputDirection(direction)<br>  resamplefilter.SetSize(outputsize)<br>  resamplefilter.SetOutputOrigin(origin)<br>  resamplefilter.SetOutputSpacing(outputspacing)<br>  outputimage = resamplefilter.Execute(inputimage)<br>  numpyImage = sitk.GetArrayFromImage(outputimage)<br>  numpyImage = normalizePlanes(numpyImage)<br>  return numpyImage, list(outputsize), spacing, outputspacing, origin</p>
<p>def createImageBorder(numpyImage, outputsize):<br>  BackImage = np.zeros(((800, 800, 800)))<br>  BackImage[400 - int(outputsize[2] / 2):400 + int(outputsize[2] / 2),<br>            400 - int(outputsize[1] / 2):400 + int(outputsize[1] / 2),<br>            400 - int(outputsize[0] / 2):400 + int(outputsize[0] / 2)] = numpyImage<br>  return BackImage</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def readSpecialLine(csvLines, uid):<br>  coor = []<br>  label = []<br>  for line in csvLines:<br>    if line[0] == uid:<br>      coor.append(np.array(line[-2:0:-1], np.float))<br>      label.append(int(line[-1]))<br>  return coor, label</p>
<p>def readSpecialLine_own(csvLines, uid):<br>  coor = []<br>  label = []<br>  for line in csvLines:<br>    if line[1] == uid and line[-1] == ‘0’:<br>      coor.append(np.array(line[5:2:-1], np.float))<br>      label.append(int(line[-2]))<br>  return coor, label</p>
<p>Wb = {<br>    ‘W11’: tf.get_variable(‘W11’, [3, 3, 3, FLAGS.CHANNEL_NUMBER, 16], tf.float32, XAVIER_INIT),<br>    ‘b11’: tf.Variable(tf.zeros([16])),<br>    ‘W12’: tf.get_variable(‘W12’, [3, 3, 3, 16, 24], tf.float32, XAVIER_INIT),<br>    ‘b12’: tf.Variable(tf.zeros([24])),<br>    ‘W2’: tf.get_variable(‘W2’, [3, 3, 3, 24, 32], tf.float32, XAVIER_INIT),<br>    ‘b2’: tf.Variable(tf.zeros([32])),<br>    ‘W3’: tf.get_variable(‘W3’, [3, 3, 3, 32, 48], tf.float32, XAVIER_INIT),<br>    ‘b3’: tf.Variable(tf.zeros([48])),<br>    ‘W4’: tf.get_variable(‘W4’, [3, 3, 3, 48, 64], tf.float32, XAVIER_INIT),<br>    ‘b4’: tf.Variable(tf.zeros([64])),<br>    ‘fcw1’: tf.get_variable(‘fcw1’, [2**3 * 64, 32], tf.float32, XAVIER_INIT),<br>    ‘fcb1’: tf.Variable(tf.zeros([32])),<br>    ‘fcw2’: tf.get_variable(‘fcw2’, [32, FLAGS.LABEL_NUMBER], tf.float32, XAVIER_INIT),<br>    ‘fcb2’: tf.Variable(tf.zeros([FLAGS.LABEL_NUMBER]))<br>}</p>
<p>def model(data):<br>  with tf.variable_scope(‘conv1’):<br>    conv = tf.nn.conv3d(data, Wb[‘W11’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b11’]))<br>    conv = tf.nn.conv3d(relu, Wb[‘W12’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b12’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv2’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W2’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b2’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W3’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b3’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W4’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b4’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’):<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] * ps[4]])<br>  with tf.variable_scope(‘fc1’):<br>    hidden = tf.nn.relu(tf.matmul(reshape, Wb[‘fcw1’]) + Wb[‘fcb1’])<br>  with tf.variable_scope(‘fc2’):<br>    out = tf.matmul(hidden, Wb[‘fcw2’]) + Wb[‘fcb2’]<br>  return out</p>
<p>def LUNAtest(ssNo, image):<br>  modelPath = ‘/home/kong/4T/official3D_110W/Cross{}’.format(ssNo)<br>  test_data_node = tf.placeholder(<br>      tf.float32, (None, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, FLAGS.CHANNEL_NUMBER))<br>  test_prediction = tf.nn.softmax(model(test_data_node))</p>
<p>  def test_in_batches(data, sess):<br>    size = data.shape[0]<br>    predictions = np.ndarray(shape=(size, FLAGS.LABEL_NUMBER), dtype=np.float32)<br>    for begin in xrange(0, size, FLAGS.EVAL_BATCH_SIZE):<br>      end = begin + FLAGS.EVAL_BATCH_SIZE<br>      if end &lt;= size:<br>        predictions[begin:end, :] = sess.run(<br>            test_prediction,<br>            feed_dict={test_data_node: data[begin:end, …]})<br>      else:<br>        batch_predictions = sess.run(<br>            test_prediction,<br>            feed_dict={test_data_node: data[-FLAGS.EVAL_BATCH_SIZE:, …]})<br>        predictions[begin:, :] = batch_predictions[begin - size:, :]<br>    return predictions</p>
<p>  saver = tf.train.Saver()<br>  with tf.Session() as sess:<br>    ckpt = tf.train.get_checkpoint_state(modelPath)<br>    ckpt.model_checkpoint_path = os.path.join(modelPath, ckpt.model_checkpoint_path)<br>    if ckpt and ckpt.model_checkpoint_path:<br>      saver.restore(sess, ckpt.model_checkpoint_path)<br>    predictions = test_in_batches(image, sess)<br>  return predictions</p>
<p>def error_rate(preds, labels):<br>  “””Calculate the error rate based on predictions and labels.”””<br>  return 100.0 - (100.0 * np.sum(np.argmax(preds, 1) == labels) / len(preds))</p>
<p>def test_official(mhdOriginalPath, uid, ssNo, csvLines, count):<br>  print(‘Processing No. {}…’.format(count))<br>  axis, label = readSpecialLine(csvLines, uid)<br>  interpolatedImage, outputsize, _, outputspacing, origin = interpolatefilter(<br>      mhdOriginalPath)<br>  BackImage = createImageBorder(interpolatedImage, outputsize)<br>  ccList = []<br>  for a in axis:<br>    cutCenter = worldToVoxelCoord(a, origin[::-1], outputspacing)<br>    cutCenter += (400 - np.array(outputsize[::-1]) / 2)<br>    ccList.append(cutCenter)<br>  ccList = np.round(ccList).astype(np.int)<br>  image = np.empty([len(ccList), FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, 1])<br>  for index, cc in enumerate(ccList):<br>    cutTemp = BackImage[cc[0] - 32:cc[0] + 32,<br>                        cc[1] - 32:cc[1] + 32,<br>                        cc[2] - 32:cc[2] + 32]</p>
<pre><code># saveImageSlice(BackImage, cc, &apos;test1/&apos;)
cutTemp = zoom(cutTemp, float(FLAGS.SAVE\_SIZE) / FLAGS.CUT\_SIZE)
image\[index, :, :, :, 0\] = cutTemp
</code></pre><p>  results = LUNAtest(ssNo, image)<br>  return results, np.array(axis), label</p>
<p>def test_own(mhdOriginalPath, uid, ssNo, csvLines, count):<br>  print(‘Processing No. {}…’.format(count))<br>  axis, label = readSpecialLine_own(csvLines, uid)<br>  interpolatedImage, outputsize, spacing, _, _ = interpolatefilter(mhdOriginalPath)<br>  BackImage = createImageBorder(interpolatedImage, outputsize)<br>  ccList = []<br>  for a in axis:<br>    cutCenter = np.array(a, np.float) * spacing[::-1] / spacing[0]<br>    cutCenter += (400 - np.array(outputsize[::-1]) / 2)<br>    ccList.append(cutCenter)<br>  ccList = np.round(ccList).astype(np.int)<br>  image = np.empty([len(ccList), FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, FLAGS.SAVE_SIZE, 1])<br>  for index, cc in enumerate(ccList):<br>    cutTemp = BackImage[cc[0] - 32:cc[0] + 32,<br>                        cc[1] - 32:cc[1] + 32,<br>                        cc[2] - 32:cc[2] + 32]</p>
<pre><code># saveImageSlice(BackImage, cc, &apos;test1/&apos;)
cutTemp = zoom(cutTemp, float(FLAGS.SAVE\_SIZE) / FLAGS.CUT\_SIZE)
image\[index, :, :, :, 0\] = cutTemp
</code></pre><p>  results = LUNAtest(ssNo, image)<br>  return results, np.array(axis), label</p>
<p>def genPath(originalPath):<br>  ‘’’generate a dict with the uid as keys<br>     and the subset number as values.<br>  ‘’’<br>  pathDict = {}<br>  for (dirpath, dirnames, filenames) in walk(originalPath):<br>    dirnames.sort()<br>    filenames.sort()<br>    if(len(filenames) &lt; 20):<br>      continue<br>    else:<br>      for filename in filenames:<br>        if filename.endswith(‘.mhd’):<br>          pathDict.setdefault(filename[:-4], dirpath[-1])<br>  return pathDict</p>
<p>def main(_):<br>  filePath = ‘/home/kong/4T/nodule_project’<br>  pathDict = genPath(filePath)<br>  if FLAGS.USE_OFFICIAL:<br>    csvName = ‘/home/kong/4T/nodule_project/CSVFILES/candidates.csv’<br>    csvLines = readCSV(csvName)[1:]<br>    count = 0<br>    with open(‘results_official.csv’, ‘wb’) as f:<br>      csvwriter = csv.writer(f)<br>      writeContent = [‘seriesuid’, ‘coordX’, ‘coordY’, ‘coordZ’, ‘probability’]<br>      csvwriter.writerow(writeContent)<br>      for uid in pathDict:<br>        ssNo = pathDict[uid]<br>        mhdFileName = (filePath + ‘/subset{}/‘ + ‘{}.mhd’).format(ssNo, uid)<br>        result, axis, label = test_official(mhdFileName, uid, ssNo, csvLines, count)<br>        for index in range(result.shape[0]):<br>          writeContent = [uid, axis[index, 2], axis[<br>              index, 1], axis[index, 0], result[index, 1]]<br>          csvwriter.writerow(writeContent)<br>        count += 1<br>  else:<br>    csvName = ‘/home/kong/4T/new_detect_first/LUNASTable.csv’<br>    csvLines = readCSV(csvName)[1:]<br>    with open(‘results_own.csv’, ‘wb’) as f:<br>      csvwriter = csv.writer(f)<br>      writeContent = [‘seriesuid’, ‘coordX’, ‘coordY’, ‘coordZ’, ‘probability’]<br>      csvwriter.writerow(writeContent)<br>      for uid in pathDict:<br>        ssNo = pathDict[uid]<br>        mhdFileName = (filePath + ‘/subset{}/‘ + ‘{}.mhd’).format(ssNo, uid)<br>        result, axis, label = test_own(mhdFileName, uid, ssNo, csvLines)<br>        for index in range(result.shape[0]):<br>          writeContent = [uid, axis[index, 2], axis[<br>              index, 1], axis[index, 0], result[index, 1]]<br>          csvwriter.writerow(writeContent)</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2016/a-tensorflow-example-to-read-data-using-queuerunner/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/a-tensorflow-example-to-read-data-using-queuerunner/" itemprop="url">a TensorFlow example to read data using QueueRunner</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-15T20:16:38+08:00">
                2016-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’3D convolutional neural network trained<br>   to reduce the False Positive Rate for the LUNA datasets.<br>   The LUNA datasets are organized in the CIFAR architecture.</p>
<p>   Author: Kong Haiyang<br>‘’’<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import os<br>import sys<br>import time<br>import math<br>import numpy as np<br>from six.moves import xrange<br>import tensorflow as tf<br>import csv</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 4, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 64, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 1, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 12,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_integer(‘NUM_LABEL’, 1, “How many Label bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(<br>    ‘NUM_IMAGE’, 40 ** 3, “How many Image bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_LENGTH’, 4, “Length of label or image pixel.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_string(‘XAVIER_INIT’,<br>                           ‘tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)’,<br>                           “Initialize with XAVIER_INIT.”)<br>tf.app.flags.DEFINE_bool(‘SAVE_MODEL’, True, ‘Save model or not.’)</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def get_noaug_first(no, count):<br>  lines = readCSV(FLAGS.CSV_FILE)[1:]<br>  data = np.empty([count, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE,<br>                   FLAGS.IMAGE_SIZE, 1], dtype=np.float32)<br>  i = count_ = 0<br>  length = (FLAGS.NUM_LABEL + FLAGS.NUM_IMAGE) <em> FLAGS.PIXEL_LENGTH<br>  with open(FLAGS.BIN_FILE, ‘rb’) as f:<br>    for line in lines:<br>      if line[1] == str(no) and line[-1] == ‘0’ and line[-2] == ‘1’:<br>        f.seek(i </em> length)<br>        buf = f.read(length)<br>        data[count_, …] = (np.frombuffer(buf[4:], dtype=np.float32)).reshape(<br>            FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, FLAGS.IMAGE_SIZE, 1)<br>        count_ += 1<br>      i += 1<br>  labels = np.ones(count, dtype=np.int64)<br>  return data, labels</p>
<p>def init_bin_file():<br>  bin_file_name = [FLAGS.BIN_FILE]<br>  for f in bin_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqb = tf.train.string_input_producer(bin_file_name)<br>  record_bytes = (FLAGS.NUM_LABEL + FLAGS.NUM_IMAGE) * FLAGS.PIXEL_LENGTH<br>  rb = tf.FixedLengthRecordReader(record_bytes=record_bytes)<br>  return fqb, rb</p>
<p>def init_csv_file():<br>  csv_file_name = [FLAGS.CSV_FILE]<br>  for f in csv_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqc = tf.train.string_input_producer(csv_file_name)<br>  rc = tf.TextLineReader(skip_header_lines=True)<br>  return fqc, rc</p>
<p>def get_data_without_no(fqb, rb, fqc, rc, val_no, test_no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [FLAGS.NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [FLAGS.NUM_LABEL], [FLAGS.NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.logical_or(tf.equal(subsetid, tf.constant(<br>      val_no, dtype=tf.int32)), tf.equal(subsetid, tf.constant(test_no, dtype=tf.int32)))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_data_with_no(fqb, rb, fqc, rc, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [FLAGS.NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [FLAGS.NUM_LABEL], [FLAGS.NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.not_equal(<br>      subsetid, tf.constant(no, dtype=tf.int32))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_train_data(fqb, rb, fqc, rc, val_no, test_no):<br>  subsetid, label, image = get_data_without_no(fqb, rb, fqc, rc, val_no, test_no)<br>  min_queue_examples = FLAGS.BATCH_SIZE <em> 10<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=FLAGS.BATCH_SIZE,<br>      num_threads=FLAGS.NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> FLAGS.BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_test_data(fqb, rb, fqc, rc, no):<br>  subsetid, label, image = get_data_with_no(fqb, rb, fqc, rc, no)<br>  min_queue_examples = FLAGS.BATCH_SIZE <em> 5<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=FLAGS.BATCH_SIZE,<br>      num_threads=FLAGS.NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> FLAGS.BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_size():<br>  ss = [0] <em> 10<br>  noaug = [0] </em> 10<br>  with open(FLAGS.CSV_FILE) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      if line[0] != ‘candidateID’:<br>        ss[int(line[1])] += 1<br>        if line[-1] == ‘0’ and line[-2] == ‘1’:<br>          noaug[int(line[1])] += 1<br>  return ss, noaug</p>
<p># Wb = {<br>#     ‘W11’: tf.Variable(tf.truncated_normal([3, 3, 3, FLAGS.CHANNEL_NUMBER, 16], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘b11’: tf.Variable(tf.zeros([16])),<br>#     ‘W12’: tf.Variable(tf.truncated_normal([3, 3, 3, 16, 24], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘b12’: tf.Variable(tf.zeros([24])),<br>#     ‘W2’: tf.Variable(tf.truncated_normal([3, 3, 3, 24, 32], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘b2’: tf.Variable(tf.zeros([32])),<br>#     ‘W3’: tf.Variable(tf.truncated_normal([3, 3, 3, 32, 48], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘b3’: tf.Variable(tf.zeros([48])),<br>#     ‘W4’: tf.Variable(tf.truncated_normal([3, 3, 3, 48, 64], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘b4’: tf.Variable(tf.zeros([64])),<br>#     ‘fcw1’: tf.Variable(tf.truncated_normal([2**3 * 64, 32], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘fcb1’: tf.Variable(tf.zeros([32])),<br>#     ‘fcw2’: tf.Variable(tf.truncated_normal([32, FLAGS.LABEL_NUMBER], stddev=0.1, seed=FLAGS.SEED)),<br>#     ‘fcb2’: tf.Variable(tf.zeros([FLAGS.LABEL_NUMBER]))<br># }</p>
<p>Wb = {<br>    ‘W11’: tf.get_variable(‘W11’, [3, 3, 3, FLAGS.CHANNEL_NUMBER, 16], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘b11’: tf.Variable(tf.zeros([16])),<br>    ‘W12’: tf.get_variable(‘W12’, [3, 3, 3, 16, 24], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘b12’: tf.Variable(tf.zeros([24])),<br>    ‘W2’: tf.get_variable(‘W2’, [3, 3, 3, 24, 32], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘b2’: tf.Variable(tf.zeros([32])),<br>    ‘W3’: tf.get_variable(‘W3’, [3, 3, 3, 32, 48], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘b3’: tf.Variable(tf.zeros([48])),<br>    ‘W4’: tf.get_variable(‘W4’, [3, 3, 3, 48, 64], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘b4’: tf.Variable(tf.zeros([64])),<br>    ‘fcw1’: tf.get_variable(‘fcw1’, [2**3 * 64, 32], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘fcb1’: tf.Variable(tf.zeros([32])),<br>    ‘fcw2’: tf.get_variable(‘fcw2’, [32, FLAGS.LABEL_NUMBER], tf.float32, tf.contrib.layers.xavier_initializer(seed=FLAGS.SEED)),<br>    ‘fcb2’: tf.Variable(tf.zeros([FLAGS.LABEL_NUMBER]))<br>}</p>
<p>def model(data, keep_prob):<br>  with tf.variable_scope(‘conv1’):<br>    conv = tf.nn.conv3d(data, Wb[‘W11’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b11’]))<br>    conv = tf.nn.conv3d(relu, Wb[‘W12’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b12’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv2’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W2’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b2’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W3’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b3’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’):<br>    conv = tf.nn.conv3d(pool, Wb[‘W4’], strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, Wb[‘b4’]))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’):<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] * ps[4]])<br>  with tf.variable_scope(‘fc1’):<br>    hidden = tf.nn.relu(tf.matmul(reshape, Wb[‘fcw1’]) + Wb[‘fcb1’])<br>  with tf.variable_scope(‘dropout’):<br>    hidden = tf.nn.dropout(hidden, keep_prob, seed=FLAGS.SEED)<br>  with tf.variable_scope(‘fc2’):<br>    out = tf.matmul(hidden, Wb[‘fcw2’]) + Wb[‘fcb2’]<br>  return out</p>
<p>def eval_in_batches(data, sess, eval_prediction, eval_data):<br>  size = data.shape[0]<br>  if size &lt; FLAGS.EVAL_BATCH_SIZE:<br>    raise ValueError(“batch size for evals larger than dataset: %d” % size)<br>  predictions = np.ndarray(shape=(size, FLAGS.LABEL_NUMBER), dtype=np.float32)<br>  for begin in xrange(0, size, FLAGS.EVAL_BATCH_SIZE):<br>    end = begin + FLAGS.EVAL_BATCH_SIZE<br>    if end &lt;= size:<br>      predictions[begin:end, :] = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[begin:end, …]})<br>    else:<br>      batch_predictions = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[-FLAGS.EVAL_BATCH_SIZE:, …]})<br>      predictions[begin:, :] = batch_predictions[begin - size:, :]<br>  return predictions</p>
<p>def error_rate(predictions, labels):<br>  “””Return the error rate based on dense predictions and sparse labels.”””<br>  return 100.0 - (100.0 * np.sum(np.argmax(predictions, 1) == labels) /<br>                  predictions.shape[0])</p>
<p>def lunaTrain(VIEW_DIRECTORY, imgName, csvName, ss_list, noaug_list):<br>  for cross in range(10):<br>    sssstttt = time.time()<br>    print(‘Cross {}…’.format(cross))<br>    WORK_DIRECTORY = os.path.join(VIEW_DIRECTORY, ‘Cross{}’.format(cross))<br>    testNo = cross<br>    valNo = (cross + 1) % 10<br>    st = time.time()<br>    train_size = sum(ss_list) - ss_list[testNo] - ss_list[valNo]<br>    val_size = ss_list[valNo]<br>    test_size = ss_list[testNo]<br>    test_no_aug_data, test_no_aug_label = get_noaug_first(testNo, noaug_list[testNo])<br>    val_no_aug_data, val_no_aug_label = get_noaug_first(valNo, noaug_list[valNo])<br>    print(‘Reading no aug data finished in {:.2f} seconds…’.format(time.time() - st))</p>
<pre><code>fqbt, rbt = init\_bin\_file()
fqct, rct = init\_csv\_file()
fqbv, rbv = init\_bin\_file()
fqcv, rcv = init\_csv\_file()
fqbe, rbe = init\_bin\_file()
fqce, rce = init\_csv\_file()
data_node = tf.placeholder(tf.float32, shape=(
    None, FLAGS.IMAGE\_SIZE, FLAGS.IMAGE\_SIZE, FLAGS.IMAGE\_SIZE, FLAGS.CHANNEL\_NUMBER))
labels_node = tf.placeholder(tf.int64, shape=(None,))
eval_data = tf.placeholder(tf.float32, shape=(
    None, FLAGS.IMAGE\_SIZE, FLAGS.IMAGE\_SIZE, FLAGS.IMAGE\_SIZE, FLAGS.CHANNEL\_NUMBER))
keep_hidden = tf.placeholder(tf.float32)
logits = model(data\_node, keep\_hidden)
loss = tf.reduce\_mean(tf.nn.sparse\_softmax\_cross\_entropy\_with\_logits(
    logits, labels_node))

batch = tf.Variable(0, trainable=False)
learning\_rate = tf.train.exponential\_decay(0.01, batch * FLAGS.BATCH_SIZE,
                                           train_size / 5, 0.95, staircase=True)
optimizer = tf.train.MomentumOptimizer(
    learning\_rate, 0.9).minimize(loss, global\_step=batch)
eval\_predictions = tf.nn.softmax(model(eval\_data, 1))

train\_label\_node, train\_data\_node = get\_train\_data(
    fqbt, rbt, fqct, rct, valNo, testNo)
val\_label\_node, val\_data\_node = get\_test\_data(fqbv, rbv, fqcv, rcv, valNo)
test\_label\_node, test\_data\_node = get\_test\_data(fqbe, rbe, fqce, rce, testNo)

saver = tf.train.Saver(tf.all_variables())

TRAIN\_FREQUENCY = train\_size // FLAGS.BATCH_SIZE // 20
VAL\_FREQUENCY = train\_size // FLAGS.BATCH_SIZE // 20
TEST\_FREQUENCY = train\_size // FLAGS.BATCH_SIZE // 20

with tf.Session() as sess:
  sess.run(tf.initialize\_local\_variables())
  sess.run(tf.initialize\_all\_variables())
  summary\_writer = tf.train.SummaryWriter(WORK\_DIRECTORY, sess.graph)
  coord = tf.train.Coordinator()
  threads = tf.train.start\_queue\_runners(sess=sess, coord=coord)
  try:
    while not coord.should_stop():
      start_time = time.time()
      valPE = test_errorP = 100
      for step in xrange(int(FLAGS.NUM\_EPOCHS * train\_size) // FLAGS.BATCH_SIZE):
        # st_read = time.time()
        train\_data, train\_label = sess.run(\[train\_data\_node, train\_label\_node\])
        # print(&apos;Read data costs {:.3f} seconds.&apos;.format(time.time() - st_read))
        feed\_dict = {data\_node: train_data,
                     labels\_node: train\_label, keep_hidden: 0.5}
        # st_train = time.time()
        _, l, lr = sess.run(\[optimizer, loss, learning\_rate\], feed\_dict=feed_dict)
        # print(&apos;Train data costs {:.3f} seconds.&apos;.format(time.time() - st_train))
        if step != 0 and step % TRAIN_FREQUENCY == 0:
          et = time.time() - start_time
          print(&apos;Step %d (epoch %.2f), %.1f ms&apos; %
                (step, float(step) * FLAGS.BATCH\_SIZE / train\_size, 1000 * et / TRAIN_FREQUENCY))
          print(&apos;Minibatch loss: %.3f, learning rate: %.6f&apos; % (l, lr))
          start_time = time.time()
        if step != 0 and VAL\_FREQUENCY != 0 and step % VAL\_FREQUENCY == 0:
          valPE = error\_rate(eval\_in_batches(
              val\_no\_aug\_data, sess, eval\_predictions, eval\_data), val\_no\_aug\_label)
          print(&apos;Validation error of no aug Positive: %.3f%%&apos; % valPE)
          if valPE &lt;= 5 and test_errorP &lt;= 5:
            st = time.time()
            val\_label\_total = \[\]
            prediction_total = \[\]
            for vi in xrange(val\_size // FLAGS.BATCH\_SIZE):
              val\_data, val\_label = sess.run(\[val\_data\_node, val\_label\_node\])
              predictions = eval\_in\_batches(
                  val\_data, sess, eval\_predictions, eval_data)
              val\_label\_total.extend(val_label)
              prediction_total.extend(predictions)
            val\_label\_total = np.array(val\_label\_total)
            prediction\_total = np.array(prediction\_total)
            valE = error\_rate(prediction\_total, val\_label\_total)
            print(&apos;Validation error: %.3f%%&apos; % valE)
            print(&apos;Validation costs {:.2f} seconds.&apos;.format(time.time() - st))
          val_data = 0
          start_time = time.time()
        if step != 0 and TEST\_FREQUENCY != 0 and step % TEST\_FREQUENCY == 0:
          test\_errorP = error\_rate(eval\_in\_batches(
              test\_no\_aug\_data, sess, eval\_predictions, eval\_data), test\_no\_aug\_label)
          print(&apos;Test error of no aug Positive: %.3f%%&apos; % test_errorP)
          if valPE &lt;= 5 and test_errorP &lt;= 5:
            st = time.time()
            test\_label\_total = \[\]
            prediction_total = \[\]
            for ti in xrange(test\_size // FLAGS.BATCH\_SIZE):
              test\_data, test\_label = sess.run(\[test\_data\_node, test\_label\_node\])
              predictions = eval\_in\_batches(
                  test\_data, sess, eval\_predictions, eval_data)
              test\_label\_total.extend(test_label)
              prediction_total.extend(predictions)
            test\_label\_total = np.array(test\_label\_total)
            prediction\_total = np.array(prediction\_total)
            test\_error = error\_rate(prediction\_total, test\_label_total)
            print(&apos;Test error: %.3f%%&apos; % test_error)
            print(&apos;Test costs {:.2f} seconds.&apos;.format(time.time() - st))
            if FLAGS.SAVE_MODEL:
              checkpoint\_path = os.path.join(WORK\_DIRECTORY, &apos;model.ckpt&apos;)
              saver.save(sess, checkpoint\_path, global\_step=step)
            VAL\_FREQUENCY = train\_size // FLAGS.BATCH_SIZE
            TEST\_FREQUENCY = train\_size // FLAGS.BATCH_SIZE * 2
          test_data = 0
          start_time = time.time()
      else:
        if FLAGS.SAVE_MODEL:
          checkpoint\_path = os.path.join(WORK\_DIRECTORY, &apos;model.ckpt&apos;)
          saver.save(sess, checkpoint\_path, global\_step=step)
        coord.request_stop()
  except tf.errors.OutOfRangeError:
    print(&apos;Done training -- epoch limit reached&apos;)
  finally:
    pass
  coord.join(threads)
print(&apos;All costs {:.2f} seconds...&apos;.format(time.time() - sssstttt))
train\_data = val\_data = test_data = 0
train\_labels = val\_labels = test_labels = 0
</code></pre><p>def main(_):<br>  viewPath = ‘/home/kong/4T/official3D_110W’<br>  csvName = ‘/home/kong/4T/official3D_110W/Shuffle.csv’<br>  imgName = ‘/home/kong/4T/official3D_110W/shuffle3D.bin’</p>
<h1 id="viewPath-‘-home-admin6-3d’"><a href="#viewPath-‘-home-admin6-3d’" class="headerlink" title="viewPath = ‘/home/admin6/3d’"></a>viewPath = ‘/home/admin6/3d’</h1><h1 id="csvName-‘-home-admin6-3d-Shuffle-csv’"><a href="#csvName-‘-home-admin6-3d-Shuffle-csv’" class="headerlink" title="csvName = ‘/home/admin6/3d/Shuffle.csv’"></a>csvName = ‘/home/admin6/3d/Shuffle.csv’</h1><h1 id="imgName-‘-home-admin6-3d-shuffle3D64-bin’"><a href="#imgName-‘-home-admin6-3d-shuffle3D64-bin’" class="headerlink" title="imgName = ‘/home/admin6/3d/shuffle3D64.bin’"></a>imgName = ‘/home/admin6/3d/shuffle3D64.bin’</h1><p>  ss_list, noaug_list = get_size()<br>  lunaTrain(viewPath, imgName, csvName, ss_list, noaug_list)</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://kongsea.github.io/2016/tensorflow-multiple-gpu-and-reading-data-using-queue-runner-example/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/tensorflow-multiple-gpu-and-reading-data-using-queue-runner-example/" itemprop="url">TensorFlow Multiple GPU and Reading data using Queue Runner Example</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-15T20:14:52+08:00">
                2016-12-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/谈天说地/" itemprop="url" rel="index">
                    <span itemprop="name">谈天说地</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#!/usr/local/bin/python<br># -<em>- coding: utf-8 -</em>-<br>‘’’3D convolutional neural network trained<br>   to reduce the False Positive Rate for the LUNA datasets.<br>   The LUNA datasets are organized in the CIFAR architecture.</p>
<p>   Author: Kong Haiyang<br>‘’’<br>from __future__ import absolute_import<br>from __future__ import division<br>from __future__ import print_function</p>
<p>import os<br>import sys<br>import time<br>import math<br>import numpy as np<br>from six.moves import xrange<br>import tensorflow as tf<br>import csv<br>import cv2</p>
<p>FLAGS = tf.app.flags.FLAGS<br>tf.app.flags.DEFINE_integer(‘IMAGE_SIZE’, 40, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘PIXEL_DATA_SIZE’, 4, “Size of Image pixel.”)<br>tf.app.flags.DEFINE_integer(‘CHANNEL_NUMBER’, 1, “Size of input Image.”)<br>tf.app.flags.DEFINE_integer(‘LABEL_NUMBER’, 2, “Label number.”)<br>tf.app.flags.DEFINE_integer(‘BATCH_SIZE’, 128, “Size of a Batch.”)<br>tf.app.flags.DEFINE_integer(‘NUM_EPOCHS’, 10, “Number of epochs.”)<br>tf.app.flags.DEFINE_integer(‘EVAL_BATCH_SIZE’, 64, “Size of an Evalution Batch.”)<br>tf.app.flags.DEFINE_integer(‘SEED’, 66478, “Seed of Shuffle.”)<br>tf.app.flags.DEFINE_string(‘TOWER_NAME’, ‘JP’, “Name of tower.”)<br>tf.app.flags.DEFINE_integer(‘NUM_GPU’, 2, “How many GPUs to use.”)<br>tf.app.flags.DEFINE_integer(‘NUM_PREPROCESS_THREADS’, 8,<br>                            “Number of preprocessing threads.”)<br>tf.app.flags.DEFINE_integer(‘NUM_LABEL’, 1, “How many Label bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(<br>    ‘NUM_IMAGE’, 40 ** 3, “How many Image bytes in a unit of Bin file.”)<br>tf.app.flags.DEFINE_integer(‘BYTE_LENGTH’, 4, “Byte length of label or image bytes.”)<br>tf.app.flags.DEFINE_string(<br>    ‘CSV_FILE’, ‘/home/kong/4T/official3D_110W/Shuffle.csv’, “Csv file path and name.”)<br>tf.app.flags.DEFINE_string(<br>    ‘BIN_FILE’, ‘/home/kong/4T/official3D_110W/shuffle3D64.bin’, “Bin file path and name.”)<br>tf.app.flags.DEFINE_string(‘XAVIER_INIT’,<br>                           ‘tf.contrib.layers.xavier_initializer(seed=SEED)’,<br>                           “Initialize with XAVIER_INIT.”)</p>
<p>IMAGE_SIZE = FLAGS.IMAGE_SIZE<br>PIXEL_DATA_SIZE = FLAGS.PIXEL_DATA_SIZE<br>NUM_CHANNELS = FLAGS.CHANNEL_NUMBER<br>NUM_LABELS = FLAGS.LABEL_NUMBER<br>SEED = FLAGS.SEED<br>BATCH_SIZE = FLAGS.BATCH_SIZE<br>NUM_EPOCHS = FLAGS.NUM_EPOCHS<br>EVAL_BATCH_SIZE = FLAGS.EVAL_BATCH_SIZE<br>XAVIER_INIT = FLAGS.XAVIER_INIT<br>TOWER_NAME = FLAGS.TOWER_NAME<br>NUM_GPU = FLAGS.NUM_GPU<br>NUM_PREPROCESS_THREADS = FLAGS.NUM_PREPROCESS_THREADS<br>CSV_FILE = FLAGS.CSV_FILE<br>BIN_FILE = FLAGS.BIN_FILE<br>NUM_LABEL = FLAGS.NUM_LABEL<br>NUM_IMAGE = FLAGS.NUM_IMAGE<br>BYTE_LENGTH = FLAGS.BYTE_LENGTH<br>DTYPE = tf.float32</p>
<p>def readCSV(filename):<br>  ‘’’read lines from a csv file.<br>  ‘’’<br>  lines = []<br>  with open(filename, “rb”) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      lines.append(line)<br>  return lines</p>
<p>def get_noaug_first(CSV_FILE, BIN_FILE, no, count):<br>  lines = readCSV(CSV_FILE)[1:]<br>  data = np.empty([count, IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1], dtype=float)<br>  labels = np.empty(count, dtype=int)<br>  i = count_ = 0<br>  length = (NUM_LABEL + NUM_IMAGE) <em> 4<br>  with open(BIN_FILE, ‘rb’) as f:<br>    for line in lines:<br>      if line[1] == str(no) and line[-1] == ‘0’ and line[-2] == ‘1’:<br>        f.seek(i </em> length)<br>        buf = f.read(length)<br>        data[count_, …] = (np.frombuffer(buf[4:], dtype=np.float32)).reshape(<br>            IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1)<br>        labels[count_] = np.frombuffer(buf[0:4], dtype=np.float32).astype(np.int64)<br>        count_ += 1<br>      i += 1<br>  return data, labels</p>
<p>def init_bin_file(BIN_FILE):<br>  bin_file_name = [BIN_FILE]<br>  for f in bin_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqb = tf.train.string_input_producer(bin_file_name, num_epochs=1)<br>  record_bytes = (NUM_LABEL + NUM_IMAGE) * BYTE_LENGTH<br>  rb = tf.FixedLengthRecordReader(record_bytes=record_bytes)<br>  return fqb, rb</p>
<p>def init_csv_file(CSV_FILE):<br>  csv_file_name = [CSV_FILE]<br>  for f in csv_file_name:<br>    if not tf.gfile.Exists(f):<br>      raise ValueError(‘Failed to find file: ‘ + f)<br>  fqc = tf.train.string_input_producer(csv_file_name, num_epochs=1)<br>  rc = tf.TextLineReader(skip_header_lines=True)<br>  return fqc, rc</p>
<p>def get_data_without_no(fqb, rb, fqc, rc, val_no, test_no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.logical_or(tf.equal(subsetid, tf.constant(<br>      val_no, dtype=tf.int32)), tf.equal(subsetid, tf.constant(test_no, dtype=tf.int32)))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_data_with_no(fqb, rb, fqc, rc, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      return subsetid<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    return getID(), label, image<br>  subsetid, label, image = getBIN()<br>  cond = lambda subsetid, label, image: tf.not_equal(<br>      subsetid, tf.constant(no, dtype=tf.int32))<br>  doRead = lambda subsetid, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, label, image])<br>  return result</p>
<p>def get_noaug_with_no(fqb, rb, fqc, rc, no):<br>  def getBIN():<br>    def getID():<br>      key_raw, value = rc.read(fqc)<br>      value_raw = tf.reshape(value, [1])<br>      split_values = tf.string_split(value_raw, delimiter=’,’)<br>      subsetid = tf.string_to_number(split_values.values[1], out_type=tf.int32)<br>      class_flag = tf.string_to_number(split_values.values[-2], out_type=tf.int32)<br>      noaug = tf.string_to_number(split_values.values[-1], out_type=tf.int32)<br>      return subsetid, class_flag, noaug<br>    key, value = rb.read(fqb)<br>    record_bytes = tf.decode_raw(value, tf.float32)<br>    label = tf.cast(tf.slice(record_bytes, [0], [NUM_LABEL]), tf.int64)<br>    image = tf.reshape(tf.slice(record_bytes, [NUM_LABEL], [NUM_IMAGE]),<br>                       shape=[40, 40, 40, 1])<br>    subsetid, class_flag, noaug = getID()<br>    return subsetid, class_flag, noaug, label, image<br>  subsetid, class_flag, noaug, label, image = getBIN()<br>  cond = lambda subsetid, class_flag, noaug, label, image: tf.logical_or(tf.not_equal(subsetid, tf.constant(no, dtype=tf.int32)),<br>                                                                         tf.logical_or(tf.not_equal(class_flag, tf.constant(1, dtype=tf.int32)), tf.not_equal(noaug, tf.constant(0, dtype=tf.int32))))<br>  doRead = lambda subsetid, class_flag, noaug, label, image: getBIN()<br>  result = tf.while_loop(cond, doRead, [subsetid, class_flag, noaug, label, image])<br>  return result</p>
<p>def get_train_data(fqb, rb, fqc, rc, val_no, test_no):<br>  subsetid, label, image = get_data_without_no(fqb, rb, fqc, rc, val_no, test_no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_test_data(fqb, rb, fqc, rc, no):<br>  subsetid, label, image = get_data_with_no(fqb, rb, fqc, rc, no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, labels, images = tf.train.batch(<br>      [subsetid, label, image],<br>      batch_size=BATCH_SIZE,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return labels, images</p>
<p>def get_noaug_data(fqb, rb, fqc, rc, no):<br>  subsetid, class_flag, noaug, label, image = get_noaug_with_no(fqb, rb, fqc, rc, no)<br>  min_queue_examples = BATCH_SIZE <em> 20<br>  sis, cfs, noaugs, labels, images = tf.train.batch(<br>      [subsetid, class_flag, noaug, label, image],<br>      batch_size=BATCH_SIZE // 10,<br>      num_threads=NUM_PREPROCESS_THREADS,<br>      capacity=min_queue_examples + 3 </em> BATCH_SIZE)<br>  labels = tf.reshape(labels, [-1])<br>  return sis, cfs, noaugs, labels, images</p>
<p>def get_size(CSV_FILE):<br>  ss = [0] <em> 10<br>  noaug = [0] </em> 10<br>  with open(CSV_FILE) as f:<br>    csvreader = csv.reader(f)<br>    for line in csvreader:<br>      if line[0] != ‘candidateID’:<br>        ss[int(line[1])] += 1<br>        if line[-1] == ‘0’ and line[-2] == ‘1’:<br>          noaug[int(line[1])] += 1<br>  return ss, noaug</p>
<p>def _weight_on_cpu(name, shape):<br>  with tf.device(‘/cpu:0’):<br>    var = tf.get_variable(name, shape, DTYPE, tf.truncated_normal_initializer(stddev=0.1))<br>  return var</p>
<p>def _bias_on_cpu(name, shape):<br>  with tf.device(‘/cpu:0’):<br>    var = tf.get_variable(name, shape, DTYPE, tf.constant_initializer(0.0))<br>  return var</p>
<p>def model(data, isTraining, keep_prob):<br>  with tf.variable_scope(‘conv1’) as scope:<br>    W1 = _weight_on_cpu(‘W1’, [3, 3, 3, NUM_CHANNELS, 16])<br>    conv = tf.nn.conv3d(data, W1, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b1 = _bias_on_cpu(‘b1’, [16])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b1))<br>  with tf.variable_scope(‘conv2’) as scope:<br>    W2 = _weight_on_cpu(‘W2’, [3, 3, 3, 16, 24])<br>    conv = tf.nn.conv3d(relu, W2, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b2 = _bias_on_cpu(‘b2’, [24])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b2))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv3’) as scope:<br>    W3 = _weight_on_cpu(‘W3’, [3, 3, 3, 24, 32])<br>    conv = tf.nn.conv3d(pool, W3, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b3 = _bias_on_cpu(‘b3’, [32])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b3))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv4’) as scope:<br>    W4 = _weight_on_cpu(‘W4’, [3, 3, 3, 32, 48])<br>    conv = tf.nn.conv3d(pool, W4, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b4 = _bias_on_cpu(‘b4’, [48])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b4))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘conv5’) as scope:<br>    W5 = _weight_on_cpu(‘W5’, [3, 3, 3, 48, 64])<br>    conv = tf.nn.conv3d(pool, W5, strides=[1, 1, 1, 1, 1], padding=’SAME’)<br>    b5 = _bias_on_cpu(‘b5’, [64])<br>    relu = tf.nn.relu(tf.nn.bias_add(conv, b5))<br>    pool = tf.nn.max_pool3d(relu, ksize=[1, 2, 2, 2, 1],<br>                            strides=[1, 2, 2, 2, 1], padding=’VALID’)<br>  with tf.variable_scope(‘reshape’) as scope:<br>    ps = pool.get_shape().as_list()<br>    reshape = tf.reshape(pool, [-1, ps[1] <em> ps[2] </em> ps[3] <em> ps[4]])<br>  with tf.variable_scope(‘fc1’) as scope:<br>    fcw1 = _weight_on_cpu(‘fcw1’, [2\</em>*3 * 64, 32])<br>    fcb1 = _bias_on_cpu(‘fcb1’, [32])<br>    hidden = tf.nn.relu(tf.matmul(reshape, fcw1) + fcb1)</p>
<pre><code>hidden = tf.cond(isTraining,
                 lambda: tf.nn.dropout(hidden, keep_prob),
                 lambda: hidden)
</code></pre><p>  with tf.variable_scope(‘fc2’) as scope:<br>    fcw2 = _weight_on_cpu(‘fcw2’, [32, NUM_LABELS])<br>    fcb2 = _bias_on_cpu(‘fcb2’, [NUM_LABELS])<br>    out = tf.add(tf.matmul(hidden, fcw2), fcb2)<br>  return out</p>
<p>def loss(logits, labels):<br>  “””Add L2Loss to all the trainable variables.<br>  “””<br>  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(<br>      logits, labels, name=’cross_entropy_per_example’)<br>  cross_entropy_mean = tf.reduce_mean(cross_entropy, name=’cross_entropy’)<br>  tf.add_to_collection(‘losses’, cross_entropy_mean)</p>
<p>  return tf.add_n(tf.get_collection(‘losses’), name=’total_loss’)</p>
<p>def tower_loss(images, labels, isTraining, scope):<br>  logits = model(images, isTraining, 0.5)<br>  _ = loss(logits, labels)<br>  losses = tf.get_collection(‘losses’, scope)<br>  total_loss = tf.add_n(losses, name=’total_loss’)</p>
<p>  loss_averages = tf.train.ExponentialMovingAverage(0.9, name=’avg’)<br>  loss_averages_op = loss_averages.apply(losses + [total_loss])</p>
<p>  with tf.control_dependencies([loss_averages_op]):<br>    total_loss = tf.identity(total_loss)<br>  return total_loss, logits</p>
<p>def average_gradients(tower_grads):<br>  “””Calculate the average gradient for each shared variable across all towers.<br>  Note that this function provides a synchronization point across all towers.<br>  “””<br>  average_grads = []<br>  for grad_and_vars in zip(*tower_grads):<br>    grads = []<br>    for g, _ in grad_and_vars:<br>      expanded_g = tf.expand_dims(g, 0)<br>      grads.append(expanded_g)</p>
<pre><code>grad = tf.concat(0, grads)
grad = tf.reduce_mean(grad, 0)
v = grad\_and\_vars\[0\]\[1\]
grad\_and\_var = (grad, v)
average\_grads.append(grad\_and_var)
</code></pre><p>  return average_grads</p>
<p>def eval_in_batches(data, sess, eval_prediction, eval_data, isTraining):<br>  size = data.shape[0]<br>  if size &lt; EVAL_BATCH_SIZE:<br>    raise ValueError(“batch size for evals larger than dataset: %d” % size)</p>
<h1 id="size-size-NUM-GPU-comment-this-will-cause-tf-exception"><a href="#size-size-NUM-GPU-comment-this-will-cause-tf-exception" class="headerlink" title="size -= size % NUM_GPU  # comment this will cause tf exception?"></a>size -= size % NUM_GPU  # comment this will cause tf exception?</h1><p>  predictions = np.ndarray(shape=(size, NUM_LABELS), dtype=np.float32)<br>  for begin in xrange(0, size, EVAL_BATCH_SIZE):<br>    end = begin + EVAL_BATCH_SIZE<br>    if end &lt;= size:<br>      predict = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[begin:end, …], isTraining: False})<br>      predictions[begin:end, :] = np.vstack(predict)<br>    else:<br>      batch_predictions = sess.run(eval_prediction, feed_dict={<br>          eval_data: data[-EVAL_BATCH_SIZE:, …], isTraining: False})<br>      predictions[begin:, :] = batch_predictions[begin - size:, :]<br>  return predictions</p>
<p>def error_rate(predictions, labels):<br>  “””Return the error rate based on dense predictions and sparse labels.”””<br>  return 100.0 - (100.0 * np.sum(np.argmax(predictions, 1) == labels) /<br>                  predictions.shape[0])</p>
<p>def lunaTrain(VIEW_DIRECTORY, imgName, csvName, ss_list, noaug_list):<br>  with tf.Graph().as_default(), tf.device(‘/cpu:0’):<br>    for cross in range(10):<br>      sssstttt = time.time()<br>      print(‘Cross {}…’.format(cross))<br>      WORK_DIRECTORY = os.path.join(VIEW_DIRECTORY, ‘Cross{}’.format(cross))<br>      testNo = cross<br>      valNo = (cross + 1) % 10<br>      st = time.time()<br>      train_size = sum(ss_list) - ss_list[testNo] - ss_list[valNo]<br>      test_no_aug_data, test_no_aug_label = get_noaug_first(<br>          CSV_FILE, BIN_FILE, testNo, noaug_list[testNo])<br>      val_no_aug_data, val_no_aug_label = get_noaug_first(<br>          CSV_FILE, BIN_FILE, valNo, noaug_list[valNo])<br>      print(‘Reading no aug data finished in {:.2f} seconds…’.format(time.time() - st))<br>      st = time.time()<br>      fqbt, rbt = init_bin_file(BIN_FILE)<br>      fqct, rct = init_csv_file(CSV_FILE)<br>      fqbe, rbe = init_bin_file(BIN_FILE)<br>      fqce, rce = init_csv_file(CSV_FILE)<br>      data_node = tf.placeholder(tf.float32, shape=(<br>          None, IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))<br>      labels_node = tf.placeholder(tf.int64, shape=(None,))<br>      isTraining = tf.placeholder(tf.bool, name=’isTrain’)</p>
<pre><code>batch = tf.Variable(0, trainable=False)
learning\_rate = tf.train.exponential\_decay(0.01, batch * BATCH\_SIZE, train\_size / 5,
                                           0.95, staircase=True)
opt = tf.train.MomentumOptimizer(learning_rate, 0.9)

split\_images = tf.split(0, NUM\_GPU, data_node)
split\_labels = tf.split(0, NUM\_GPU, labels_node)

eval_predictions = \[\]
tower_grads = \[\]
for i in xrange(NUM_GPU):
  with tf.device(&apos;/gpu:%d&apos; % i):
    with tf.name\_scope(&apos;%s\_%d&apos; % (TOWER_NAME, i)) as scope:
      loss, logits = tower\_loss(split\_images\[i\], split_labels\[i\], isTraining, scope)
      predictions = tf.nn.softmax(logits)
      eval_predictions.append(predictions)
      tf.get\_variable\_scope().reuse_variables()

      grads = opt.compute_gradients(loss)
      tower_grads.append(grads)

grads = average\_gradients(tower\_grads)
apply\_gradient\_op = opt.apply_gradients(grads)

variable_averages = tf.train.ExponentialMovingAverage(0.9999)
variables\_averages\_op = variable\_averages.apply(tf.trainable\_variables())

train\_op = tf.group(apply\_gradient\_op, variables\_averages_op)

train\_label\_node, train\_data\_node = get\_train\_data(
    fqbt, rbt, fqct, rct, valNo, testNo)
val\_label\_node, val\_data\_node = get\_test\_data(fqbe, rbe, fqce, rce, valNo)
test\_label\_node, test\_data\_node = get\_test\_data(fqbe, rbe, fqce, rce, testNo)

saver = tf.train.Saver(tf.all_variables())

TRAIN\_FREQUENCY = train\_size // BATCH_SIZE // 20
VAL\_FREQUENCY = train\_size // BATCH_SIZE
TEST\_FREQUENCY = train\_size // BATCH_SIZE * 5

config = tf.ConfigProto(allow\_soft\_placement=True, log\_device\_placement=False)
with tf.Session(config=config) as sess:
  summary\_writer = tf.train.SummaryWriter(WORK\_DIRECTORY, sess.graph)
  sess.run(tf.initialize\_local\_variables())
  sess.run(tf.initialize\_all\_variables())
  coord = tf.train.Coordinator()
  threads = tf.train.start\_queue\_runners(sess=sess, coord=coord)
  try:
    while not coord.should_stop():
      start_time = time.time()
      for step in xrange(int(NUM\_EPOCHS * train\_size) // BATCH_SIZE):
        train\_data, train\_label = sess.run(\[train\_data\_node, train\_label\_node\])
        feed\_dict = {data\_node: train_data,
                     labels\_node: train\_label, isTraining: True}
        _, l, lr = sess.run(\[train\_op, loss, learning\_rate\], feed\_dict=feed\_dict)
        if step != 0 and step % TRAIN_FREQUENCY == 0:
          et = time.time() - start_time
          print(&apos;Step %d (epoch %.2f), %.1f ms&apos; %
                (step, float(step) * BATCH\_SIZE / train\_size, 1000 * et / TRAIN_FREQUENCY))
          print(&apos;Minibatch loss: %.3f, learning rate: %.6f&apos; % (l, lr))
          start_time = time.time()
        if step != 0 and VAL\_FREQUENCY != 0 and step % VAL\_FREQUENCY == 0:
          val\_data, val\_label = sess.run(\[val\_data\_node, val\_label\_node\])
          valE = error\_rate(eval\_in_batches(
              val\_data, sess, eval\_predictions, data\_node, isTraining), val\_label)
          print(&apos;Validation error: %.3f%%&apos; % valE)
          valPE = error\_rate(eval\_in_batches(
              val\_no\_aug\_data, sess, eval\_predictions, data\_node, isTraining), val\_no\_aug\_label)
          print(&apos;Validation error of no aug Positive: %.3f%%&apos; % valPE)
          val_data = 0
          start_time = time.time()
        if step != 0 and TEST\_FREQUENCY != 0 and step % TEST\_FREQUENCY == 0:
          test\_data, test\_label = sess.run(\[test\_data\_node, test\_label\_node\])
          test\_error = error\_rate(eval\_in\_batches(
              test\_data, sess, eval\_predictions, data\_node, isTraining), test\_label)
          print(&apos;Test error: %.3f%%&apos; % test_error)
          test\_errorP = error\_rate(eval\_in\_batches(
              test\_no\_aug\_data, sess, eval\_predictions, data\_node, isTraining), test\_no\_aug\_label)
          print(&apos;Test error of no aug Positive: %.3f%%&apos; % test_errorP)
          test_data = 0
          start_time = time.time()
      else:
        checkpoint\_path = os.path.join(WORK\_DIRECTORY, &apos;model.ckpt&apos;)
        saver.save(sess, checkpoint\_path, global\_step=step)
  except tf.errors.OutOfRangeError:
    print(&apos;Done training -- epoch limit reached&apos;)
  finally:
    coord.request_stop()
  coord.join(threads)
print(&apos;All costs {:.2f} seconds...&apos;.format(time.time() - sssstttt))
train\_data = val\_data = test_data = 0
train\_labels = val\_labels = test_labels = 0
</code></pre><p>def main(_):<br>  viewPath = ‘/home/kong/4T/official3D_110W’<br>  csvName = ‘/home/kong/4T/official3D_110W/Shuffle.csv’<br>  imgName = ‘/home/kong/4T/official3D_110W/shuffle3D.bin’</p>
<p>  ss_list, noaug_list = get_size(CSV_FILE)<br>  lunaTrain(viewPath, imgName, csvName, ss_list, noaug_list)</p>
<p>if __name__ == ‘__main__‘:<br>  tf.app.run()</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="John Doe" />
          <p class="site-author-name" itemprop="name">John Doe</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">433</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">108</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
